{"id":"2010.12496","submitter":"Chaoning Zhang","authors":"Chaoning Zhang, Philipp Benz, Dawit Mureja Argaw, Seokju Lee, Junsik\n  Kim, Francois Rameau, Jean-Charles Bazin, In So Kweon","title":"ResNet or DenseNet? Introducing Dense Shortcuts to ResNet","comments":"Accepted to WACV2021 first round","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  ResNet or DenseNet? Nowadays, most deep learning based approaches are\nimplemented with seminal backbone networks, among them the two arguably most\nfamous ones are ResNet and DenseNet. Despite their competitive performance and\noverwhelming popularity, inherent drawbacks exist for both of them. For ResNet,\nthe identity shortcut that stabilizes training also limits its representation\ncapacity, while DenseNet has a higher capacity with multi-layer feature\nconcatenation. However, the dense concatenation causes a new problem of\nrequiring high GPU memory and more training time. Partially due to this, it is\nnot a trivial choice between ResNet and DenseNet. This paper provides a unified\nperspective of dense summation to analyze them, which facilitates a better\nunderstanding of their core difference. We further propose dense weighted\nnormalized shortcuts as a solution to the dilemma between them. Our proposed\ndense shortcut inherits the design philosophy of simple design in ResNet and\nDenseNet. On several benchmark datasets, the experimental results show that the\nproposed DSNet achieves significantly better results than ResNet, and achieves\ncomparable performance as DenseNet but requiring fewer computation resources.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:00:15 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12497","submitter":"Omid Ghahabi","authors":"Omid Ghahabi, Volker Fischer","title":"EML System Description for VoxCeleb Speaker Diarization Challenge 2020","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This technical report describes the EML submission to the first VoxCeleb\nspeaker diarization challenge. Although the aim of the challenge has been the\noffline processing of the signals, the submitted system is basically the EML\nonline algorithm which decides about the speaker labels in runtime\napproximately every 1.2 sec. For the first phase of the challenge, only\nVoxCeleb2 dev dataset was used for training. The results on the provided\nVoxConverse dev set show much better accuracy in terms of both DER and JER\ncompared to the offline baseline provided in the challenge. The real-time\nfactor of the whole diarization process is about 0.01 using a single CPU\nmachine.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:01:28 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12498","submitter":"Zhi Hu","authors":"Zhi Hu, Siqi Xu, Chandan Mondal, Xingbo Zhao, James P. Vary","title":"Transverse structure of electron in momentum space in basis light-front\n  quantization","comments":"16 pages, 14 figures","journal-ref":"Phys. Rev. D 103, 036005 (2021)","doi":"10.1103/PhysRevD.103.036005","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the leading-twist transverse momentum-dependent distribution\nfunctions (TMDs) for a physical electron, a spin-1/2 composite system\nconsisting of a bare electron and a photon, using the Basis Light-front\nQuantization (BLFQ) framework. The light-front wave functions of the physical\nelectron are obtained from the eigenvectors of the light-front QED Hamiltonian.\nWe evaluate the TMDs using the overlaps of the light-front wave functions. The\nBLFQ results are found to be in excellent agreement with those TMDs calculated\nusing lowest-order perturbation theory.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:03:16 GMT"}],"update_date":"2021-02-10"}
{"id":"2010.12499","submitter":"Nicolas Moreau","authors":"Nicolas Moreau, Boris Brun, Sowmya Somanchi, Kenji Watanabe, Takashi\n  Taniguchi, Christoph Stampfer, Benoit Hackens","title":"Upstream modes and antidots poison graphene quantum Hall effect","comments":"6 pages, 4 figures","journal-ref":null,"doi":"10.1038/s41467-021-24481-2","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The quantum Hall effect is the seminal example of topological protection, as\ncharge carriers are transmitted through one-dimensional edge channels where\nbackscattering is prohibited. Graphene has made its marks as an exceptional\nplatform to reveal new facets of this remarkable property. However, in\nconventional Hall bar geometries, topological protection of graphene edge\nchannels is found regrettably less robust than in high mobility\nsemi-conductors. Here, we explore graphene quantum Hall regime at the local\nscale, using a scanning gate microscope. We reveal the detrimental influence of\nantidots along the graphene edges, mediating backscattering towards upstream\nedge channels, hence triggering topological breakdown. Combined with\nsimulations, our experimental results provide further insights into graphene\nquantum Hall channels vulnerability. In turn, this may ease future developments\ntowards precise manipulation of topologically protected edge channels hosted in\nvarious types of two-dimensional crystals.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:03:48 GMT"},{"version":"v2","created":"Mon, 19 Apr 2021 22:22:01 GMT"}],"update_date":"2021-07-14"}
{"id":"2010.12500","submitter":"Myriam Bontonou","authors":"Myriam Bontonou, Giulia Lioi, Nicolas Farrugia, Vincent Gripon","title":"Few-shot Decoding of Brain Activation Maps","comments":"5 pages. Updated title and minor modifications","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Few-shot learning addresses problems for which a limited number of training\nexamples are available. So far, the field has been mostly driven by\napplications in computer vision. Here, we are interested in adapting recently\nintroduced few-shot methods to solve problems dealing with neuroimaging data, a\npromising application field. To this end, we create a neuroimaging benchmark\ndataset for few-shot learning and compare multiple learning paradigms,\nincluding meta-learning, as well as various backbone networks. Our experiments\nshow that few-shot methods are able to efficiently decode brain signals using\nfew examples, which paves the way for a number of applications in clinical and\ncognitive neuroscience, such as identifying biomarkers from brain scans or\nunderstanding the generalization of brain representations across a wide range\nof cognitive tasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:04:45 GMT"},{"version":"v2","created":"Tue, 2 Mar 2021 11:59:26 GMT"},{"version":"v3","created":"Wed, 19 May 2021 15:11:23 GMT"}],"update_date":"2021-05-20"}
{"id":"2010.12501","submitter":"En-Wei Liang","authors":"Xiao-Li Huang (NJU), En-Wei Liang (GXU), Ruo-Yu Liu (NJU), Ji-Gui\n  Cheng (GXU), Xiang-Yu Wang (NJU)","title":"Afterglow Synchrotron Radiations follow the $L_{\\rm p, iso}-E_{\\rm\n  p,z}-\\Gamma_0$ relation of Gamma-Ray Bursts? Cases of GRBs 190114C, 130427A,\n  and 180720B","comments":"15 pages, 3 figures, and 1 table; Accepted for publication in ApJL","journal-ref":null,"doi":"10.3847/2041-8213/abc330","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bimodal spectral energy distributions (SEDs) of gamma-ray burst (GRB)\nafterglow of GRBs 190114C, 130427A and 180720B confirm that they are originated\nfrom the synchrotron emission (Syn) and synchrotron self-Compton Scattering\nprocess (SSC) of electrons accelerated in the jets. The radiation mechanism and\nthe physics of the observed spectrum-luminosity/energy relations of GRBs remain\nas open questions. By extracting the Syn component through fitting their early\nafterglow SEDs with the Syn+SSC model, we find that their luminosity ($L_{\\rm\nsyn}$), peak energy ($E_{\\rm p,syn,z}$), and the Lorentz factor of the\nafterglow fireball ($\\Gamma_t$) follow the $L_{\\rm p, iso}-E_{\\rm\np,z}-\\Gamma_{0}$ relation of prompt gamma-rays, where $L_{\\rm p, iso}$ is the\nisotropic luminosity, $E_{\\rm p, z}$ is the peak energy of the $\\nu f_\\nu$\nspectrum in the burst frame, and $\\Gamma_0$ is the initial Lorentz factor of\nthe fireball. To examine whether late afterglows is consistent with this\nrelation, we calculate the synchrotron component at late afterglows. It is\nfound that they also follow the same $L_{\\rm p, iso}-E_{\\rm p,z}-\\Gamma_{0}$\nrelation, albeit they are not consistent with the $L_{\\rm p, iso}-E_{\\rm p,z}$\nrelation. Our results may imply that the $L_{\\rm p, iso}-E_{\\rm\np,z}-\\Gamma_{0}$ would be an universal feature of synchrotron radiations of\nelectrons accelerated in GRB jets throughout the prompt and afterglow phases\namong GRBs. Its origin is not fully understood and possible explanations are\nbriefly discussed.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:07:27 GMT"}],"update_date":"2020-11-11"}
{"id":"2010.12502","submitter":"Gonzalo Seco-Granados","authors":"Gonzalo Seco-Granados, David Gomez-Casco, Jose A. Lopez-Salcedo,\n  Ignacio Fernandez-Hernandez","title":"Detection of Replay Attacks to GNSS based on Partial Correlations and\n  Authentication Data Unpredictability","comments":null,"journal-ref":"GPS Solutions, 2021","doi":"10.1007/s10291-020-01049-z","report-no":null,"categories":"cs.CR eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Intentional interference, and in particular GNSS spoofing, is currently one\nof the most significant concerns of the Positioning, Navigation and Timing\n(PNT) community. With the adoption of Open Service Navigation Message\nAuthentication (OSNMA) in Galileo, the E1B signal component will continuously\nbroadcast unpredictable cryptographic data. This allows GNSS receivers not only\nto ensure the authenticity of data origin but also to detect replay spoofing\nattacks for receivers already tracking real signals with relatively good\nvisibility conditions. Since the spoofer needs to estimate the unpredictable\nbits introduced by OSNMA with almost zero delay in order to perform a Security\nCode Estimation and Replay (SCER) attack, the spoofer unavoidably introduces a\nslight distortion into the signal, which can be the basis of a spoofing\ndetector. In this work, we propose five detectors based on partial correlations\nof GNSS signals obtained over predictable and unpredictable parts of the\nsignals. We evaluate them in a wide set of test cases, including different\ntypes of receiver and spoofing conditions. The results show that one of the\ndetectors is consistently superior to the others, and it is able to detect SCER\nattacks with a high probability even in favorable conditions for the spoofer.\nFinally, we discuss some practical considerations for implementing the proposed\ndetector in receivers, in particular when the Galileo OSNMA message structure\nis used.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:09:17 GMT"},{"version":"v2","created":"Fri, 6 Nov 2020 19:57:27 GMT"}],"update_date":"2021-01-25"}
{"id":"2010.12503","submitter":"Jorge Olmos","authors":"Cristina Sanz-Fern\\'andez, Mart\\'in Molezuelas, Jon Lasa-Alonso, Nuno\n  de Sousa, Xavier Zambrana-Puyalto, and Jorge Olmos-Trigo","title":"Multiple Kerker anapoles in dielectric microspheres","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  High refractive index dielectric spheres present remarkable light-scattering\nproperties in the spectral range dominated by dipolar modes. However, most of\nthese properties are absent for larger spheres under plane wave illumination.\nHere, we propose to unravel dipolar regimes regardless of the sphere size and\nrefractive index by illuminating with a pure dipolar field. This type of\nillumination ensures that the scattering response of the sphere is purely\ndipolar. In this scenario, we show that Kerker conditions are not only related\nto duality symmetry and a strong backward-to-forward asymmetric\nlight-scattering, but also to the appearance of non-radiating sources: the\nso-called hybrid anapoles. Finally, we show that all the abovementioned\nscattering features under dipolar illumination are reproducible with an\nexperimentally accessible tightly-focused Gaussian beam.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:11:42 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12504","submitter":"Masahiro Sato","authors":"Masahiro Sato and Jacques Garrigue","title":"An Intuitionistic Set-theoretical Model of Fully Dependent CC{\\omega}","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Werner's set-theoretical model is one of the simplest models of CIC. It\ncombines a functional view of predicative universes with a collapsed view of\nthe impredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle holds. Following our previous work, we interpret\nProp into a topological space (a special case of Heyting algebra) to make the\nmodel more intuitionistic without sacrificing simplicity. We improve on that\nwork by providing a full interpretation of dependent product types, using\nAlexandroff spaces. We also extend our approach to inductive types by adding\nsupport for lists.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:11:48 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12505","submitter":"Tim Draws","authors":"Tim Draws, Jody Liu, Nava Tintarev","title":"Helping users discover perspectives: Enhancing opinion mining with joint\n  topic models","comments":"Accepted at the SENTIRE workshop at ICDM 2020:\n  https://sentic.net/sentire/#2020","journal-ref":"2020 International Conference on Data Mining Workshops (ICDMW)","doi":"10.1109/ICDMW51313.2020.00013","report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Support or opposition concerning a debated claim such as abortion should be\nlegal can have different underlying reasons, which we call perspectives. This\npaper explores how opinion mining can be enhanced with joint topic modeling, to\nidentify distinct perspectives within the topic, providing an informative\noverview from unstructured text. We evaluate four joint topic models (TAM, JST,\nVODUM, and LAM) in a user study assessing human understandability of the\nextracted perspectives. Based on the results, we conclude that joint topic\nmodels such as TAM can discover perspectives that align with human judgments.\nMoreover, our results suggest that users are not influenced by their\npre-existing stance on the topic of abortion when interpreting the output of\ntopic models.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:13:06 GMT"},{"version":"v2","created":"Wed, 28 Apr 2021 20:28:16 GMT"}],"update_date":"2021-04-30"}
{"id":"2010.12506","submitter":"Andrew Lawrie","authors":"Jacek Jendrej and Andrew Lawrie","title":"Continuous time soliton resolution for two-bubble equivariant wave maps","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the energy-critical wave maps equation from 1+2 dimensional\nMinkowski space into the 2-sphere, in the equivariant case. We prove that if a\nwave map decomposes, along a sequence of times, into a superposition of at most\ntwo rescaled harmonic maps (bubbles) and radiation, then such a decomposition\nholds for continuous time. If the equivariance degree equals one or two, we\ndeduce, as a consequence of sequential soliton resolution results of C\\^ote,\nand Jia and Kenig, that any topologically trivial equivariant wave map with\nenergy less than four times the energy of the bubble asymptotically decomposes\ninto (at most two) bubbles and radiation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:16:13 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12507","submitter":"Lara Benfatto","authors":"G. Seibold, M. Udina, C. Castellani and L. Benfatto","title":"Third harmonic generation from collective modes in disordered\n  superconductors","comments":null,"journal-ref":"Phys. Rev. B 103, 014512 (2021)","doi":"10.1103/PhysRevB.103.014512","report-no":null,"categories":"cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent experiments with strong THz fields in both conventional and\nunconventional superconductors have clearly evidenced a marked third-harmonic\ngeneration below the superconducting temperature $T_c$. Its interpretation\nchallenged substantial theoretical work aimed at establishing the relative\nefficiency of quasiparticle excitations and collective modes in triggering such\na resonant response. Here we compute the non-linear current by implementing a\ntime-dependent Bogoljubov de-Gennes approach, with the twofold aim to account\nnon-perturbatively for the effect of local disorder, and to include the\ncontribution of all collective modes, i.e. superconducting amplitude (Higgs)\nand phase fluctuations, and charge fluctuations. We show that, in agreement\nwith previous work, already at small disorder the quasiparticle response is\ndominated by paramagnetic effects. We further demonstrate that paramagnetic\nprocesses mediate also the response of all collective modes, with a substantial\ncontribution of charge/phase fluctuations. These processes, which have been\noverlooked so far, turn out to dominate the third-order current at strong\ndisorder. In addition, we show that disorder strongly influences the\npolarization dependence of the non-linear response, with a marked difference\nbetween the clean and the disordered case. Our results are particularly\nrelevant for recent experiments in cuprates, whose band structure is in a first\napproximation reproduced by our lattice model.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:19:26 GMT"}],"update_date":"2021-01-27"}
{"id":"2010.12508","submitter":"Gustav Sourek","authors":"Ond\\v{r}ej Hub\\'a\\v{c}ek, Gustav \\v{S}\\'ir","title":"Beating the market with a bad predictive model","comments":"We share our insights on how to beat a market maker (bookmaker) with\n  a predictive (statistical) price-estimation model more easily. Feel free to\n  contact us with questions: souregus@gmail.com","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CE cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is a common misconception that in order to make consistent profits as a\ntrader, one needs to posses some extra information leading to an asset value\nestimation more accurate than that reflected by the current market price. While\nthe idea makes intuitive sense and is also well substantiated by the widely\npopular Kelly criterion, we prove that it is generally possible to make\nsystematic profits with a completely inferior price-predicting model. The key\nidea is to alter the training objective of the predictive models to explicitly\ndecorrelate them from the market, enabling to exploit inconspicuous biases in\nmarket maker's pricing, and profit on the inherent advantage of the market\ntaker. We introduce the problem setting throughout the diverse domains of stock\ntrading and sports betting to provide insights into the common underlying\nproperties of profitable predictive models, their connections to standard\nportfolio optimization strategies, and the, commonly overlooked, advantage of\nthe market taker. Consequently, we prove desirability of the decorrelation\nobjective across common market distributions, translate the concept into a\npractical machine learning setting, and demonstrate its viability with real\nworld market data.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:20:35 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12509","submitter":"Min-Cheol Kim","authors":"Min-cheol Kim, Namyoung Ahn, Diyi Cheng, Mingjie Xu, Xiaoqing Pan, Suk\n  Jun Kim, Yanqi Luo, David P. Fenning, Darren H. S. Tan, Minghao Zhang,\n  So-Yeon Ham, Kiwan Jeong, Mansoo Choi, Ying Shirley Meng","title":"Imaging real-time amorphization of hybrid perovskite solar cells under\n  electrical biasing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Perovskite solar cells have drawn much attention in recent years, owing to\nits world-record setting photovoltaic performances. Despite its promising use\nin tandem applications and flexible devices, its practicality is still limited\nby its structural instability often arising from ion migration and defect\nformation. While it is generally understood that ion instability is a primary\ncause for degradation, there is still a lack of direct evidence of structural\ntransformation at the atomistic scale. Such an understanding is crucial to\nevaluate and pin-point how such instabilities are induced relative to external\nperturbations such as illumination or electrical bias with time, allowing\nresearchers to devise effective strategies to mitigate them. Here, we designed\nan in-situ TEM setup to enable real-time observation of amorphization in double\ncation mixed perovskite materials under electrical biasing at 1 V. It is found\nthat amorphization occurs along the (001) and (002) planes, which represents\nthe observation of in-situ facet-dependent amorphization of a perovskite\ncrystal. To reverse the degradation, the samples were heated at 50 oC and was\nfound to recrystallize, effectively regaining its performance losses. This work\nis vital toward understanding fundamental ion-migration phenomena and address\ninstability challenges of perovskite optoelectronics.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:21:47 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12510","submitter":"Nafise Sadat Moosavi","authors":"Nafise Sadat Moosavi, Marcel de Boer, Prasetya Ajie Utama, Iryna\n  Gurevych","title":"Improving Robustness by Augmenting Training Sentences with\n  Predicate-Argument Structures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing NLP datasets contain various biases, and models tend to quickly\nlearn those biases, which in turn limits their robustness. Existing approaches\nto improve robustness against dataset biases mostly focus on changing the\ntraining objective so that models learn less from biased examples. Besides,\nthey mostly focus on addressing a specific bias, and while they improve the\nperformance on adversarial evaluation sets of the targeted bias, they may bias\nthe model in other ways, and therefore, hurt the overall robustness. In this\npaper, we propose to augment the input sentences in the training data with\ntheir corresponding predicate-argument structures, which provide a higher-level\nabstraction over different realizations of the same meaning and help the model\nto recognize important parts of sentences. We show that without targeting a\nspecific bias, our sentence augmentation improves the robustness of transformer\nmodels against multiple biases. In addition, we show that models can still be\nvulnerable to the lexical overlap bias, even when the training data does not\ncontain this bias, and that the sentence augmentation also improves the\nrobustness in this scenario. We will release our adversarial datasets to\nevaluate bias in such a scenario as well as our augmentation scripts at\nhttps://github.com/UKPLab/data-augmentation-for-robustness.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:22:05 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12511","submitter":"Claudio Onorati","authors":"Giovanni Mongardi and Claudio Onorati","title":"Birational geometry of irreducible holomorphic symplectic tenfolds of\n  O'Grady type","comments":"Comments are very welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we analyse the birational geometry of O'Grady ten dimensional\nmanifolds, giving a characterisation of Kaehler classes and lagrangian\nfibrations. Moreover, we study symplectic compactifications of intermediate\njacobian fibrations of smooth cubic fourfolds.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:23:51 GMT"},{"version":"v2","created":"Fri, 30 Oct 2020 11:33:33 GMT"}],"update_date":"2020-11-02"}
{"id":"2010.12512","submitter":"Linyi Yang","authors":"Linyi Yang, Eoin M. Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, and\n  Ruihai Dong","title":"Generating Plausible Counterfactual Explanations for Deep Transformers\n  in Financial Text Classification","comments":"Accepted by COLING-20 (Oral)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Corporate mergers and acquisitions (M&A) account for billions of dollars of\ninvestment globally every year, and offer an interesting and challenging domain\nfor artificial intelligence. However, in these highly sensitive domains, it is\ncrucial to not only have a highly robust and accurate model, but be able to\ngenerate useful explanations to garner a user's trust in the automated system.\nRegrettably, the recent research regarding eXplainable AI (XAI) in financial\ntext classification has received little to no attention, and many current\nmethods for generating textual-based explanations result in highly implausible\nexplanations, which damage a user's trust in the system. To address these\nissues, this paper proposes a novel methodology for producing plausible\ncounterfactual explanations, whilst exploring the regularization benefits of\nadversarial training on language models in the domain of FinTech. Exhaustive\nquantitative experiments demonstrate that not only does this approach improve\nthe model accuracy when compared to the current state-of-the-art and human\nperformance, but it also generates counterfactual explanations which are\nsignificantly more plausible based on human trials.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:29:26 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12513","submitter":"Vladimir Dyakonov","authors":"Andreas Gottscholl, Matthias Diez, Victor Soltamov, Christian Kasper,\n  Andreas Sperlich, Mehran Kianinia, Carlo Bradac, Igor Aharonovich, Vladimir\n  Dyakonov","title":"Room Temperature Coherent Control of Spin Defects in hexagonal Boron\n  Nitride","comments":null,"journal-ref":"Science Advances Vol. 7, no. 14, eabf3630 (2021)","doi":"10.1126/sciadv.abf3630","report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Optically active defects in solids with accessible spin states are promising\ncandidates for solid state quantum information and sensing applications. To\nemploy these defects as quantum building blocks, coherent manipulation of their\nspin state is required. Here we realize coherent control of ensembles of boron\nvacancy (V$_B^-$) centers in hexagonal boron nitride (hBN). Specifically, by\napplying pulsed spin resonance protocols, we measure spin-lattice relaxation\ntime ($T_1$) of 18 $\\mu$s and spin coherence time ($T_2$) of 2 $\\mu$s at room\ntemperature. The spin-lattice relaxation time increases by three orders of\nmagnitude at cryogenic temperature. Furthermore, employing a two- and\nthree-pulse electron spin-echo envelope modulation (ESEEM) we separate the\nquadrupole and hyperfine interactions with the surrounding nuclei. Finally, by\napplying a method to decouple the spin state from its inhomogeneous nuclear\nenvironment - a \"hole-burning\" - the spectral optically detected magnetic\nresonance linewidth is significantly reduced to several tens of kHz, thus\nextending the spin coherence time by a factor of three. Our results are\nimportant for employment of van der Waals materials for quantum technologies,\nspecifically in the context of using hBN as a high-resolution quantum sensor\nfor hybrid quantum systems including 2D heterostructures, nanoscale devices and\nemerging atomically thin magnets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:31:37 GMT"}],"update_date":"2021-04-06"}
{"id":"2010.12514","submitter":"James Johndrow","authors":"James E. Johndrow, Natesh S. Pillai, Aaron Smith","title":"No Free Lunch for Approximate MCMC","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.CO math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is widely known that the performance of Markov chain Monte Carlo (MCMC)\ncan degrade quickly when targeting computationally expensive posterior\ndistributions, such as when the sample size is large. This has motivated the\nsearch for MCMC variants that scale well to large datasets. One general\napproach has been to look at only a subsample of the data at every step. In\nthis note, we point out that well-known MCMC convergence results often imply\nthat these \"subsampling\" MCMC algorithms cannot greatly improve performance. We\napply these generic results to realistic statistical problems and proposed\nalgorithms, and also discuss some design principles suggested by the results.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:32:28 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12515","submitter":"Jos\\'e Eduardo Rosales Quintero Dr.","authors":"I. D\\'iaz-Salda\\~na, M. Sabido, J. C. L\\'opez-Dom\\'inguez and J. E.\n  Rosales-Quintero","title":"Comments on the symmetry breaking condition in MacDowell-Mansouri action","comments":"9 pages","journal-ref":null,"doi":"10.1142/S0218271821500656","report-no":null,"categories":"hep-th math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we study the symmetry breaking conditions, given by a (anti)de\nSitter-valued vector field, of a full (anti)de Sitter-invariant\nMacDowell-Mansouri inspired action. We show that under these conditions the\naction breaks down to General Relativity with a cosmological constant, the four\ndimensional topological invariants, as well as the Holst term. We obtain the\nequations of motion of this action, and analyze the symmetry breaking\nconditions.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:33:00 GMT"},{"version":"v2","created":"Thu, 28 Jan 2021 23:20:38 GMT"},{"version":"v3","created":"Tue, 4 May 2021 20:23:53 GMT"}],"update_date":"2021-06-08"}
{"id":"2010.12516","submitter":"Sheng Zhong","authors":"Sheng Zhong (1), Zhenyuan Zhang (1), Nima Fazeli (1), Dmitry Berenson\n  (1) ((1) Robotics Institute, University of Michigan)","title":"TAMPC: A Controller for Escaping Traps in Novel Environments","comments":"8 pages, 7 figures (excluding tables and algorithms), 4 tables, 4\n  algorithms, accepted to RA-L, preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an approach to online model adaptation and control in the\nchallenging case of hybrid and discontinuous dynamics where actions may lead to\ndifficult-to-escape \"trap\" states, under a given controller. We first learn\ndynamics for a system without traps from a randomly collected training set\n(since we do not know what traps will be encountered online). These \"nominal\"\ndynamics allow us to perform tasks in scenarios where the dynamics matches the\ntraining data, but when unexpected traps arise in execution, we must find a way\nto adapt our dynamics and control strategy and continue attempting the task.\nOur approach, Trap-Aware Model Predictive Control (TAMPC), is a two-level\nhierarchical control algorithm that reasons about traps and non-nominal\ndynamics to decide between goal-seeking and recovery policies. An important\nrequirement of our method is the ability to recognize nominal dynamics even\nwhen we encounter data that is out-of-distribution w.r.t the training data. We\nachieve this by learning a representation for dynamics that exploits invariance\nin the nominal environment, thus allowing better generalization. We evaluate\nour method on simulated planar pushing and peg-in-hole as well as real robot\npeg-in-hole problems against adaptive control, reinforcement learning,\ntrap-handling baselines, where traps arise due to unexpected obstacles that we\nonly observe through contact. Our results show that our method outperforms the\nbaselines on difficult tasks, and is comparable to prior trap-handling methods\non easier tasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:33:15 GMT"},{"version":"v2","created":"Tue, 12 Jan 2021 17:22:00 GMT"},{"version":"v3","created":"Wed, 3 Feb 2021 18:22:05 GMT"}],"update_date":"2021-02-04"}
{"id":"2010.12517","submitter":"Amir H. Safavi-Naeini","authors":"Christopher J. Sarabalis, Rapha\\\"el Van Laer, Rishi N. Patel, Yanni D.\n  Dahmani, Wentao Jiang, Felix M. Mayor, Amir H. Safavi-Naeini","title":"Acousto-optic modulation of a wavelength-scale waveguide","comments":"14 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate a collinear acousto-optic modulator in a suspended film of\nlithium niobate employing a high-confinement, wavelength-scale waveguide. By\nstrongly confining the optical and mechanical waves, this modulator improves by\norders of magnitude a figure-of-merit that accounts for both acousto-optic and\nelectro-mechanical efficiency. Our device demonstration marks a significant\ntechnological advance in acousto-optics that promises a novel class of compact\nand low-power frequency shifters, tunable filters, non-magnetic isolators, and\nbeam deflectors.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:34:20 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12518","submitter":"Lars Zurek","authors":"L. Zurek, E. A. Coello P\\'erez, S. K. Bogner, R. J. Furnstahl, A.\n  Schwenk","title":"Comparing different density-matrix expansions for long-range pion\n  exchange","comments":"21 pages, 15 figures, including Supplemental Material, published\n  version","journal-ref":"Phys. Rev. C 103, 014325 (2021)","doi":"10.1103/PhysRevC.103.014325","report-no":null,"categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Empirical energy density functionals (EDFs) are generally successful in\ndescribing nuclear properties across the table of nuclides. But their\nlimitations motivate using the density-matrix expansion (DME) to embed\nlong-range pion interactions into a Skyrme functional. Recent results on the\nimpact of the pion were both encouraging and puzzling, necessitating a careful\nre-examination of the DME implementation. Here we take the first steps,\nfocusing on two-body scalar terms in the DME. Exchange energies with long-range\none-pion contributions are well approximated by all DME implementations\nconsidered, with preference for variants that do not truncate at two\nderivatives in every EDF term. The use of the DME for chiral pion contributions\nis therefore supported by this investigation. For scalar-isovector energies it\nis important to treat neutrons and protons separately. The results are found to\napply under broad conditions, although self-consistency is not yet tested.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:35:22 GMT"},{"version":"v2","created":"Fri, 5 Feb 2021 18:05:09 GMT"}],"update_date":"2021-02-08"}
{"id":"2010.12519","submitter":"Mustapha Ishak","authors":"Cristhian Garcia-Quintero, Mustapha Ishak, Orion Ning","title":"Current constraints on deviations from General Relativity using binning\n  in redshift and scale","comments":"22 pages, 7 figures","journal-ref":"JCAP 2012:018, 2020","doi":"10.1088/1475-7516/2020/12/018","report-no":null,"categories":"astro-ph.CO gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We constrain deviations from general relativity (GR) including both redshift\nand scale dependencies in the modified gravity (MG) parameters. In particular,\nwe employ the under-used binning approach and compare the results to functional\nforms. We use available datasets such as Cosmic Microwave Background (CMB) from\nPlanck 2018, Baryonic Acoustic Oscillations (BAO) and Redshift Space\nDistortions (BAO/RSD) from the BOSS DR12, the 6DF Galaxy Survey, the SDSS DR7\nMain Galaxy Sample, the correlation of Lyman-$\\alpha$ forest absorption and\nquasars from SDSS-DR14, Supernova Type Ia (SNe) from the Pantheon compilation,\nand DES Y1 data. Moreover, in order to maximize the constraining power from\navailable datasets, we analyze MG models where we alternatively set some of the\nMG parameters to their GR values and vary the others. Using functional forms,\nwe find an up to 3.5-$\\sigma$ tension with GR in $\\Sigma$ (while $\\mu$ is\nfixed) when using Planck+SNe+BAO+RSD; this goes away when lensing data is\nincluded, i.e. CMB lensing and DES (CMBL+DES). Using different binning methods,\nwe find that a tension with GR above 2-$\\sigma$ in the (high-z, high-k) bin is\npersistent even when including CMBL+DES to Planck+SNe+BAO+RSD. Also, we find\nanother tension above 2-$\\sigma$ in the (low-z, high-k) bin, but that can be\nreduced with the addition of lensing data. Furthermore, we perform a model\ncomparison using the Deviance Information Criterion statistical tool and find\nthat the MG model ($\\mu=1$, $\\Sigma$) is weakly favored by the data compared to\n$\\Lambda$CDM, except when DES data is included. Another noteworthy result is\nthat we find that the binning methods do not agree with the widely-used\nfunctional parameterization where the MG parameters are proportional to\n$\\Omega_{\\text{DE}}(a)$, and this is clearly apparent in the high-z and high-k\nregime where this parameterization underestimates the deviations from GR.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:35:36 GMT"}],"update_date":"2022-04-18"}
{"id":"2010.12520","submitter":"Christopher Lee","authors":"Christopher Lee, James Hogan","title":"Automated crater detection with human level performance","comments":"18 pages, 6 figures, 1 table. In press at Computers & Geosciences","journal-ref":null,"doi":"10.1016/j.cageo.2020.104645","report-no":null,"categories":"astro-ph.EP cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Crater cataloging is an important yet time-consuming part of geological\nmapping. We present an automated Crater Detection Algorithm (CDA) that is\ncompetitive with expert-human researchers and hundreds of times faster. The CDA\nuses multiple neural networks to process digital terrain model and thermal\ninfra-red imagery to identify and locate craters across the surface of Mars. We\nuse additional post-processing filters to refine and remove potential false\ncrater detections, improving our precision and recall by 10% compared to Lee\n(2019). We now find 80% of known craters above 3km in diameter, and identify\n7,000 potentially new craters (13% of the identified craters). The median\ndifferences between our catalog and other independent catalogs is 2-4% in\nlocation and diameter, in-line with other inter-catalog comparisons. The CDA\nhas been used to process global terrain maps and infra-red imagery for Mars,\nand the software and generated global catalog are available at\nhttps://doi.org/10.5683/SP2/CFUNII.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:36:31 GMT"},{"version":"v2","created":"Wed, 18 Nov 2020 05:20:47 GMT"}],"update_date":"2020-11-19"}
{"id":"2010.12521","submitter":"Luca Merlo","authors":"Antonello Maruotti, Luca Merlo and Lea Petrella","title":"A two-part finite mixture quantile regression model for semi-continuous\n  longitudinal data","comments":null,"journal-ref":"Statistical Modelling (2021): 1471082X21993603","doi":"10.1177/1471082X21993603","report-no":null,"categories":"stat.ME stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper develops a two-part finite mixture quantile regression model for\nsemi-continuous longitudinal data. The proposed methodology allows\nheterogeneity sources that influence the model for the binary response\nvariable, to influence also the distribution of the positive outcomes. As is\ncommon in the quantile regression literature, estimation and inference on the\nmodel parameters are based on the Asymmetric Laplace distribution. Maximum\nlikelihood estimates are obtained through the EM algorithm without parametric\nassumptions on the random effects distribution. In addition, a penalized\nversion of the EM algorithm is presented to tackle the problem of variable\nselection. The proposed statistical method is applied to the well-known RAND\nHealth Insurance Experiment dataset which gives further insights on its\nempirical behavior.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:37:08 GMT"}],"update_date":"2021-07-19"}
{"id":"2010.12522","submitter":"Christophe Ley","authors":"Fatemeh Ghaderinezhad, Christophe Ley and Ben Serrien","title":"The Wasserstein Impact Measure (WIM): a generally applicable, practical\n  tool for quantifying prior impact in Bayesian statistics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The prior distribution is a crucial building block in Bayesian analysis, and\nits choice will impact the subsequent inference. It is therefore important to\nhave a convenient way to quantify this impact, as such a measure of prior\nimpact will help us to choose between two or more priors in a given situation.\nA recently proposed approach consists in determining the Wasserstein distance\nbetween posteriors resulting from two distinct priors, revealing how close or\ndistant they are. In particular, if one prior is the uniform/flat prior, this\ndistance leads to a genuine measure of prior impact for the other prior. While\nhighly appealing and successful from a theoretical viewpoint, this proposal\nsuffers from practical limitations: it requires prior distributions to be\nnested, posterior distributions should not be of a too complex form, in most\nconsidered settings the exact distance was not computed but sharp upper and\nlower bounds were proposed, and the proposal so far is restricted to scalar\nparameter settings. In this paper, we overcome all these limitations by\nintroducing a practical version of this theoretical approach, namely the\nWasserstein Impact Measure (WIM). In three simulated scenarios, we will compare\nthe WIM to the theoretical Wasserstein approach, as well as to two competitor\nprior impact measures from the literature. We finally illustrate the\nversatility of the WIM by applying it on two datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:42:35 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12523","submitter":"Yinfei Yang","authors":"Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, Yinfei Yang","title":"Neural Passage Retrieval with Improved Negative Contrast","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we explore the effects of negative sampling in dual encoder\nmodels used to retrieve passages for automatic question answering. We explore\nfour negative sampling strategies that complement the straightforward random\nsampling of negatives, typically used to train dual encoder models. Out of the\nfour strategies, three are based on retrieval and one on heuristics. Our\nretrieval-based strategies are based on the semantic similarity and the lexical\noverlap between questions and passages. We train the dual encoder models in two\nstages: pre-training with synthetic data and fine tuning with domain-specific\ndata. We apply negative sampling to both stages. The approach is evaluated in\ntwo passage retrieval tasks. Even though it is not evident that there is one\nsingle sampling strategy that works best in all the tasks, it is clear that our\nstrategies contribute to improving the contrast between the response and all\nthe other passages. Furthermore, mixing the negatives from different strategies\nachieve performance on par with the best performing strategy in all tasks. Our\nresults establish a new state-of-the-art level of performance on two of the\nopen-domain question answering datasets that we evaluated.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:45:06 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12524","submitter":"Xinliang An","authors":"Xinliang An, Qing Han","title":"Anisotropic Dynamical Horizons Arising in Gravitational Collapse","comments":"54 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc math-ph math.AP math.DG math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For the study of $3+1$ dimensional Einstein vacuum equations (EVEs),\nsubstantial progress has been made recently on the problem of trapped surface\nformation. However, very limited knowledge of existence and associated\nproperties is acquired on the boundary of the emerged trapped region, i.e., the\napparent horizon, which is composed of marginally outer trapped surfaces\n(MOTSs) and is of great physical importance. In this paper, concerning this\nemerged apparent horizon we prove a folklore conjecture relating to both cosmic\ncensorship and black hole thermodynamics. In a framework set up by\nChristodoulou and under a general anisotropic condition introduced by\nKlainerman, Luk and Rodnianski, for $3+1$ EVEs we prove that in the process of\ngravitational collapse, a smooth and spacelike apparent horizon (dynamical\nhorizon) emerges from general (both isotropic and anisotropic) initial data.\nThis dynamical horizon censors singularities formed in gravitational collapse\nfrom non-trapped local observers near the center, and it also enables the\nextension of black hole thermodynamical theory along the apparent horizon to\nanisotropic scenarios. Our analysis builds on scale-critical hyperbolic method\nand non-perturbative elliptic techniques. New observations and equation\nstructures are exploited. Geometrically, we furthermore construct explicit\nfinger-type single and multi-valley anisotropic apparent horizons. They are the\nfirst mathematical examples of the anisotropic MOTS and the anisotropic\napparent horizon formed in dynamics, which have potential applications in\ngeometric analysis, black hole mechanics, numerical relativity and\ngravitational wave phenomenology.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:46:46 GMT"},{"version":"v2","created":"Wed, 5 May 2021 03:03:15 GMT"}],"update_date":"2021-05-06"}
{"id":"2010.12525","submitter":"Duo Xu","authors":"Duo Xu, Stella S. R. Offner, Robert Gutermuth, Colin Van Oort","title":"Application of Convolutional Neural Networks to Identify Protostellar\n  Outflows in CO Emission","comments":"Revised version submitted to ApJ, comments welcome","journal-ref":null,"doi":"10.3847/1538-4357/abc7bf","report-no":null,"categories":"astro-ph.GA astro-ph.IM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We adopt the deep learning method CASI-3D (Convolutional Approach to\nStructure Identification-3D) to identify protostellar outflows in molecular\nline spectra. We conduct magneto-hydrodynamics simulations that model forming\nstars that launch protostellar outflows and use these to generate synthetic\nobservations. We apply the 3D radiation transfer code RADMC-3D to model 12CO\n(J=1-0) line emission from the simulated clouds. We train two CASI-3D models:\nME1 is trained to predict only the position of outflows, while MF is trained to\npredict the fraction of the mass coming from outflows in each voxel. The two\nmodels successfully identify all 60 previously visually identified outflows in\nPerseus. Additionally, CASI-3D finds 20 new high-confidence outflows. All of\nthese have coherent high-velocity structures, and 17 of them have nearby young\nstellar objects, while the remaining three are outside the Spitzer survey\ncoverage. The mass, momentum and energy of individual outflows in Perseus\npredicted by model MF is comparable to the previous estimations. This\nsimilarity is due to a cancelation in errors: previous calculations missed\noutflow material with velocities comparable to the cloud velocity, however,\nthey compensate for this by over-estimating the amount of mass at higher\nvelocities that has contamination from non-outflow gas. We show outflows likely\ndriven by older sources have more high-velocity gas compared to those driven by\nyounger sources.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:48:47 GMT"}],"update_date":"2021-01-06"}
{"id":"2010.12526","submitter":"Mark Schlutow","authors":"Mark Schlutow and Georg S. V\\\"olker","title":"On strongly nonlinear gravity waves in a vertically sheared atmosphere,\n  Part I: Spectral stability of the refracted wave","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn physics.geo-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate strongly nonlinear stationary gravity waves which experience\nrefraction due to a thin vertical shear layer of horizontal background wind.\nThe velocity amplitude of the waves is of the same order of magnitude as the\nbackground flow and hence the self-induced mean flow alters the modulation\nproperties to leading order. In this theoretical study, we show that the\nstability of such a refracted wave depends on the classical modulation\nstability criterion for each individual layer, above and below the shearing.\nAdditionally, the stability is conditioned by novel instability criteria\nproviding bounds on the mean-flow horizontal wind and the amplitude of the\nwave. A necessary condition for instability is that the mean-flow horizontal\nwind in the upper layer is stronger than the wind in the lower layer.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:49:27 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12527","submitter":"Peng Qi","authors":"Peng Qi, Haejun Lee, Oghenetegiri \"TG\" Sido, Christopher D. Manning","title":"Answering Open-Domain Questions of Varying Reasoning Steps from Text","comments":"EMNLP 2021. Peng Qi, Haejun Lee, and TG Sido contributed equally","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We develop a unified system to answer directly from text open-domain\nquestions that may require a varying number of retrieval steps. We employ a\nsingle multi-task transformer model to perform all the necessary subtasks --\nretrieving supporting facts, reranking them, and predicting the answer from all\nretrieved documents -- in an iterative fashion. We avoid crucial assumptions of\nprevious work that do not transfer well to real-world settings, including\nexploiting knowledge of the fixed number of retrieval steps required to answer\neach question or using structured metadata like knowledge bases or web links\nthat have limited availability. Instead, we design a system that can answer\nopen-domain questions on any text collection without prior knowledge of\nreasoning complexity. To emulate this setting, we construct a new benchmark,\ncalled BeerQA, by combining existing one- and two-step datasets with a new\ncollection of 530 questions that require three Wikipedia pages to answer,\nunifying Wikipedia corpora versions in the process. We show that our model\ndemonstrates competitive performance on both existing benchmarks and this new\nbenchmark. We make the new benchmark available at https://beerqa.github.io/.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:51:09 GMT"},{"version":"v2","created":"Thu, 15 Apr 2021 16:39:47 GMT"},{"version":"v3","created":"Fri, 16 Apr 2021 16:48:50 GMT"},{"version":"v4","created":"Fri, 29 Oct 2021 15:12:46 GMT"}],"update_date":"2021-11-01"}
{"id":"2010.12528","submitter":"Leonid Dworzanski W","authors":"Leonid W. Dworzanski","title":"Towards Dynamic-Point Systems on Metric Graphs with Longest\n  Stabilization Time","comments":"15 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DM math-ph math.DS math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A dynamical system of points moving along the edges of a graph could be\nconsidered as a geometrical discrete dynamical system or as a discrete version\nof a quantum graph with localized wave packets. We study the set of such\nsystems over metric graphs that can be constructed from a given set of\ncommensurable edges with fixed lengths. It is shown that there always exists a\nsystem consisting of a bead graph with vertex degrees not greater than three\nthat demonstrates the longest stabilization time in such a set. The results are\nextended to graphs with incommensurable edges using the notion of\n$\\varepsilon$-nets and, also, it is shown that dynamical systems of points on\nlinear graphs have the slowest growth of the number of dynamic points\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:53:34 GMT"},{"version":"v2","created":"Wed, 11 Nov 2020 06:25:26 GMT"},{"version":"v3","created":"Sun, 9 Jan 2022 08:03:11 GMT"}],"update_date":"2022-01-11"}
{"id":"2010.12529","submitter":"Luana Ruiz","authors":"Luana Ruiz, Zhiyang Wang, Alejandro Ribeiro","title":"Graph and graphon neural network stability","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph neural networks (GNNs) are learning architectures that rely on\nknowledge of the graph structure to generate meaningful representations of\nlarge-scale network data. GNN stability is thus important as in real-world\nscenarios there are typically uncertainties associated with the graph. We\nanalyze GNN stability using kernel objects called graphons. Graphons are both\nlimits of convergent graph sequences and generating models for deterministic\nand stochastic graphs. Building upon the theory of graphon signal processing,\nwe define graphon neural networks and analyze their stability to graphon\nperturbations. We then extend this analysis by interpreting the graphon neural\nnetwork as a generating model for GNNs on deterministic and stochastic graphs\ninstantiated from the original and perturbed graphons. We observe that GNNs are\nstable to graphon perturbations with a stability bound that decreases\nasymptotically with the size of the graph. This asymptotic behavior is further\ndemonstrated in an experiment of movie recommendation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:55:56 GMT"},{"version":"v2","created":"Mon, 9 Nov 2020 22:30:48 GMT"},{"version":"v3","created":"Mon, 8 Feb 2021 22:32:16 GMT"},{"version":"v4","created":"Mon, 26 Apr 2021 15:47:35 GMT"}],"update_date":"2021-04-27"}
{"id":"2010.12530","submitter":"Davide Marenduzzo","authors":"C. A. Brackley, A. Lips, A. Morozov, W. C. K. Poon, D. Marenduzzo","title":"Electrostatic inactivation of RNA viruses at air-water and liquid-liquid\n  interfaces","comments":"10 pages, 5 figures; minor corrections to the Appendix","journal-ref":null,"doi":"10.1038/s41467-021-27052-7","report-no":null,"categories":"cond-mat.soft physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Understanding the interactions between viruses and surfaces or interfaces is\nimportant, as they provide the principles underpinning the cleaning and\ndisinfection of contaminated surfaces. Yet, the physics of such interactions is\ncurrently poorly understood. For instance, there are longstanding experimental\nobservations suggesting that the presence of air-water interfaces can\ngenerically inactivate and kill viruses, yet the mechanism underlying this\nphenomenon remains unknown. Here we use theory and simulations to show that\nelectrostatics provides one such mechanism, and that this is very general.\nThus, we predict that the free energy of an RNA virus should increase by\nseveral thousands of $k_BT$ as the virion breaches an air-water interface. We\nalso show that the fate of a virus approaching a generic liquid-liquid\ninterface depends strongly on the detailed balance between interfacial and\nelectrostatic forces, which can be tuned, for instance, by choosing different\nmedia to contact a virus-laden respiratory droplet. We propose that these\nresults can be used to design effective strategies for surface disinfection.\nIntriguingly, tunability requires electrostatic and interfacial forces to scale\nsimilarly with viral size, which naturally occurs when charges are arranged in\na double-shell distribution as in RNA viruses like influenza and all\ncoronaviruses.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:58:14 GMT"},{"version":"v2","created":"Tue, 15 Dec 2020 12:44:39 GMT"}],"update_date":"2022-01-19"}
{"id":"2010.12531","submitter":"Youngho Jung","authors":"Youngho Jung, Junho Jeong, Zhongnan Qu, Bin Cui, Ankita Khanda, Stuart\n  S. P. Parkin, Joyce K. S. Poon","title":"Observation of photoelectric nonvolatile memory and oscillations in VO2\n  at room temperature","comments":"31 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vanadium dioxide (VO2) is a phase change material that can reversibly change\nbetween high and low resistivity states through electronic and structural phase\ntransitions. Thus far, VO2 memory devices have essentially been volatile at\nroom temperature, and nonvolatile memory has required non-ambient surroundings\n(e.g., elevated temperatures, electrolytes) and long write times. Here, we\nreport the first observation of optically addressable nonvolatile memory in VO2\nat room temperature with a readout by voltage oscillations. The read and write\ntimes had to be kept shorter than about 150 {\\mu}s. The writing of the memory\nand onset of the voltage oscillations had a minimum optical power threshold.\nThis discovery demonstrates the potential of VO2 for new computing devices and\narchitectures, such as artificial neurons and oscillatory neural networks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:58:53 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12532","submitter":"Nicole Peinelt","authors":"Nicole Peinelt, Marek Rei and Maria Liakata","title":"GiBERT: Introducing Linguistic Knowledge into BERT through a Lightweight\n  Gated Injection Method","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large pre-trained language models such as BERT have been the driving force\nbehind recent improvements across many NLP tasks. However, BERT is only trained\nto predict missing words - either behind masks or in the next sentence - and\nhas no knowledge of lexical, syntactic or semantic information beyond what it\npicks up through unsupervised pre-training. We propose a novel method to\nexplicitly inject linguistic knowledge in the form of word embeddings into any\nlayer of a pre-trained BERT. Our performance improvements on multiple semantic\nsimilarity datasets when injecting dependency-based and counter-fitted\nembeddings indicate that such information is beneficial and currently missing\nfrom the original model. Our qualitative analysis shows that counter-fitted\nembedding injection particularly helps with cases involving synonym pairs.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:00:26 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12534","submitter":"Valentino Vito","authors":"Valentino Vito","title":"Some notes on diagram chasing and diagrammatic proofs in category theory","comments":"20 pages, 10 exercises, no figures. Corrected typos","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diagram chasing is a customary proof method used in category theory and\nhomological algebra. It involves an element-theoretic approach to show that\ncertain properties hold for a commutative diagram. When dealing with abelian\ncategories for the first time, one would work using a diagrammatic approach\nwithout relying on the notion of elements. However, constantly manipulating\nuniversal properties of various diagrams can be quite cumbersome. That said, we\nbelieve that it is still important to draw a contrast between both viewpoints\nin order to motivate the field of category theory. We focus our scope to the\nshort five lemma, one of the more elementary diagram lemmas, and present a\nquick exposition on relevant subjects. Moreover, we give an original proof of\nthe short five lemma using the universal property of pullbacks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:03:24 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 14:08:21 GMT"}],"update_date":"2020-10-29"}
{"id":"2010.12535","submitter":"Tim Coopmans","authors":"Tim Coopmans, Robert Knegjens, Axel Dahlberg, David Maier, Loek\n  Nijsten, Julio de Oliveira Filho, Martijn Papendrecht, Julian Rabbie, Filip\n  Rozp\\k{e}dek, Matthew Skrzypczyk, Leon Wubben, Walter de Jong, Damian\n  Podareanu, Ariana Torres-Knoop, David Elkouss, Stephanie Wehner","title":"NetSquid, a NETwork Simulator for QUantum Information using Discrete\n  events","comments":"NetSquid is freely available at https://netsquid.org; refined main\n  text sections","journal-ref":"Commun Phys 4, 164 (2021)","doi":"10.1038/s42005-021-00647-8","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In order to bring quantum networks into the real world, we would like to\ndetermine the requirements of quantum network protocols including the\nunderlying quantum hardware. Because detailed architecture proposals are\ngenerally too complex for mathematical analysis, it is natural to employ\nnumerical simulation. Here we introduce NetSquid, the NETwork Simulator for\nQUantum Information using Discrete events, a discrete-event based platform for\nsimulating all aspects of quantum networks and modular quantum computing\nsystems, ranging from the physical layer and its control plane up to the\napplication level. We study several use cases to showcase NetSquid's power,\nincluding detailed physical layer simulations of repeater chains based on\nnitrogen vacancy centres in diamond as well as atomic ensembles. We also study\nthe control plane of a quantum switch beyond its analytically known regime, and\nshowcase NetSquid's ability to investigate large networks by simulating\nentanglement distribution over a chain of up to one thousand nodes.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:04:35 GMT"},{"version":"v2","created":"Fri, 15 Jan 2021 13:54:46 GMT"},{"version":"v3","created":"Mon, 26 Jul 2021 10:15:44 GMT"}],"update_date":"2021-07-27"}
{"id":"2010.12536","submitter":"Nasim Rahaman","authors":"Yoshua Bengio, Prateek Gupta, Tegan Maharaj, Nasim Rahaman, Martin\n  Weiss, Tristan Deleu, Eilif Muller, Meng Qu, Victor Schmidt, Pierre-Luc\n  St-Charles, Hannah Alsdurf, Olexa Bilanuik, David Buckeridge, G\\'aetan\n  Marceau Caron, Pierre-Luc Carrier, Joumana Ghosn, Satya Ortiz-Gagne, Chris\n  Pal, Irina Rish, Bernhard Sch\\\"olkopf, Abhinav Sharma, Jian Tang, Andrew\n  Williams","title":"Predicting Infectiousness for Proactive Contact Tracing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.MA cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual\ncontact tracing in many countries and resulting in widespread lockdowns for\nemergency containment. Large-scale digital contact tracing (DCT) has emerged as\na potential solution to resume economic and social activity while minimizing\nspread of the virus. Various DCT methods have been proposed, each making\ntrade-offs between privacy, mobility restrictions, and public health. The most\ncommon approach, binary contact tracing (BCT), models infection as a binary\nevent, informed only by an individual's test results, with corresponding binary\nrecommendations that either all or none of the individual's contacts\nquarantine. BCT ignores the inherent uncertainty in contacts and the infection\nprocess, which could be used to tailor messaging to high-risk individuals, and\nprompt proactive testing or earlier warnings. It also does not make use of\nobservations such as symptoms or pre-existing medical conditions, which could\nbe used to make more accurate infectiousness predictions. In this paper, we use\na recently-proposed COVID-19 epidemiological simulator to develop and test\nmethods that can be deployed to a smartphone to locally and proactively predict\nan individual's infectiousness (risk of infecting others) based on their\ncontact history and other information, while respecting strong privacy\nconstraints. Predictions are used to provide personalized recommendations to\nthe individual via an app, as well as to send anonymized messages to the\nindividual's contacts, who use this information to better predict their own\ninfectiousness, an approach we call proactive contact tracing (PCT). We find a\ndeep-learning based PCT method which improves over BCT for equivalent average\nmobility, suggesting PCT could help in safe re-opening and second-wave\nprevention.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:06:07 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12542","submitter":"Yiping Ma","authors":"Y.-P. Ma and H. Susanto","title":"Topological edge solitons and their stability in a nonlinear\n  Su-Schrieffer-Heeger model","comments":"7 pages, 6 figures; accepted version in Physical Review E after\n  addressing referee comments","journal-ref":"Phys. Rev. E 104, 054206 (2021)","doi":"10.1103/PhysRevE.104.054206","report-no":null,"categories":"nlin.PS cond-mat.mes-hall math.DS physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study continuations of topological edge states in the Su-Schrieffer-Heeger\nmodel with on-site cubic (Kerr) nonlinearity, which is a 1D nonlinear photonic\ntopological insulator (TI). Based on the topology of the underlying spatial\ndynamical system, we establish the existence of nonlinear edge states (edge\nsolitons) for all positive energies in the topological band gap. We discover\nthat these edge solitons are stable at any energy when the ratio between the\nweak and strong couplings is below a critical value. Above the critical\ncoupling ratio, there are energy intervals where the edge solitons experience\nan oscillatory instability. Though our paper focuses on a photonic system, we\nalso discuss the broader relevance of our methods and results to 1D nonlinear\nmechanical TIs.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:09:40 GMT"},{"version":"v2","created":"Sat, 25 Dec 2021 16:33:12 GMT"}],"update_date":"2021-12-28"}
{"id":"2010.12543","submitter":"Diluka Galappaththige","authors":"Diluka Loku Galappaththige, Dhanushka Kudathanthirige, Gayan\n  Amarasuriya Aruma Baduge","title":"Performance Analysis of Distributed Intelligent Reflective Surfaces for\n  Wireless Communications","comments":"31 pages, 10 Figures, Journal version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  In this paper, a comprehensive performance analysis of a distributed\nintelligent reflective surfaces (IRSs)-aided communication system is presented.\nFirst, the optimal signal-to-noise ratio (SNR), which is attainable through the\ndirect and reflected channels, is quantified by controlling the phase shifts of\nthe distributed IRS. Next, this optimal SNR is statistically characterized by\nderiving tight approximations to the exact probability density function (PDF)\nand cumulative distribution function (CDF) for Nakagami-$m$ fading. The\naccuracy/tightness of this statistical characterization is investigated by\nderiving the Kullback-Leibler divergence. Our PDF/CDF analysis is used to\nderive tight approximations/bounds for the outage probability, achievable rate,\nand average symbol error rate (SER) in closed-form. To obtain useful insights,\nthe asymptotic outage probability and average SER are derived for the high SNR\nregime. Thereby, the achievable diversity order and array gains are quantified.\nOur asymptotic performance analysis reveals that the diversity order can be\nboosted by using distributed passive IRSs without generating additional\nelectromagnetic (EM) waves via active radio frequency chains. Our asymptotic\nrate analysis shows that the lower and upper rate bounds converge to an\nasymptotic limit in large reflective element regime. Our analysis is validated\nvia Monte-Carlo simulations. We present a rigorous set of numerical results to\ninvestigate the performance gains of the proposed system model. Our analytical\nand numerical results reveal that the performance of single-input single-output\nwireless systems can be boosted by recycling the EM waves generated by a\ntransmitter through distributed passive IRS reflections to enable constructive\nsignal combining at a receiver.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:10:02 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 17:17:55 GMT"},{"version":"v3","created":"Wed, 9 Feb 2022 05:23:34 GMT"}],"update_date":"2022-02-10"}
{"id":"2010.12544","submitter":"Dulaj Gunasinghe","authors":"Dulaj Gunasinghe, Dhanushka Kudathanthirige, Gayan Amarasuriya Aruma\n  Baduge","title":"Performance Analysis of Intelligent Reflective Surface Aided Wireless\n  Communications","comments":"30 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The fundamental performance metrics of an intelligent reflective surface\n(IRS)-aided wireless system are presented. By optimizing the IRS phase-shift\nmatrix, the received signal-to-noise ratio (SNR) is maximized at the\ndestination in the presence of both reflected and direct channels. The\nprobability distributions of this maximum SNR are tightly approximated for the\nmoderate-to-large reflective element regime. Thereby, the probability density\nfunction and cumulative distribution function of this tight SNR approximation\nare derived in closed-form for Nakagami-m fading to facilitate a statistical\ncharacterization of the performance metrics. The outage probability, average\nsymbol error probability, and achievable rate bounds are derived. By virtue of\nan asymptotic analysis in the high SNR regime, the diversity order is\nquantified. Thereby, we reveal that the overall diversity order can be scaled\nas a function of the number of reflective elements (N) such that Gd = mv +\nmin(mg;mh)N, where mv, mh and mg are the Nakagami-m parameters of the direct,\nsource-to-IRS and IRS-to-destination channels, respectively. The asymptotic\nachievable rate is derived, and thereby, it is shown that the transmit power\ncan be scaled inversely proportional to N2. The impact of quantized IRS\nphase-shifts is investigated by deriving the achievable rate bounds. Useful\ninsights are obtained by analyzing the system performance for different\nseverity of fading cases including spatially correlated fading. Our analysis\nand numerical results reveal that IRS is a promising technology for boosting\nthe performance of wireless communications by intelligently controlling the\npropagation channels without employing additional active radio-frequency\nchains.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:10:29 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12545","submitter":"Thomas Holt","authors":"Tom Holt, Weiyi Zhang","title":"Almost K\\\"ahler Kodaira-Spencer problem","comments":"12 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG math.AP math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the almost complex Hodge number $h^{0,1}$ varies with different\nchoices of almost K\\\"ahler metrics. This answers the almost K\\\"ahler version of\na question of Kodaira and Spencer.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:12:41 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12546","submitter":"Erdem Koyuncu","authors":"Erdem Koyuncu","title":"Quantizing Multiple Sources to a Common Cluster Center: An Asymptotic\n  Analysis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.IT math.IT stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider quantizing an $Ld$-dimensional sample, which is obtained by\nconcatenating $L$ vectors from datasets of $d$-dimensional vectors, to a\n$d$-dimensional cluster center. The distortion measure is the weighted sum of\n$r$th powers of the distances between the cluster center and the samples. For\n$L=1$, one recovers the ordinary center based clustering formulation. The\ngeneral case $L>1$ appears when one wishes to cluster a dataset through $L$\nnoisy observations of each of its members. We find a formula for the average\ndistortion performance in the asymptotic regime where the number of cluster\ncenters are large. We also provide an algorithm to numerically optimize the\ncluster centers and verify our analytical results on real and artificial\ndatasets. In terms of faithfulness to the original (noiseless) dataset, our\nclustering approach outperforms the naive approach that relies on quantizing\nthe $Ld$-dimensional noisy observation vectors to $Ld$-dimensional centers.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:14:28 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12547","submitter":"Lin Pan","authors":"Lin Pan, Chung-Wei Hang, Haode Qi, Abhishek Shah, Saloni Potdar, Mo Yu","title":"Multilingual BERT Post-Pretraining Alignment","comments":"Accepted at NAACL2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a simple method to align multilingual contextual embeddings as a\npost-pretraining step for improved zero-shot cross-lingual transferability of\nthe pretrained models. Using parallel data, our method aligns embeddings on the\nword level through the recently proposed Translation Language Modeling\nobjective as well as on the sentence level via contrastive learning and random\ninput shuffling. We also perform sentence-level code-switching with English\nwhen finetuning on downstream tasks. On XNLI, our best model (initialized from\nmBERT) improves over mBERT by 4.7% in the zero-shot setting and achieves\ncomparable result to XLM for translate-train while using less than 18% of the\nsame parallel data and 31% less model parameters. On MLQA, our model\noutperforms XLM-R_Base that has 57% more parameters than ours.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:14:41 GMT"},{"version":"v2","created":"Sat, 10 Apr 2021 15:24:26 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12548","submitter":"Eleni Tzirita Zacharatou","authors":"Eleni Tzirita Zacharatou, Andreas Kipf, Ibrahim Sabek, Varun Pandey,\n  Harish Doraiswamy, Volker Markl","title":"The Case for Distance-Bounded Spatial Approximations","comments":"11th Annual Conference on Innovative Data Systems Research (CIDR'21)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spatial approximations have been traditionally used in spatial databases to\naccelerate the processing of complex geometric operations. However,\napproximations are typically only used in a first filtering step to determine a\nset of candidate spatial objects that may fulfill the query condition. To\nprovide accurate results, the exact geometries of the candidate objects are\ntested against the query condition, which is typically an expensive operation.\nNevertheless, many emerging applications (e.g., visualization tools) require\ninteractive responses, while only needing approximate results. Besides,\nreal-world geospatial data is inherently imprecise, which makes exact data\nprocessing unnecessary. Given the uncertainty associated with spatial data and\nthe relaxed precision requirements of many applications, this vision paper\nadvocates for approximate spatial data processing techniques that omit exact\ngeometric tests and provide final answers solely on the basis of (fine-grained)\napproximations. Thanks to recent hardware advances, this vision can be realized\ntoday. Furthermore, our approximate techniques employ a distance-based error\nbound, i.e., a bound on the maximum spatial distance between false (or missing)\nand exact results which is crucial for meaningful analyses. This bound allows\nto control the precision of the approximation and trade accuracy for\nperformance.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:16:46 GMT"},{"version":"v2","created":"Thu, 21 Jan 2021 16:53:41 GMT"}],"update_date":"2021-01-22"}
{"id":"2010.12549","submitter":"Sebastian Szybka","authors":"Sebastian J. Szybka and Syed U. Naqvi","title":"Freely falling bodies in a standing-wave spacetime","comments":"23 pages, 8 figures; minor changes to match published version","journal-ref":"Phys. Rev. D 103, 024011 (2021)","doi":"10.1103/PhysRevD.103.024011","report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the motion of free masses subject to the influence of standing\ngravitational waves in the polarized Gowdy cosmology with a three-torus\ntopology. We show that antinodes attract freely falling particles and we trace\nthe velocity memory effect.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:17:29 GMT"},{"version":"v2","created":"Sun, 7 Nov 2021 14:28:11 GMT"}],"update_date":"2021-11-09"}
{"id":"2010.12550","submitter":"David Shikumo Mr.","authors":"David Haritone Shikumo and Mwangi Mirie","title":"Determinants of Lending to Small and Medium Enterprises by Commercial\n  Banks in Kenya","comments":"7 Pages","journal-ref":"IOSR Journal of Economics and Finance (IOSR-JEF) e-ISSN:\n  2321-5933, p-ISSN: 2321-5925.Volume 7, Issue 4. Ver. IV (Jul. - Aug. 2016),\n  PP 57-63 www.iosrjournals.org","doi":null,"report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Small and Medium Enterprises (SMEs) access to external finance is an issue of\nsignificant research interest to academicians. Commercial banks consider many\nSMEs not to be credit worthy because of their inability to meet some banking\nrequirements. Hence, the objective of this study was to investigate what\ndetermines lending to SMEs by commercial banks in Kenya. To achieve the study\nobjectives, a descriptive research design was employed. The study undertook a\ncensus of the 43 commercial banks in Kenya, with full data being obtained for\n36 institutions. The study used secondary data from the annual published\nreports of commercial banks in Kenya for a period of 5 years from 2010-2014.\nThe data collected was analyzed through the multiple linear regression using\nthe Statistical Package for Social Studies version 20.The study established\nthat bank size and liquidity significantly influences (positively and\nnegatively, respectively) lending to SMEs by commercial banks in Kenya while\ncredit risk and interest rates have no significant influence on lending to SMEs\nby commercial banks in Kenya. The study recommends that lending to SMEs by\ncommercial banks in Kenya be enhanced by adopting policies that grow the\ncommercial banks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:25:12 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12551","submitter":"Mohammed Mou\\c{c}ouf","authors":"Mohammed Mou\\c{c}ouf, Said Zriaa","title":"Some Explicit Formulas for Matrix Exponential, Matrix Logarithm, the\n  $n$th Power of Matrices and their Drazin Inverses","comments":"23 pages; the abstract is changed; corrected typos; some examples are\n  added; some references are omitted and others are added or modified; some\n  remarks are omitted","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, new closed-form formulas for the matrix exponential are\nprovided. Our method is direct and elementary, it gives tractable and\nmanageable formulas not current in the extensive literature on this essential\nsubject. Moreover, others are recuperated and generalized. As a consequence, we\neasily obtain the Chevalley{Jordan decomposition and the spectral projections\nof any matrix. In addition, closed-form expressions for the arbitrary positive\npowers of matrices and their Drazin inverses are presented. Using these\nresults, an elegant explicit formula for logarithm of matrices is obtained.\nSeveral particular cases and examples are formulated to illustrate the methods\npresented in this paper.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:26:41 GMT"},{"version":"v2","created":"Fri, 30 Oct 2020 18:27:50 GMT"},{"version":"v3","created":"Mon, 16 Aug 2021 13:31:45 GMT"}],"update_date":"2021-08-17"}
{"id":"2010.12552","submitter":"Saeed Khaki","authors":"Saeed Khaki, Hieu Pham, Ye Han, Wade Kent and Lizhi Wang","title":"High-Throughput Image-Based Plant Stand Count Estimation Using\n  Convolutional Neural Networks","comments":"15 pages, 3 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG q-bio.QM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The future landscape of modern farming and plant breeding is rapidly changing\ndue to the complex needs of our society. The explosion of collectable data has\nstarted a revolution in agriculture to the point where innovation must occur.\nTo a commercial organization, the accurate and efficient collection of\ninformation is necessary to ensure that optimal decisions are made at key\npoints of the breeding cycle. However, due to the shear size of a breeding\nprogram and current resource limitations, the ability to collect precise data\non individual plants is not possible. In particular, efficient phenotyping of\ncrops to record its color, shape, chemical properties, disease susceptibility,\netc. is severely limited due to labor requirements and, oftentimes, expert\ndomain knowledge. In this paper, we propose a deep learning based approach,\nnamed DeepStand, for image-based corn stand counting at early phenological\nstages. The proposed method adopts a truncated VGG-16 network as a backbone\nfeature extractor and merges multiple feature maps with different scales to\nmake the network robust against scale variation. Our extensive computational\nexperiments suggest that our proposed method can successfully count corn stands\nand out-perform other state-of-the-art methods. It is the goal of our work to\nbe used by the larger agricultural community as a way to enable high-throughput\nphenotyping without the use of extensive time and labor requirements.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:28:29 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12553","submitter":"Gary K. Nave Jr.","authors":"Gary K. Nave, Jr., Nathaniel Hall, Katrina Somers, Brock Davis, Hope\n  Gruszewski, Craig Powers, Michael Collver, David G. Schmale III, Shane D.\n  Ross","title":"Wind dispersal of natural and biomimetic maple samaras","comments":null,"journal-ref":null,"doi":"10.3390/biomimetics6020023","report-no":null,"categories":"physics.bio-ph physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Maple trees (genus $\\textit{Acer}$) accomplish the task of distributing\nobjects to a wide area by producing seeds which are carried by the wind as they\nslowly descend to the ground, known as samaras. With the goal of supporting\nengineering applications, such as gathering environmental data over a broad\narea, we developed 3D-printed artificial samaras. Here, we compare the behavior\nof both natural and artificial samaras in both still-air laboratory experiments\nand wind dispersal experiments in the field. We show that the artificial\nsamaras are able to replicate (within 1 standard deviation) the behavior of\nnatural samaras in a lab setting. We further introduce the notion of windage to\ncompare dispersal behavior, and show that the natural samara has the highest\nmean windage, corresponding to the longest flights during both high wind and\nlow wind experimental trials. This research provides a bioinspired design for\nthe dispersed deployment of sensors and provides a better understanding of\nwind-dispersal of both natural and artificial samaras.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:32:03 GMT"}],"update_date":"2021-09-02"}
{"id":"2010.12554","submitter":"Elena Kolganova","authors":"G. Nikoghosyan, A. Balabekyan, E.A. Kolganova, R.V. Jolos, D.A.\n  Sazonov","title":"Isovector pair correlations in analytically solvable models","comments":"12 pages, 5 figures","journal-ref":"Int. J. Mod. Phys. E 29 (2020) 205091","doi":"10.1142/S0218301320500913","report-no":null,"categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The eigensolutions of the collective Hamiltonian with different potentials\nsuggested for description of the isovector pair correlations are obtained,\nanalyzed and compared with the experimental energies. It is shown that the\nisovector pair correlations in nuclei around $^{56}$Ni can be described as\nanharmonic pairing vibrations. The results obtained indicate the presence of\nthe $\\alpha$-particle type correlations in these nuclei and the existence of\nthe interaction different from isovector pairing which also influences on the\nisospin dependence of the energies.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:34:30 GMT"}],"update_date":"2021-01-06"}
{"id":"2010.12555","submitter":"Sam Streeter","authors":"Masahiro Nakahara and Sam Streeter","title":"Weak approximation and the Hilbert property for Campana points","comments":"23 pages, minor revisions; to appear in Michigan Mathematical Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study weak approximation and the Hilbert property for Campana points, both\nof importance in recent work on a Manin-type conjecture by Pieropan, Smeets,\nTanimoto and Varilly-Alvarado. We show that weak weak approximation implies the\nHilbert property for Campana points, and we exploit this to exhibit Campana\norbifolds whose sets of Campana points are not thin.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:35:20 GMT"},{"version":"v2","created":"Fri, 11 Mar 2022 11:13:41 GMT"},{"version":"v3","created":"Tue, 22 Nov 2022 11:21:00 GMT"},{"version":"v4","created":"Wed, 3 May 2023 08:01:15 GMT"}],"update_date":"2023-05-04"}
{"id":"2010.12556","submitter":"Robin Corbet","authors":"Robin H. D. Corbet, Joel B. Coley, Hans A. Krimm, Katja Pottschmidt,\n  Paul Roche","title":"Superorbital Modulation in the High-Mass X-ray Binary 4U 1538-52, and\n  Possible Modulation in IGR J16393-4643","comments":"Accepted for publication in the Astrophysical Journal. 15 pages, 16\n  figures","journal-ref":null,"doi":"10.3847/1538-4357/abc477","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hard X-ray observations with the Neil Gehrels Swift Observatory Burst Alert\nTelescope (BAT) reveal superorbital modulation in the wind-accreting supergiant\nhigh-mass X-ray binary (HMXB) 4U 1538-52 at a period of 14.9130 +/- 0.0026 days\nthat is consistent with four times the 3.73 day orbital period. These periods\nagree with a previously suggested correlation between superorbital and orbital\nperiods in similar HMXBs. During the ~14 years of observations the superorbital\nmodulation changes amplitude, and since ~MJD 57,650 it was no longer detected\nin the power spectrum, although a peak near the second harmonic of this was\npresent for some time. Measurements of the spin period of the neutron star in\nthe system with the Fermi Gamma-ray Burst Monitor show a long-term spin-down\ntrend which halted towards the end of the light curve, suggesting a connection\nbetween dP(spin)/dt and superorbital modulation, as proposed for 2S 0114+650.\nHowever, an earlier torque reversal from INTEGRAL observations was not\nassociated with superorbital modulation changes. B and V band photometry from\nthe Las Cumbres Observatory reveals orbital ellipsoidal photometric\nvariability, but no superorbital optical modulation. However the photometry was\nobtained when the 14.9130 day period was no longer detected in the BAT power\nspectrum. We revisit possible superorbital modulation in BAT observations of\nIGR J16393-4643 but cannot conclusively determine whether this is present,\nalthough is not persistent. We consider superorbital modulation mechanisms, and\nsuggest that the Corotating Interaction Region model, with small deviations\nfrom orbital synchronization, appears promising.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:36:19 GMT"}],"update_date":"2021-01-06"}
{"id":"2010.12557","submitter":"Giulia Fardelli","authors":"Agnese Bissi, Giulia Fardelli and Alessandro Georgoudis","title":"All loop structures in Supergravity Amplitudes on $AdS_5 \\times S^5$\n  from CFT","comments":"43 pages, Ancillary files contains various results presented in the\n  paper. V2: Corrected typos, added references and modified figure. V3:\n  reformatted for J.Phys. A, accepted version","journal-ref":null,"doi":"10.1088/1751-8121/ac0ebf","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We computed a set of structures which appear in the four-point function of\nprotected operators of dimension two in $\\mathcal{N}=4$ Super Yang Mills with\n$SU(N)$ gauge group, at any order in a large $N$ expansion. They are determined\nonly by leading order CFT data. By focusing on a specific limit, we made\nconnection with the dual supergravity amplitude in flat space, where such\nstructures correspond to iterated $s$-cuts. We made several checks and we\nconjecture that the same interpretation holds for supergravity amplitudes on\n$AdS_5 \\times S^5$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:37:10 GMT"},{"version":"v2","created":"Sun, 7 Feb 2021 16:43:54 GMT"},{"version":"v3","created":"Wed, 23 Jun 2021 12:53:17 GMT"}],"update_date":"2021-08-11"}
{"id":"2010.12558","submitter":"Alexander Nitz","authors":"Alexander H. Nitz and Collin D. Capano","title":"GW190521 may be an intermediate mass ratio inspiral","comments":"9 pages, 5 figures, 1 table, corresponding data release at\n  http://github.com/gwastro/gw190521, updated to match version accepted by ApJL","journal-ref":null,"doi":"10.3847/2041-8213/abccc5","report-no":null,"categories":"astro-ph.HE gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  GW190521 is the first confident observation of a binary black hole merger\nwith total mass $M > 100\\,\\mathrm{M}_{\\odot}$. Given the lack of observational\nconstraints at these masses, we analyze GW190521 considering two different\npriors for the binary's masses: uniform in mass ratio and source-frame total\nmass, and uniform in source-frame component masses. For the uniform in\nmass-ratio prior, we find that the component masses are $m_1^{\\mathrm{src}} =\n168_{-61}^{+15}\\,\\mathrm{M}_{\\odot}$ and $m_2^{\\mathrm{src}} =\n16_{-3}^{+33}\\,\\mathrm{M}_{\\odot}$. The uniform in component-mass prior yields\na bimodal posterior distribution. There is a low-mass-ratio mode ($q<4$) with\n$m_1^{\\mathrm{src}} = 100_{-18}^{+17}\\,\\mathrm{M}_{\\odot}$ and\n$m_2^{\\mathrm{src}} = 57_{-16}^{+17}\\,\\mathrm{M}_{\\odot}$ and a high-mass-ratio\nmode ($q\\geq4$) with $m_1^{\\mathrm{src}} = 166_{-35}^{+16}\\,\\mathrm{M}_{\\odot}$\nand $m_2^{\\mathrm{src}} = 16_{-3}^{+14}\\,\\mathrm{M}_{\\odot}$. Although the two\nmodes have nearly equal posterior probability, the maximum-likelihood\nparameters are in the high-mass ratio mode, with $m_1^{\\rm src} =\n171\\,M_{\\odot}$ and $m_2^{\\rm src} = 16\\,M_{\\odot}$, and a signal-to-noise\nratio of $16$. These results are consistent with the proposed \"mass gap\"\nproduced by pair-instability in supernova. Our results differ from those\npublished in Abbott et al. (2020b). We find that a combination of the prior\nused and the constraints applied may have prevented that analysis from sampling\nthe high-mass-ratio mode. An accretion flare in AGN J124942.3+344929 was\nobserved in possible coincidence with GW190521 by the Zwicky Transient Facility\n(ZTF). We report parameters assuming a common origin; however, the spatial\nagreement of GW190521 and the EM flare alone does not provide convincing\nevidence for the association ($\\ln\\mathcal{B} \\gtrsim -4$).\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:37:38 GMT"},{"version":"v2","created":"Tue, 3 Nov 2020 10:25:25 GMT"},{"version":"v3","created":"Tue, 24 Nov 2020 12:39:42 GMT"}],"update_date":"2021-01-27"}
{"id":"2010.12559","submitter":"Ali Ramadhan","authors":"Ali Ramadhan, John Marshall, Andre Souza, Xin Kai Lee, Ulyana\n  Piterbarg, Adeline Hillier, Gregory LeClaire Wagner, Christopher Rackauckas,\n  Chris Hill, Jean-Michel Campin, Raffaele Ferrari","title":"Capturing missing physics in climate model parameterizations using\n  neural differential equations","comments":"47 pages, 10 figures, 2 tables, 7 appendices","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore how neural differential equations (NDEs) may be trained on highly\nresolved fluid-dynamical models of unresolved scales providing an ideal\nframework for data-driven parameterizations in climate models. NDEs overcome\nsome of the limitations of traditional neural networks (NNs) in fluid dynamical\napplications in that they can readily incorporate conservation laws and\nboundary conditions and are stable when integrated over time. We advocate a\nmethod that employs a 'residual' approach, in which the NN is used to improve\nupon an existing parameterization through the representation of residual fluxes\nwhich are not captured by the base parameterization. This reduces the amount of\ntraining required and providing a method for capturing up-gradient and nonlocal\nfluxes. As an illustrative example, we consider the parameterization of free\nconvection of the oceanic boundary layer triggered by buoyancy loss at the\nsurface. We demonstrate that a simple parameterization of the process -\nconvective adjustment - can be improved upon by training a NDE against highly\nresolved explicit models, to capture entrainment fluxes at the base of the\nwell-mixed layer, fluxes that convective adjustment itself cannot represent.\nThe augmented parameterization outperforms existing commonly used\nparameterizations such as the K-Profile Parameterization (KPP). We showcase\nthat the NDE performs well independent of the time-stepper and that an online\ntraining approach using differentiable simulation via the Julia scientific\nmachine learning software stack improves accuracy by an order-of-magnitude. We\nconclude that NDEs provide an exciting route forward to the development of\nrepresentations of sub-grid-scale processes for climate science, opening up\nmyriad new opportunities.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:43:08 GMT"},{"version":"v2","created":"Mon, 6 Mar 2023 22:14:16 GMT"}],"update_date":"2023-03-08"}
{"id":"2010.12560","submitter":"Lakshmi Pradeep Chitta","authors":"L. P. Chitta, H. Peter, E. R. Priest, and S. K. Solanki","title":"Impulsive coronal heating during the interaction of surface magnetic\n  fields in the lower solar atmosphere","comments":"Published in Astronomy & Astrophysics. Online movies available at\n  https://www.aanda.org/articles/aa/olm/2020/12/aa39099-20/aa39099-20.html","journal-ref":"A&A 644, A130 (2020)","doi":"10.1051/0004-6361/202039099","report-no":null,"categories":"astro-ph.SR physics.plasm-ph physics.space-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coronal plasma in the cores of solar active regions is impulsively heated to\nmore than 5 MK. The nature and location of the magnetic energy source\nresponsible for such impulsive heating is poorly understood. Using observations\nof seven active regions from the Solar Dynamics Observatory, we found that a\nmajority of coronal loops hosting hot plasma have at least one footpoint rooted\nin regions of interacting mixed magnetic polarity at the solar surface. In\ncases when co-temporal observations from the Interface Region Imaging\nSpectrograph space mission are available, we found spectroscopic evidence for\nmagnetic reconnection at the base of the hot coronal loops. Our analysis\nsuggests that interactions of magnetic patches of opposite polarity at the\nsolar surface and the associated energy release during reconnection are key to\nimpulsive coronal heating.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:43:40 GMT"},{"version":"v2","created":"Tue, 27 Oct 2020 18:38:24 GMT"},{"version":"v3","created":"Thu, 17 Dec 2020 21:44:40 GMT"}],"update_date":"2020-12-21"}
{"id":"2010.12561","submitter":"Farzan Farnia","authors":"Farzan Farnia, Asuman Ozdaglar","title":"Train simultaneously, generalize better: Stability of gradient-based\n  minimax learners","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The success of minimax learning problems of generative adversarial networks\n(GANs) has been observed to depend on the minimax optimization algorithm used\nfor their training. This dependence is commonly attributed to the convergence\nspeed and robustness properties of the underlying optimization algorithm. In\nthis paper, we show that the optimization algorithm also plays a key role in\nthe generalization performance of the trained minimax model. To this end, we\nanalyze the generalization properties of standard gradient descent ascent (GDA)\nand proximal point method (PPM) algorithms through the lens of algorithmic\nstability under both convex concave and non-convex non-concave minimax\nsettings. While the GDA algorithm is not guaranteed to have a vanishing excess\nrisk in convex concave problems, we show the PPM algorithm enjoys a bounded\nexcess risk in the same setup. For non-convex non-concave problems, we compare\nthe generalization performance of stochastic GDA and GDmax algorithms where the\nlatter fully solves the maximization subproblem at every iteration. Our\ngeneralization analysis suggests the superiority of GDA provided that the\nminimization and maximization subproblems are solved simultaneously with\nsimilar learning rates. We discuss several numerical results indicating the\nrole of optimization algorithms in the generalization of the learned minimax\nmodels.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:44:43 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12562","submitter":"Xiaotao Gu","authors":"Xiaotao Gu, Liyuan Liu, Hongkun Yu, Jing Li, Chen Chen, Jiawei Han","title":"On the Transformer Growth for Progressive BERT Training","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to the excessive cost of large-scale language model pre-training,\nconsiderable efforts have been made to train BERT progressively -- start from\nan inferior but low-cost model and gradually grow the model to increase the\ncomputational complexity. Our objective is to advance the understanding of\nTransformer growth and discover principles that guide progressive training.\nFirst, we find that similar to network architecture search, Transformer growth\nalso favors compound scaling. Specifically, while existing methods only conduct\nnetwork growth in a single dimension, we observe that it is beneficial to use\ncompound growth operators and balance multiple dimensions (e.g., depth, width,\nand input length of the model). Moreover, we explore alternative growth\noperators in each dimension via controlled comparison to give operator\nselection practical guidance. In light of our analyses, the proposed method\nspeeds up BERT pre-training by 73.6% and 82.2% for the base and large models\nrespectively, while achieving comparable performances\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:44:59 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 22:32:35 GMT"},{"version":"v3","created":"Sun, 11 Jul 2021 06:42:23 GMT"}],"update_date":"2021-07-13"}
{"id":"2010.12563","submitter":"Eric Wallace","authors":"Eric Wallace, Tony Z. Zhao, Shi Feng, Sameer Singh","title":"Concealed Data Poisoning Attacks on NLP Models","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Adversarial attacks alter NLP model predictions by perturbing test-time\ninputs. However, it is much less understood whether, and how, predictions can\nbe manipulated with small, concealed changes to the training data. In this\nwork, we develop a new data poisoning attack that allows an adversary to\ncontrol model predictions whenever a desired trigger phrase is present in the\ninput. For instance, we insert 50 poison examples into a sentiment model's\ntraining set that causes the model to frequently predict Positive whenever the\ninput contains \"James Bond\". Crucially, we craft these poison examples using a\ngradient-based procedure so that they do not mention the trigger phrase. We\nalso apply our poison attack to language modeling (\"Apple iPhone\" triggers\nnegative generations) and machine translation (\"iced coffee\" mistranslated as\n\"hot coffee\"). We conclude by proposing three defenses that can mitigate our\nattack at some cost in prediction accuracy or extra human annotation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:47:06 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 09:10:06 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12564","submitter":"Zhan Jiang","authors":"Zhan Jiang","title":"Closure operations in complete local rings of mixed characteristic","comments":"Here are the changes: Remark 3.9 is deleted; Proof of Lemma 3.8 is\n  re-written; Definition 4.4 is deleted; Proposition 4.5 -> Proposition 4.10;\n  Corollary 4.6 -> Corollary 4.11; Proposition 4.9 is deleted; Chapter 5 is\n  merged into the Chapter 4 (Hence, Chapters 6/7/8 -> Chapters 5/6/7); New\n  remark (Remark 6.10) is added after Theorem 6.9 (previously Theorem 7.9)","journal-ref":"Journal of Algebra 580 (2021): 366-398","doi":"10.1016/j.jalgebra.2021.03.038","report-no":null,"categories":"math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Extended plus (epf) closure and rank 1 (r1f) closure are two closure\noperations introduced by Raymond C. Heitmann for rings of mixed characteristic.\nRecently, he and Linquan Ma proved that epf closure satisfies the usual\ncolon-capturing property under mild conditions. In this paper, we extend their\nresult and prove that epf closure satisfies what we call the\n$p$-colon-capturing property. Based on that, we define a new closure notion\ncalled \"weak epf closure\", and prove that it satisfies the generalized\ncolon-capturing property and some other colon-capturing properties. This gives\na new proof of the existence of big Cohen-Macaulay algebras in the mixed\ncharacteristic case. We also show that any module-finite extension of a\ncomplete local domain is epf-phantom, which generalizes a result of Mel\nHochster and Craig Huneke about \"phantom extensions\". Finally, we prove some\nrelated results in characteristic $p$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:48:52 GMT"},{"version":"v2","created":"Wed, 14 Apr 2021 22:13:47 GMT"}],"update_date":"2021-04-23"}
{"id":"2010.12565","submitter":"Ibrahim Akal","authors":"Ibrahim Akal","title":"Universality, intertwiners and black hole information","comments":"35 pages, 17 figures","journal-ref":null,"doi":null,"report-no":"YITP-20-132","categories":"hep-th gr-qc quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The central question in this article is how information does leak out from\nblack holes. Relying on algebraic arguments and the concept of superselection\nsectors, we propose the existence of certain operators whose correlations\nextend across the black hole atmosphere and range into the interior. Contained\nin the full algebra, these black hole intertwiners will not belong to the\nsubalgebra describing semiclassical bulk physics. We study this proposal in the\ncontext of operator reconstructions for code spaces containing a large number\nof microstates. As long as the atmosphere is excluded from a particular\nsubsystem, the global state seen under the action of the associated algebra is\nmaximally mixed and therefore described by a single classical background. Once\nthe relevant correlations are encoded, i.e. if the algebra is sufficiently\nenlarged, perfect state distinguishability becomes possible. We arrive at this\nby computing the von Neumann entropy which may explain the result obtained by\napplying the quantum extremal surface prescription to the mixed state. We then\nexamine these insights in the context of black hole evaporation and argue that\ninformation is transferred to the radiation via black hole intertwiners. We\nderive the Page curve. The mechanism above suggests that black hole information\nis topologically protected. An infalling observer would experience no drama.\nThis may resolve the unitarity problem without running into any firewall or\nstate puzzle, the latter being evident in generalized entropy computations. We\nalso examine the question of how certain wormhole topologies may be understood\ngiven these findings. We argue that their occurrence in gravity replica\ncomputations may be related to the maximal correlation between radiation and\natmosphere surrounding the old black hole. This may suggest a connection\nbetween topology change and near horizon quantum gravitational effects.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:51:04 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12566","submitter":"Aditi Chaudhary","authors":"Aditi Chaudhary, Karthik Raman, Krishna Srinivasan, Jiecao Chen","title":"DICT-MLM: Improved Multilingual Pre-Training using Bilingual\n  Dictionaries","comments":"13 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained multilingual language models such as mBERT have shown immense\ngains for several natural language processing (NLP) tasks, especially in the\nzero-shot cross-lingual setting. Most, if not all, of these pre-trained models\nrely on the masked-language modeling (MLM) objective as the key language\nlearning objective. The principle behind these approaches is that predicting\nthe masked words with the help of the surrounding text helps learn potent\ncontextualized representations. Despite the strong representation learning\ncapability enabled by MLM, we demonstrate an inherent limitation of MLM for\nmultilingual representation learning. In particular, by requiring the model to\npredict the language-specific token, the MLM objective disincentivizes learning\na language-agnostic representation -- which is a key goal of multilingual\npre-training. Therefore to encourage better cross-lingual representation\nlearning we propose the DICT-MLM method. DICT-MLM works by incentivizing the\nmodel to be able to predict not just the original masked word, but potentially\nany of its cross-lingual synonyms as well. Our empirical analysis on multiple\ndownstream tasks spanning 30+ languages, demonstrates the efficacy of the\nproposed approach and its ability to learn better multilingual representations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:53:11 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12567","submitter":"Steven L. Liebling","authors":"Steven L. Liebling, Carlos Palenzuela, Luis Lehner","title":"Effects of High Density Phase Transitions on Neutron Star Dynamics","comments":"10 pages, 12 figures; Updated with accepted version which includes\n  updates to the text, a new figure, and rearrangement of certain existing\n  figures","journal-ref":null,"doi":"10.1088/1361-6382/abf898","report-no":null,"categories":"gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Various theoretical arguments motivate an expectation of a phase transition\nin matter at extreme densities above nuclear density, accompanied by hopes that\ngravitational wave observations may reveal the properties of such a transition.\nInstead of adopting a particular theory, we consider here a generic form of\nfirst order phase transition using a piecewise polytropic equation of state,\nand evolve both isolated neutron stars and neutron star binaries, including\nunequal mass binaries and, in some cases, magnetic field, looking at dynamical\neffects. Of particular interest are effects that may be observable either via\ngravitational waves or electromagnetic observations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:53:45 GMT"},{"version":"v2","created":"Fri, 16 Apr 2021 14:13:38 GMT"}],"update_date":"2021-06-09"}
{"id":"2010.12568","submitter":"Devin Johnson","authors":"Devin S. Johnson, Brian M. Brost and Mevin B. Hooten","title":"Greater Than the Sum of its Parts: Computationally Flexible Bayesian\n  Hierarchical Modeling","comments":"32 pages, 4 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.CO","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We propose a multistage method for making inference at all levels of a\nBayesian hierarchical model (BHM) using natural data partitions to increase\nefficiency by allowing computations to take place in parallel form using\nsoftware that is most appropriate for each data partition. The full\nhierarchical model is then approximated by the product of independent normal\ndistributions for the data component of the model. In the second stage, the\nBayesian maximum {\\it a posteriori} (MAP) estimator is found by maximizing the\napproximated posterior density with respect to the parameters. If the\nparameters of the model can be represented as normally distributed random\neffects then the second stage optimization is equivalent to fitting a\nmultivariate normal linear mixed model. This method can be extended to account\nfor common fixed parameters shared between data partitions, as well as\nparameters that are distinct between partitions. In the case of distinct\nparameter estimation, we consider a third stage that re-estimates the distinct\nparameters for each data partition based on the results of the second stage.\nThis allows more information from the entire data set to properly inform the\nposterior distributions of the distinct parameters. The method is demonstrated\nwith two ecological data sets and models, a random effects GLM and an\nIntegrated Population Model (IPM). The multistage results were compared to\nestimates from models fit in single stages to the entire data set. Both\nexamples demonstrate that multistage point and posterior standard deviation\nestimates closely approximate those obtained from fitting the models with all\ndata simultaneously and can therefore be considered for fitting hierarchical\nBayesian models when it is computationally prohibitive to do so in one step.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:53:56 GMT"},{"version":"v2","created":"Wed, 22 Sep 2021 17:51:22 GMT"}],"update_date":"2021-09-23"}
{"id":"2010.12569","submitter":"David Shikumo Mr.","authors":"King'ori S. Ngumo, Kioko W. Collins and Shikumo H. David","title":"Determinants of Financial Performance of Microfinance Banks in Kenya","comments":"8 pages","journal-ref":"Research Journal of Finance and Accounting ISSN 2222-1697 (Paper)\n  ISSN 2222-2847 (Online) Vol.8, No.16, 2017","doi":null,"report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Microfinance provides strength to boost the economic activities of low-income\nearners and thus contributes to eradication of poverty. However, microfinance\ninstitutions face stringent competition from commercial banks; the growth of\nmicroloan activities of commercial banks may confront microfinance institutions\nwith increased competition for borrowers. In Kenya, the micro finance sector\nhas extremely high competition indicated by the shifting market share and\nprofitability. This study sought to examine the determinants of financial\nperformance of Microfinance banks in Kenya. The study adopted a descriptive\nresearch design and used secondary data from 7 Microfinance banks for a period\nof 5 years from 2011 to 2015. The data collected was analyzed using correlation\nand regression analysis. The study found a positive and statistically\nsignificant relationship between operational efficiency, capital adequacy, firm\nsize and financial performance of microfinance banks in Kenya. However, the\nstudy found an insignificant negative relationship between liquidity risk,\ncredit risk and financial performance of microfinance banks in Kenya. The study\nconcluded that there is direct relationship between operational efficiency,\ncapital adequacy, firm size and financial performance of microfinance banks in\nKenya.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:54:19 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12570","submitter":"Efe Bozkir","authors":"Efe Bozkir, Shahram Eivazi, Mete Akg\\\"un, Enkelejda Kasneci","title":"Eye Tracking Data Collection Protocol for VR for Remotely Located\n  Subjects using Blockchain and Smart Contracts","comments":"2020 IEEE International Conference on Artificial Intelligence and\n  Virtual Reality (AIVR). Authors' copy, refer to the doi for more information","journal-ref":null,"doi":"10.1109/AIVR50618.2020.00083","report-no":null,"categories":"cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Eye tracking data collection in the virtual reality context is typically\ncarried out in laboratory settings, which usually limits the number of\nparticipants or consumes at least several months of research time. In addition,\nunder laboratory settings, subjects may not behave naturally due to being\nrecorded in an uncomfortable environment. In this work, we propose a\nproof-of-concept eye tracking data collection protocol and its implementation\nto collect eye tracking data from remotely located subjects, particularly for\nvirtual reality using Ethereum blockchain and smart contracts. With the\nproposed protocol, data collectors can collect high quality eye tracking data\nfrom a large number of human subjects with heterogeneous socio-demographic\ncharacteristics. The quality and the amount of data can be helpful for various\ntasks in data-driven human-computer interaction and artificial intelligence.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:54:38 GMT"},{"version":"v2","created":"Wed, 2 Dec 2020 11:28:56 GMT"},{"version":"v3","created":"Wed, 14 Jul 2021 12:51:12 GMT"}],"update_date":"2021-07-15"}
{"id":"2010.12571","submitter":"Keith Burghardt","authors":"Keith Burghardt, Tad Hogg, Raissa M. D'Souza, Kristina Lerman, Marton\n  Posfai","title":"Origins of Algorithmic Instabilities in Crowdsourced Ranking","comments":"12 pages, 20 figures","journal-ref":"Proc. ACM Hum.-Comput. Interact., Vol. 4, No. CSCW2, Article 166.\n  2020","doi":"10.1145/3415237","report-no":null,"categories":"cs.SI cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Crowdsourcing systems aggregate decisions of many people to help users\nquickly identify high-quality options, such as the best answers to questions or\ninteresting news stories. A long-standing issue in crowdsourcing is how option\nquality and human judgement heuristics interact to affect collective outcomes,\nsuch as the perceived popularity of options. We address this limitation by\nconducting a controlled experiment where subjects choose between two ranked\noptions whose quality can be independently varied. We use this data to\nconstruct a model that quantifies how judgement heuristics and option quality\ncombine when deciding between two options. The model reveals popularity-ranking\ncan be unstable: unless the quality difference between the two options is\nsufficiently high, the higher quality option is not guaranteed to be eventually\nranked on top. To rectify this instability, we create an algorithm that\naccounts for judgement heuristics to infer the best option and rank it first.\nThis algorithm is guaranteed to be optimal if data matches the model. When the\ndata does not match the model, however, simulations show that in practice this\nalgorithm performs better or at least as well as popularity-based and\nrecency-based ranking for any two-choice question. Our work suggests that\nalgorithms relying on inference of mathematical models of user behavior can\nsubstantially improve outcomes in crowdsourcing systems.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:55:08 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12572","submitter":"Adrian Parra-Rodriguez","authors":"A. Parra-Rodriguez and I. L. Egusquiza","title":"Canonical quantisation of telegrapher's equations coupled by ideal\n  nonreciprocal elements","comments":"17 pages, 4 figures","journal-ref":"Quantum 6, 681 (2022)","doi":"10.22331/q-2022-04-04-681","report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We develop a systematic procedure to quantise canonically Hamiltonians of\nlight-matter models of transmission lines coupled through lumped linear\nlossless ideal nonreciprocal elements, that break time-reversal symmetry, in a\ncircuit QED set-up. This is achieved through a description of the distributed\nsubsystems in terms of both flux and charge fields. We prove that this apparent\nredundancy is required for the general derivation of the Hamiltonian for a\nwider class of networks. By making use of the electromagnetic duality symmetry\nin transmission lines (waveguides), we provide unambiguous identification of\nthe physical degrees of freedom, separating out the nondynamical parts. This\ndoubled description can also treat the case of other extended lumped\ninteractions in a regular manner that presents no spurious divergences, as we\nshow explicitly in the example of a circulator connected to a Josephson\njunction through a transmission line. This theory enhances the quantum\nengineering toolbox to design complex networks with nonreciprocal elements.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:56:02 GMT"},{"version":"v2","created":"Wed, 2 Jun 2021 15:05:46 GMT"},{"version":"v3","created":"Thu, 17 Mar 2022 14:50:09 GMT"},{"version":"v4","created":"Fri, 25 Mar 2022 16:36:36 GMT"}],"update_date":"2022-04-20"}
{"id":"2010.12573","submitter":"Hong Zhang","authors":"Qichuan Geng, Hong Zhang, Na Jiang, Xiaojuan Qi, Liangjun Zhang, Zhong\n  Zhou","title":"Object-aware Feature Aggregation for Video Object Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present an Object-aware Feature Aggregation (OFA) module for video object\ndetection (VID). Our approach is motivated by the intriguing property that\nvideo-level object-aware knowledge can be employed as a powerful semantic prior\nto help object recognition. As a consequence, augmenting features with such\nprior knowledge can effectively improve the classification and localization\nperformance. To make features get access to more content about the whole video,\nwe first capture the object-aware knowledge of proposals and incorporate such\nknowledge with the well-established pair-wise contexts. With extensive\nexperimental results on the ImageNet VID dataset, our approach demonstrates the\neffectiveness of object-aware knowledge with the superior performance of 83.93%\nand 86.09% mAP with ResNet-101 and ResNeXt-101, respectively. When further\nequipped with Sequence DIoU NMS, we obtain the best-reported mAP of 85.07% and\n86.88% upon the paper submitted. The code to reproduce our results will be\nreleased after acceptance.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:56:25 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12574","submitter":"Djallel Bouneffouf","authors":"Sohini Upadhyay, Mikhail Yurochkin, Mayank Agarwal, Yasaman Khazaeni\n  and DjallelBouneffouf","title":"Online Semi-Supervised Learning with Bandit Feedback","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We formulate a new problem at the intersectionof semi-supervised learning and\ncontextual bandits,motivated by several applications including clini-cal trials\nand ad recommendations. We demonstratehow Graph Convolutional Network (GCN), a\nsemi-supervised learning approach, can be adjusted tothe new problem\nformulation. We also propose avariant of the linear contextual bandit with\nsemi-supervised missing rewards imputation. We thentake the best of both\napproaches to develop multi-GCN embedded contextual bandit. Our algorithmsare\nverified on several real world datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:56:38 GMT"}],"update_date":"2020-10-26"}
{"id":"2010.12577","submitter":"Hansjoerg Albrecher","authors":"Hansjoerg Albrecher and Pierre-Olivier Goffard","title":"On the profitability of selfish blockchain mining under consideration of\n  ruin","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR math.OC math.PR q-fin.RM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mining blocks on a blockchain equipped with a proof of work consensus\nprotocol is well-known to be resource-consuming. A miner bears the operational\ncost, mainly electricity consumption and IT gear, of mining, and is compensated\nby a capital gain when a block is discovered. This paper aims at quantifying\nthe profitability of mining when the possible event of ruin is also considered.\nThis is done by formulating a tractable stochastic model and using tools from\napplied probability and analysis, including the explicit solution of a certain\ntype of advanced functional differential equation. The expected profit at a\nfuture time point is determined for the situation when the miner follows the\nprotocol as well as when he/she withholds blocks. The obtained explicit\nexpressions allow to analyze the sensitivity with respect to the different\nmodel ingredients and to identify conditions under which selfish mining is a\nstrategic advantage.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:21:45 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12580","submitter":"Hamid Eftekhari","authors":"Hamid Eftekhari, Moulinath Banerjee, Ya'acov Ritov","title":"Design of $c$-Optimal Experiments for High dimensional Linear Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.ME stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study random designs that minimize the asymptotic variance of a de-biased\nlasso estimator when a large pool of unlabeled data is available but measuring\nthe corresponding responses is costly. The optimal sampling distribution arises\nas the solution of a semidefinite program. The improvements in efficiency that\nresult from these optimal designs are demonstrated via simulation experiments.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:31:27 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12581","submitter":"Max Zimet","authors":"Arnav Tripathy and Max Zimet","title":"A plethora of K3 metrics","comments":"72 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We extend our recent study of K3 metrics near the $T^4/Z_2$ orbifold locus to\nthe other torus orbifold loci. In particular, we provide several new\nconstructions of K3 surfaces as hyper-K\\\"ahler quotients, which yield new\nformulae for K3 metrics. We then relate these to the construction of\narXiv:1810.10540. As a corollary, we derive infinitely many constraints on the\n(as yet unknown) BPS spectra of the Minahan-Nemeschansky SCFTs with $E_n$\nglobal symmetry. Specifically, we find linear combinations of $E_n$ characters\n(evaluated at different points) hiding within K3 metrics and we compute their\nsecond order Taylor expansions. We also find novel strong relationships between\nthe BPS spectra of these SCFTs, as well as with that of the $SU(2)$ $N_f = 4$\nSCFT. Finally, we provide a new derivation of the class S constructions of\nthese SCFTs and state some experimental observations regarding their BPS\nspectra.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12582","submitter":"Sebastian Marino","authors":"S. Marino, A. Zurlo, V. Faramaz, J. Milli, Th. Henning, G. M. Kennedy,\n  L. Matr\\`a, S. P\\'erez, P. Delorme, L. A. Cieza, A. M. Hughes","title":"Insights into the planetary dynamics of HD 206893 with ALMA","comments":null,"journal-ref":null,"doi":"10.1093/mnras/staa2386","report-no":null,"categories":"astro-ph.EP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Radial substructure in the form of rings and gaps has been shown to be\nubiquitous among protoplanetary discs. This could be the case in exoKuiper\nbelts as well, and evidence for this is emerging. In this paper we present ALMA\nobservations of the debris/planetesimal disc surrounding HD 206893, a system\nthat also hosts two massive companions at 2 and 11 au. Our observations reveal\na disc extending from 30 to 180 au, split by a 27 au wide gap centred at 74 au,\nand no dust surrounding the reddened brown dwarf (BD) at 11 au. The gap width\nsuggests the presence of a 0.9 M$_\\mathrm{Jup}$ planet at 74 au, which would be\nthe third companion in this system. Using previous astrometry of the BD,\ncombined with our derived disc orientation as a prior, we were able to better\nconstrain its orbit finding it is likely eccentric ($0.14^{+0.05}_{-0.04}$).\nFor the innermost companion, we used RV, proper motion anomaly and stability\nconsiderations to show its mass and semi-major axis are likely in the range\n4-100 M$_\\mathrm{Jup}$ and 1.4-4.5 au. These three companions will interact on\nsecular timescales and perturb the orbits of planetesimals, stirring the disc\nand potentially truncating it to its current extent via secular resonances.\nFinally, the presence of a gap in this system adds to the growing evidence that\ngaps could be common in wide exoKuiper belts. Out of 6 wide debris discs\nobserved with ALMA with enough resolution, 4-5 show radial substructure in the\nform of gaps.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:00 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.12583","submitter":"Matteo Puel","authors":"James M. Cline, Guillermo Gambini, Samuel D. McDermott, Matteo Puel","title":"Late-Time Dark Matter Oscillations and the Core-Cusp Problem","comments":"27 pages, 12 figures; v2: 30 pages, added discussion on Boltzmann\n  equation in galaxies, two plots and appendix D, updated CMB constraint on\n  $\\delta m$ and references, improved version with clarifications; v3: matched\n  published version","journal-ref":"Journal of High Energy Physics (2021)","doi":"10.1007/JHEP04(2021)223","report-no":"FNAL-PUB-20-556-T","categories":"hep-ph astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The core-cusp problem persists as an unresolved tension between the\npredictions of $\\Lambda$CDM cosmology and observations of dark matter (DM)\nprofiles in dwarf spheroidal and other galaxies. We present a novel scenario\nfor converting cusps into cores through reactivation of DM annihilation in\ngalaxies at late times. This can happen in asymmetric DM models when there is a\nvery small DM-number violating mass term that causes oscillations between DM\nand its antiparticle. Using analytic methods as well as gravitational N-body\nsimulations, we show that this mechanism can robustly eliminate cusps from\ngalactic DM profiles for light fermionic DM of mass $m_\\chi\\sim (0.1-1)$ GeV\nand a lighter mediator into which the DM can annihilate. We identify regions of\nparameter space where annihilation of DM particles is more efficient than\nelastic scattering at reducing the inner density of the DM profile. Dark matter\nannihilation is therefore a qualitatively distinct alternative to the mechanism\nof elastic self-interacting dark matter for addressing the cusp-core problem.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:01 GMT"},{"version":"v2","created":"Fri, 2 Apr 2021 20:31:38 GMT"},{"version":"v3","created":"Wed, 28 Apr 2021 12:29:00 GMT"}],"update_date":"2021-04-29"}
{"id":"2010.12584","submitter":"Cornelius Rampf","authors":"Cornelius Rampf and Oliver Hahn","title":"Shell-crossing in a $\\Lambda$CDM Universe","comments":"5 pages + 7 pages supplementary material, 4 + 10 figures; v2: minor\n  revisions, published at MNRAS Letters","journal-ref":"Mon.Not.Roy.Astron.Soc. 501 (2021) 1, L71-L75","doi":"10.1093/mnrasl/slaa198","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Perturbation theory is an indispensable tool for studying the cosmic\nlarge-scale structure, and establishing its limits is therefore of utmost\nimportance. One crucial limitation of perturbation theory is shell-crossing,\nwhich is the instance when cold-dark-matter trajectories intersect for the\nfirst time. We investigate Lagrangian perturbation theory (LPT) at very high\norders in the vicinity of the first shell-crossing for random initial data in a\nrealistic three-dimensional Universe. For this we have numerically implemented\nthe all-order recursion relations for the matter trajectories, from which the\nconvergence of the LPT series at shell-crossing is established. Convergence\nstudies performed up to the 40th order reveal the nature of the\nconvergence-limiting singularities. These singularities are not the well-known\ndensity singularities at shell-crossing but occur at later times when LPT\nalready ceased to provide physically meaningful results.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:02 GMT"},{"version":"v2","created":"Thu, 24 Jun 2021 13:16:45 GMT"}],"update_date":"2021-06-25"}
{"id":"2010.12585","submitter":"Tommaso Tufarelli Dr","authors":"Tommaso Tufarelli, Daniel Friedrich, Heiko Gro{\\ss}, Joachim Hamm,\n  Ortwin Hess and Bert Hecht","title":"Single Quantum Emitter Dicke Enhancement","comments":"Improved abstract and introduction. 12 pages, 6 figures, comments\n  still welcome!","journal-ref":"Phys. Rev. Research 3, 033103 (2021)","doi":"10.1103/PhysRevResearch.3.033103","report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coupling $N$ identical emitters to the same field mode is well-established\nmethod to enhance light matter interaction. However, the resulting $\\sqrt{N}$\nboost of the coupling strength comes at the cost of a \"linearized\" (effectively\nsemi-classical) dynamics. Here, we instead demonstrate a new approach for\nenhancing the coupling constant of a \\textit{single} quantum emitter, while\nretaining the nonlinear character of the light-matter interaction. We consider\na single quantum emitter with $N$ nearly degenerate transitions that are\ncollectively coupled to the same field mode. We show that in such conditions an\neffective Jaynes-Cummings model emerges, with a boosted coupling constant of\norder $\\sqrt{N}$. The validity and consequences of our general conclusions are\nanalytically demonstrated for the instructive case $N=2$. We further observe\nthat our system can closely match the spectral line shapes and photon\nautocorrelation functions typical of Jaynes-Cummings physics, hence proving\nthat quantum optical nonlinearities are retained. Our findings match up very\nwell with recent broadband plasmonic nanoresonator strong-coupling experiments\nand will therefore facilitate the control and detection of single-photon\nnonlinearities at ambient conditions.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:02 GMT"},{"version":"v2","created":"Thu, 25 Mar 2021 17:02:36 GMT"}],"update_date":"2021-08-04"}
{"id":"2010.12586","submitter":"Anna De Graaff","authors":"Anna de Graaff, Rachel Bezanson, Marijn Franx, Arjen van der Wel, Eric\n  F. Bell, Francesco D'Eugenio, Bradford Holden, Michael V. Maseda, Adam\n  Muzzin, Camilla Pacifici, Jesse van de Sande, David Sobral, Caroline M.S.\n  Straatman, Po-Feng Wu","title":"Tightly coupled morpho-kinematic evolution for massive star-forming and\n  quiescent galaxies across 7 Gyr of cosmic time","comments":"7 pages, 4 figures; accepted for publication in ApJL","journal-ref":null,"doi":"10.3847/2041-8213/abc428","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use the Fundamental Plane (FP) to measure the redshift evolution of the\ndynamical mass-to-light ratio ($M_{\\mathrm{dyn}}/L$) and the\ndynamical-to-stellar mass ratio ($M_{\\mathrm{dyn}}/M_*$). Although\nconventionally used to study the properties of early-type galaxies, we here\nobtain stellar kinematic measurements from the Large Early Galaxy Astrophysics\nCensus (LEGA-C) Survey for a sample of $\\sim1400$ massive ($\\log( M_*/M_\\odot)\n>10.5$) galaxies at $0.6<z<1.0$ that span a wide range in star formation\nactivity. In line with previous studies, we find a strong evolution in\n$M_{\\mathrm{dyn}}/L_g$ with redshift. In contrast, we find only a weak\ndependence of the mean value of $M_{\\mathrm{dyn}}/M_*$ on the specific star\nformation rate, and a redshift evolution that likely is explained by\nsystematics. Therefore, we demonstrate that star-forming and quiescent galaxies\nlie on the same, stable mass FP across $0<z<1$, and that the decrease in\n$M_{\\mathrm{dyn}}/L_g$ toward high redshift can be attributed entirely to\nevolution of the stellar populations. Moreover, we show that the growth of\ngalaxies in size and mass is constrained to occur within the mass FP. Our\nresults imply either minimal structural evolution in massive galaxies since\n$z\\sim1$, or a tight coupling in the evolution of their morphological and\ndynamical properties, and establish the mass FP as a tool for studying galaxy\nevolution with low impact from progenitor bias.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:02 GMT"}],"update_date":"2020-11-18"}
{"id":"2010.12587","submitter":"Murray Brightman","authors":"Murray Brightman, Charlotte Ward, Daniel Stern, Kunal Mooley, Kishalay\n  De, Suvi Gezari, Sjoert Van Velzen, Igor Andreoni, Matthew Graham, Frank J.\n  Masci, Reed Riddle, Jeffry Zolkower","title":"A luminous X-ray transient in SDSS J143359.16+400636.0: a likely tidal\n  disruption event","comments":"Accepted for publication by ApJ. Accepted version now replaces\n  initial submission","journal-ref":null,"doi":"10.3847/1538-4357/abde34","report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the discovery of a luminous X-ray transient, serendipitously\ndetected by Swift's X-ray Telescope (XRT) on 2020 February 5, located in the\nnucleus of the galaxy SDSS J143359.16+400636.0 at z=0.099 (luminosity distance\n$D_{\\rm L}=456$ Mpc). The transient was observed to reach a peak luminosity of\n$\\sim10^{44}$ erg s$^{-1}$ in the 0.3--10 keV X-ray band, which was $\\sim20$\ntimes more than the peak optical/UV luminosity. Optical, UV, and X-ray\nlightcurves from the Zwicky Transient Facility (ZTF) and Swift show a decline\nin flux from the source consistent with $t^{-5/3}$, and observations with\nNuSTAR and Chandra show a soft X-ray spectrum with photon index\n$\\Gamma=2.9\\pm0.1$. The X-ray/UV properties are inconsistent with well known\nAGN properties and have more in common with known X-ray tidal disruption events\n(TDE), leading us to conclude that it was likely a TDE. The broadband spectral\nenergy distribution (SED) can be described well by a disk blackbody model with\nan inner disk temperature of $7.3^{+0.3}_{-0.8}\\times10^{5}$ K, with a large\nfraction ($>40$%) of the disk emission up-scattered into the X-ray band. An\noptical spectrum taken with Keck/LRIS after the X-ray detection reveals LINER\nline ratios in the host galaxy, suggesting low-level accretion on to the\nsupermassive black hole prior to the event, but no broad lines or other\nindications of a TDE were seen. The stellar velocity dispersion implies the\nmass of the supermassive black hole powering the event is log($M_{\\rm\nBH}$/$M_{\\odot}$)$=7.41\\pm0.41$, and we estimate that at peak the Eddington\nfraction of this event was $\\sim$50%. This likely TDE was not identified by\nwide-field optical surveys, nor optical spectroscopy, indicating that more\nevents like this would be missed without wide-field UV or X-ray surveys.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:03 GMT"},{"version":"v2","created":"Fri, 29 Jan 2021 23:46:14 GMT"}],"update_date":"2021-03-17"}
{"id":"2010.12588","submitter":"Chao Wang","authors":"Chao Wang, Yoni Schattner, Steven A. Kivelson","title":"Nematic Antiferromagnetism and Deconfined Criticality from the Interplay\n  between Electron-Phonon and Electron-Electron Interactions","comments":null,"journal-ref":"Phys. Rev. B 104, 081110 (2021)","doi":"10.1103/PhysRevB.104.L081110","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Systems with strong electron-phonon couplings typically exhibit various forms\nof charge order, while strong electron-electron interactions lead to magnetism.\nWe use determinant quantum Monte Carlo (DQMC) calculations to solve a model on\na square lattice with a caricature of these interactions. In the limit where\nelectron-electron interactions dominate it has antiferromagnetic (AF) order,\nwhile where electron-phonon coupling dominates there is columnar valence-bond\nsolid (VBS) order. We find a novel intervening phase that hosts coexisting\nnematic and antiferromagnetic orders. We have also found evidence of a\nLandau-forbidden continuous quantum phase transition with an emergent $O(4)$\nsymmetry between the VBS and the nematic antiferromagnetic phases.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:03 GMT"}],"update_date":"2021-08-25"}
{"id":"2010.12589","submitter":"Ruari Mackenzie","authors":"Ruari Mackenzie, Gabriele Pezzulli, Sebastiano Cantalupo, Raffaella A.\n  Marino, Simon Lilly, Sowgat Muzahid, Jorryt Matthee, Joop Schaye, Lutz\n  Wisotzki","title":"Revealing the Impact of Quasar Luminosity on Giant Ly$\\alpha$ Nebulae","comments":"Accepted to MNRAS. 17 pages, 7 figures","journal-ref":null,"doi":"10.1093/mnras/staa3277","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the results from a MUSE survey of twelve $z\\simeq3.15$ quasars,\nwhich were selected to be much fainter (20<i<23) than in previous studies of\nGiant Ly$\\alpha$ Nebulae around the brightest quasars (16.6<i<18.7). We detect\nHI Ly$\\alpha$ nebulae around 100% of our target quasars, with emission\nextending to scales of at least 60 physical kpc, and up to 190 pkpc. We explore\ncorrelations between properties of the nebulae and their host quasars, with the\ngoal of connecting variations in the properties of the illuminating QSO to the\nresponse in nebular emission. We show that the surface brightness profiles of\nthe nebulae are similar to those of nebulae around bright quasars, but with a\nlower normalization. Our targeted quasars are on average 3.7 magnitudes (~30\ntimes) fainter in UV continuum than our bright reference sample, and yet the\nnebulae around them are only 4.3 times fainter in mean Ly$\\alpha$ surface\nbrightness, measured between 20 and 50 pkpc. We find significant correlations\nbetween the surface brightness of the nebula and the luminosity of the quasar\nin both UV continuum and Ly$\\alpha$. The latter can be interpreted as evidence\nfor a substantial contribution from unresolved inner parts of the nebulae to\nthe narrow components seen in the Ly$\\alpha$ lines of some of our faint\nquasars, possibly from the inner CGM or from the host galaxy's ISM.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:05 GMT"}],"update_date":"2020-11-04"}
{"id":"2010.12590","submitter":"Justin Spilker","authors":"Justin S. Spilker, Kedar A. Phadke, Manuel Aravena, Matthieu\n  Bethermin, Scott C. Chapman, Chenxing Dong, Anthony H. Gonzalez, Christopher\n  C. Hayward, Yashar D. Hezaveh, Sreevani Jarugula, Katrina C. Litke, Matthew\n  A. Malkan, Daniel P. Marrone, Desika Narayanan, Cassie Reuter, Joaquin D.\n  Vieira, Axel Weiss","title":"Ubiquitous Molecular Outflows in z > 4 Massive, Dusty Galaxies I. Sample\n  Overview and Clumpy Structure in Molecular Outflows on 500pc Scales","comments":"ApJ accepted. 28 pages, 12 figures + appendix. Data and tables from\n  Papers I and II available at https://github.com/spt-smg/publicdata","journal-ref":null,"doi":"10.3847/1538-4357/abc47f","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Massive galaxy-scale outflows of gas are one of the most commonly-invoked\nmechanisms to regulate the growth and evolution of galaxies throughout the\nuniverse. While the gas in outflows spans a large range of temperatures and\ndensities, the cold molecular phase is of particular interest because molecular\noutflows may be capable of suppressing star formation in galaxies by removing\nthe star-forming gas. We have conducted the first survey of molecular outflows\nat z > 4, targeting 11 strongly-lensed dusty, star-forming galaxies (DSFGs)\nwith high-resolution Atacama Large Millimeter Array (ALMA) observations of OH\n119um absorption as an outflow tracer. In this first paper, we give an overview\nof the survey, focusing on the detection rate and structure of molecular\noutflows. We find unambiguous evidence for outflows in 8/11 (73%) galaxies,\nmore than tripling the number known at z > 4. This implies that molecular winds\nin z > 4 DSFGs must have both a near-unity occurrence rate and large opening\nangles to be detectable in absorption. Lensing reconstructions reveal that\n500pc-scale clumpy structures in the outflows are common. The individual clumps\nare not directly resolved, but from optical depth arguments we expect that\nfuture observations will require 50-200pc spatial resolution to do so. We do\nnot detect high-velocity [CII] wings in any of the sources with clear OH\noutflows, indicating that [CII] is not a reliable tracer of molecular outflows.\nOur results represent a first step toward characterizing molecular outflows at\nz > 4 at the population level, demonstrating that large-scale outflows are\nubiquitous among early massive, dusty galaxies.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:12 GMT"}],"update_date":"2020-12-23"}
{"id":"2010.12591","submitter":"Justin Spilker","authors":"Justin S. Spilker, Manuel Aravena, Kedar A. Phadke, Matthieu\n  Bethermin, Scott C. Chapman, Chenxing Dong, Anthony H. Gonzalez, Christopher\n  C. Hayward, Yashar D. Hezaveh, Katrina C. Litke, Matthew A. Malkan, Daniel P.\n  Marrone, Desika Narayanan, Cassie Reuter, Joaquin D. Vieira, Axel Weiss","title":"Ubiquitous Molecular Outflows in z > 4 Massive, Dusty Galaxies II.\n  Momentum-Driven Winds Powered by Star Formation in the Early Universe","comments":"ApJ accepted. 25 pages, 16 figures. Data and tables from Papers I and\n  II available at https://github.com/spt-smg/publicdata","journal-ref":null,"doi":"10.3847/1538-4357/abc4e6","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Galactic outflows of molecular gas are a common occurrence in galaxies and\nmay represent a mechanism by which galaxies self-regulate their growth,\nredistributing gas that could otherwise have formed stars. We previously\npresented the first survey of molecular outflows at z > 4 towards a sample of\nmassive, dusty galaxies. Here we characterize the physical properties of the\nmolecular outflows discovered in our survey. Using low-redshift outflows as a\ntraining set, we find agreement at the factor-of-two level between several\noutflow rate estimates. We find molecular outflow rates 150-800Msun/yr and\ninfer mass loading factors just below unity. Among the high-redshift sources,\nthe molecular mass loading factor shows no strong correlations with any other\nmeasured quantity. The outflow energetics are consistent with expectations for\nmomentum-driven winds with star formation as the driving source, with no need\nfor energy-conserving phases. There is no evidence for AGN activity in our\nsample, and while we cannot rule out deeply-buried AGN, their presence is not\nrequired to explain the outflow energetics, in contrast to nearby obscured\ngalaxies with fast outflows. The fraction of the outflowing gas that will\nescape into the circumgalactic medium (CGM), though highly uncertain, may be as\nhigh as 50%. This nevertheless constitutes only a small fraction of the total\ncool CGM mass based on a comparison to z~2-3 quasar absorption line studies,\nbut could represent >~10% of the CGM metal mass. Our survey offers the first\nstatistical characterization of molecular outflow properties in the very early\nuniverse.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:13 GMT"}],"update_date":"2020-12-23"}
{"id":"2010.12592","submitter":"Akash Goel","authors":"Akash Goel, Luca V. Iliesiu, Jorrit Kruthoff, Zhenbin Yang","title":"Classifying boundary conditions in JT gravity: from energy-branes to\n  $\\alpha$-branes","comments":"65 pages, 6 figures; v2: published version","journal-ref":null,"doi":"10.1007/JHEP04(2021)069","report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We classify the possible boundary conditions in JT gravity and discuss their\nexact quantization. Each boundary condition that we study will reveal new\nfeatures in JT gravity related to its matrix integral interpretation, its\nfactorization properties and ensemble averaging interpretation, the definition\nof the theory at finite cutoff, its relation to the physics of near-extremal\nblack holes and, finally, its role as a two-dimensional model of cosmology.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:15 GMT"},{"version":"v2","created":"Wed, 3 Mar 2021 21:03:37 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12593","submitter":"Ivonne Alicia Maldonado Cervantes","authors":"Alejandro Ayala, Eleazar Cuautle, Isabel Dom\\'inguez, M.\n  Rodr\\'iguez-Cahuantzi, Ivonne Maldonado and Mar\\'ia Elena Tejeda-Yeomans","title":"Hyperons from Bi+Bi collisions at MPD-NICA: Preliminary analysis of\n  production at generation, simulation and reconstruction level","comments":"9 pages, 20 figures. This is a preprint of the proceeding of the\n  Conference \"RFBR grants for NICA\" that will send to the journal Physics of\n  elementary particles and atomic nuclei, year 2021, volume 3","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ex hep-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  An important observable to understand the properties of the matter produced\nin heavy-ion collisions is its strangeness content. Recent experimental results\nshow that in semi-central collisions, the $\\Lambda$ and $\\bar{\\Lambda}$ global\npolarization show differences that increase at low energies. This behaviour has\nbeen described using a model where these particles may be produced from two\ndistinct density zones in the collision region: the core and the corona where\nQGP processes and p + p like reactions, respectively, are mainly at work. Using\nthis idea, the polarization can be influenced by the relative abundance of\nthese particles coming from either regions. In this work we show how to test\nthis model in the MPD experiment.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:00:29 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12594","submitter":"G J Sreejith","authors":"Abhishek Anand, Jainendra K Jain, G J Sreejith","title":"An Exactly Solvable Model for Strongly Interacting Electrons in a\n  Magnetic Field","comments":null,"journal-ref":"Phys. Rev. Lett. 126, 136601 (2021)","doi":"10.1103/PhysRevLett.126.136601","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  States of strongly interacting particles are of fundamental interest in\nphysics, and can produce exotic emergent phenomena and topological structures.\nWe consider here two-dimensional electrons in a magnetic field, and, departing\nfrom the standard practice of restricting to the lowest LL, introduce a model\nshort-range interaction that is infinitely strong compared to the cyclotron\nenergy. We demonstrate that this model lends itself to an exact solution for\nthe ground as well as excited states at arbitrary filling factors $\\nu<1/2p$\nand produces a fractional quantum Hall effect at fractions of the form\n$\\nu=n/(2pn+ 1)$, where n and p are integers. The fractional quantum Hall\nstates of our model share many topological properties with the corresponding\nCoulomb ground states in the lowest Landau level, such as the edge physics and\nthe fractional charge of the excitations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:01:24 GMT"},{"version":"v2","created":"Sun, 21 Mar 2021 11:24:53 GMT"}],"update_date":"2022-03-16"}
{"id":"2010.12595","submitter":"Fernando Custodio Cerqueira-Campos","authors":"F. C. Cerqueira-Campos, A. Rodr\\'iguez-Ardila, R. Riffell, M.\n  Marinello, A. Prieto, L. G. Dahmer-Hahn","title":"Coronal Line Forest AGN I: physical properties of the emission-line\n  regions","comments":"30 pages, 25 figures, to be published in MNRAS","journal-ref":null,"doi":"10.1093/mnras/staa3320","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coronal-Line Forest Active Galactic Nuclei (CLiF AGN) are characterized by\nstrong high-ionization lines, which contrast to what is found in most AGNs.\nHere, we carry out a multiwavelength analysis aimed at understanding the\nphysical processes in the Narrow Line Region (NLR) of these objects and\nunveiling if they are indeed a special class of AGN. By comparing coronal\nemission-line ratios we conclude that there are no differences between CLiF and\nnon-CLiF AGNs. We derive physical conditions of the narrow line region (NLR)\ngas and found electron densities in the range $3.6\\times$10$^{2}$ -\n$1.7\\times$10$^{4}$ cm$^{-3}$ and temperatures of $3.7\\times$10$^{3}$ -\n$6.3\\times$10$^{4}$ K, suggesting that the ionization mechanism is associated\nprimarily with photoionization by the AGN. We suggest a NLR dominated by\nmatter-bounded clouds to explain the high-ionization line spectrum observed.\nThe mass of the central black hole, derived from the stellar velocity\ndispersion show that most of the objects have values in the interval\n10$^{7-8}$~M$\\odot$. Our results imply that CLiF AGN is not a separate category\nof AGNs. In all optical/near-infrared emission-line properties analyzed, they\nrepresent an extension to the low/high ends of the distribution within the AGN\nclass.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:03:18 GMT"}],"update_date":"2020-12-02"}
{"id":"2010.12596","submitter":"David Shikumo Mr.","authors":"David Haritone Shikumo, Oluoch Oluoch and Joshua Matanda Wepukhulu","title":"Effect of Long-Term Debt on the Financial Growth of Non-Financial Firms\n  Listed at the Nairobi Securities Exchange","comments":"9 pages","journal-ref":"http://www.iosrjournals.org/iosr-jef/papers/Vol11-Issue5/Series-2/A1105020109.pdf\n  2020","doi":"10.9790/5933-1105020109","report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A significant number of the non-financial firms listed at Nairobi Securities\nExchange (NSE) have been experiencing declining financial performance which\ndeter investors from investing in such firms. The lenders are also not willing\nto lend to such firms. As such, the firms struggle to raise funds for their\noperations. Prudent financing decisions can lead to financial growth of the\nfirm. The purpose of this study is to assess the effect of Long-term debt on\nthe financial growth of Non-financial firms listed at Nairobi Securities\nExchange. Financial firms were excluded because of their specific sector\ncharacteristics and stringent regulatory framework. The study is guided by\nTrade-Off Theory and Theory of Growth of the Firm. Explanatory research design\nwas adopted. The population of the study comprised of 45 non-financial firms\nlisted at the NSE for a period of ten years from 2008 to 2017. The study\nconducted both descriptive statistics analysis and panel data analysis. The\nresult indicates that Long term debt explains 21.6% and 5.16% of variation in\nfinancial growth as measured by growth in earnings per share and growth in\nmarket capitalization respectively. Long term debt positively and significantly\ninfluences financial growth measured using both growth in earnings per share\nand growth in market capitalization. The study recommends that, the management\nof non-financial firms listed at Nairobi Securities Exchange to employ\nfinancing means that can improve the earnings per share, market capitalization\nand enhance the value of the firm for the benefit of its stakeholders.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:03:47 GMT"},{"version":"v2","created":"Sat, 21 Nov 2020 11:23:12 GMT"},{"version":"v3","created":"Fri, 12 Nov 2021 10:00:00 GMT"}],"update_date":"2021-11-15"}
{"id":"2010.12597","submitter":"Andreas Andreakis","authors":"Andreas Andreakis, Ioannis Papapanagiotou","title":"DBLog: A Watermark Based Change-Data-Capture Framework","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It is a commonly observed pattern for applications to utilize multiple\nheterogeneous databases where each is used to serve a specific need such as\nstoring the canonical form of data or providing advanced search capabilities.\nFor applications it is hence desired to keep multiple databases in sync. We\nhave observed a series of distinct patterns that have tried to solve this\nproblem such as dual-writes and distributed transactions. However, these\napproaches have limitations with regard to feasibility, robustness, and\nmaintenance. An alternative approach that has recently emerged is to utilize\nChange-Data-Capture (CDC) in order to capture changed rows from a database's\ntransaction log and eventually deliver them downstream with low latency. In\norder to solve the data synchronization problem one also needs to replicate the\nfull state of a database and transaction logs typically do not contain the full\nhistory of changes. At the same time, there are use cases that require high\navailability of the transaction log events so that databases stay as closely\nin-sync as possible.\n  To address the above challenges, we developed a novel CDC framework for\ndatabases, namely DBLog. DBLog utilizes a watermark based approach that allows\nus to interleave transaction log events with rows that we directly select from\ntables to capture the full state. Our solution allows log events to continue\nprogress without stalling while processing selects. Selects can be triggered at\nany time on all tables, a specific table, or for specific primary keys of a\ntable. DBLog executes selects in chunks and tracks progress, allowing them to\npause and resume. The watermark approach does not use locks and has minimum\nimpact on the source. DBLog is currently used in production by tens of\nmicroservices at Netflix.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:06:26 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12598","submitter":"Luis Rosero","authors":"Luis Alberto Rosero, Iago Pacheco Gomes, J\\'unior Anderson Rodrigues\n  da Silva, Tiago Cesar dos Santos, Angelica Tiemi Mizuno Nakamura, Jean Amaro,\n  Denis Fernando Wolf and Fernando Santos Os\\'orio","title":"A Software Architecture for Autonomous Vehicles: Team LRM-B Entry in the\n  First CARLA Autonomous Driving Challenge","comments":"16 pages, 12 figures, preprint submitted to Journal of Systems\n  Architecture","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The objective of the first CARLA autonomous driving challenge was to deploy\nautonomous driving systems to lead with complex traffic scenarios where all\nparticipants faced the same challenging traffic situations. According to the\norganizers, this competition emerges as a way to democratize and to accelerate\nthe research and development of autonomous vehicles around the world using the\nCARLA simulator contributing to the development of the autonomous vehicle area.\nTherefore, this paper presents the architecture design for the navigation of an\nautonomous vehicle in a simulated urban environment that attempts to commit the\nleast number of traffic infractions, which used as the baseline the original\narchitecture of the platform for autonomous navigation CaRINA 2. Our agent\ntraveled in simulated scenarios for several hours, demonstrating his\ncapabilities, winning three out of the four tracks of the challenge, and being\nranked second in the remaining track.\n  Our architecture was made towards meeting the requirements of CARLA\nAutonomous Driving Challenge and has components for obstacle detection using 3D\npoint clouds, traffic signs detection and classification which employs\nConvolutional Neural Networks (CNN) and depth information, risk assessment with\ncollision detection using short-term motion prediction, decision-making with\nMarkov Decision Process (MDP), and control using Model Predictive Control\n(MPC).\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:07:48 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12599","submitter":"Stoyan Dimitrov","authors":"S. I. Dimitrov","title":"A Bombieri -- Vinogradov type result for exponential sums over\n  Piatetski-Shapiro primes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we establish a theorem of Bombieri -- Vinogradov type for\nexponential sums over Piatetski-Shapiro primes $p= [n^{1/\\gamma}]$ with\n$\\frac{865}{886}<\\gamma < 1$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:11:22 GMT"},{"version":"v2","created":"Fri, 20 Nov 2020 16:23:48 GMT"},{"version":"v3","created":"Thu, 21 Apr 2022 00:39:07 GMT"}],"update_date":"2022-04-22"}
{"id":"2010.12600","submitter":"William Lemaire","authors":"William Lemaire (1), Maher Benhouria (1), Konin Koua (1), Wei Tong\n  (2), Gabriel Martin-Hardy (1), Melanie Stamp (3), Kumaravelu Ganesan (3),\n  Louis-Philippe Gauthier (1), Marwan Besrour (1), Arman Ahnood (4), David John\n  Garrett (4), S\\'ebastien Roy (1), Michael Ibbotson (2,5), Steven Prawer (3),\n  R\\'ejean Fontaine (1) ((1) Interdisciplinary Institute for Technological\n  Innovation (3IT), Universit\\'e de Sherbrooke, Sherbrooke, Quebec, Canada, (2)\n  National Vision Research Institute, Australian College of Optometry, Carlton,\n  Victoria, Australia, (3) School of Physics, The University of Melbourne,\n  Parkville, Victoria, Australia, (4) School of Engineering, RMIT University,\n  Melbourne, Victoria, Australia, (5) Department of Optometry and Vision\n  Sciences, The University of Melbourne, Parkville, Victoria, Australia)","title":"Retinal Ganglion Cell Stimulation with an Optically Powered Retinal\n  Prosthesis","comments":"17 pages, 13 figures, to be submitted to IEEE Transactions on\n  Biomedical Circuits and Systems","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Objective. Clinical trials previously demonstrated the spectacular capacity\nto elicit visual percepts in blind patients affected with retinal diseases by\nelectrically stimulating the remaining neurons on the retina. However, these\nimplants restored very limited visual acuity and required transcutaneous cables\ntraversing the eyeball, leading to reduced reliability and complex surgery with\nhigh postoperative infection risks. Approach. To overcome the limitations\nimposed by cables, a retinal implant architecture in which near-infrared\nillumination carries both power and data through the pupil is presented. A high\nefficiency multi-junction photovoltaic cell transduces the optical power to a\nCMOS stimulator capable of delivering flexible interleaved sequential\nstimulation through a diamond microelectrode array. To demonstrate the capacity\nto elicit a neural response with this approach while complying with the optical\nirradiance safety limit at the pupil, fluorescence imaging with a calcium\nindicator is used on a degenerate rat retina. Main results. The power delivered\nby the laser at safe irradiance of 4 mW/mm2 is shown to be sufficient to both\npower the stimulator ASIC and elicit a response in retinal ganglion cells\n(RGCs), with the ability to generate of up to 35 000 pulses per second at the\naverage stimulation threshold. Significance. This confirms the feasibility of\nwirelessly generating a response in RGCs with a digital stimulation controller\nthat can deliver complex multipolar stimulation patterns at high repetition\nrates.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:11:56 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12601","submitter":"Edwin Huang","authors":"Edwin W. Huang","title":"Strong-coupling mechanism of the pseudogap in small Hubbard clusters","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the hole-doped cuprates, the pseudogap refers to a suppression of the\ndensity of states at low energies, in the absence of superconducting long-range\norder. Numerous calculations of the Hubbard model show a pseudogap in the\nsingle-particle spectra, with striking similarities to photoemission and\ntunneling experiments on cuprates. However, no clear mechanism has been\nestablished. Here, we solve the Hubbard model on $2\\times2$ clusters by exact\ndiagonalization, with integration over twisted boundary conditions. A pseudogap\nis found in the single-particle density of states with the following\ncharacteristics: a decreasing energy scale and onset temperature for increased\nhole-doping, closure at a critical hole doping near 15\\%, absence upon\nelectron-doping, particle-hole asymmetry indicated by the location of the gap\ncenter, and persistence in the strong-coupling limit of $U/t \\to \\infty$.\nStudying the many-body excitation spectrum reveals that the pseudogap in\nsingle-particle spectra is due to orthogonality between bare electrons and the\nlowest energy excitations for $U/t \\gtrsim 8$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:13:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12602","submitter":"Rajsekhar Mohapatra","authors":"Rajsekhar Mohapatra, Christoph Federrath, Prateek Sharma","title":"Turbulent density and pressure fluctuations in the stratified\n  intracluster medium","comments":"18 pages, 11 figures; MNRAS accepted version; follow-up study of\n  arXiv:2001.06494; simulation movies at\n  https://www.youtube.com/playlist?list=PLuaNgQ1v_KMYHZryKHgstRQe80ZRakr35","journal-ref":null,"doi":"10.1093/mnras/staa3564","report-no":null,"categories":"astro-ph.GA astro-ph.CO physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Turbulent gas motions are observed in the intracluster medium (ICM). The ICM\nis density-stratified, with the gas density being highest at the centre of the\ncluster and decreasing radially outwards. As a result of this, Kolmogorov\n(homogeneous, isotropic) turbulence theory does not apply to the ICM. The gas\nmotions are instead explained by anisotropic stratified turbulence, with the\nstratification quantified by the perpendicular Froude number\n($\\mathrm{Fr}_\\perp$). These turbulent motions are associated with density and\npressure fluctuations, which manifest as perturbations in X-ray surface\nbrightness maps of the ICM and as thermal Sunyaev-Zeldovich effect (SZ)\nfluctuations, respectively. In order to advance our understanding of the\nrelations between these fluctuations and the turbulent gas velocities, we have\nconducted 100 high-resolution hydrodynamic simulations of stratified turbulence\n($256^2\\times 384$ -- $1024^2\\times1536$ resolution elements), in which we scan\nthe parameter space of subsonic rms Mach number ($\\mathcal{M}$),\n$\\mathrm{Fr}_\\perp$, and the ratio of entropy and pressure scale heights\n($R_{PS}=H_P/H_S$), relevant to the ICM. We develop a new scaling relation\nbetween the standard deviation of logarithmic density fluctuations ($\\sigma_s$,\nwhere $s=\\ln(\\rho/\\left<\\rho\\right>)$), $\\mathcal{M}$, and\n$\\mathrm{Fr}_{\\perp}$, valid till\n$\\mathrm{Fr}_\\perp\\ll1$:~$\\sigma_s^2=\\ln\\left(1+b^2\\mathcal{M}^4+0.10/(\\mathrm{Fr}_\\perp+0.25/\\sqrt{\\mathrm{Fr}_\\perp})^2\\mathcal{M}^2R_{PS}\\right)$,\nwhere $b\\sim1/3$ for solenoidal turbulence driving studied here. We further\nfind that logarithmic pressure fluctuations $\\sigma_{(\\ln{P}/\\left<P\\right>)}$\nare independent of stratification and scale according to the relation\n$\\sigma_{(\\ln{\\bar{P}})}^2=\\ln\\left(1+b^2\\gamma^2\\mathcal{M}^4\\right)$, where\n$\\bar{P}=P/\\left<P\\right>$ and $\\gamma$ is the adiabatic index of the gas.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:14:34 GMT"},{"version":"v2","created":"Thu, 3 Dec 2020 02:15:52 GMT"}],"update_date":"2020-12-04"}
{"id":"2010.12603","submitter":"Ryan McKenna","authors":"Ryan McKenna and Daniel Sheldon","title":"Permute-and-Flip: A new mechanism for differentially private selection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the problem of differentially private selection. Given a finite\nset of candidate items and a quality score for each item, our goal is to design\na differentially private mechanism that returns an item with a score that is as\nhigh as possible. The most commonly used mechanism for this task is the\nexponential mechanism. In this work, we propose a new mechanism for this task\nbased on a careful analysis of the privacy constraints. The expected score of\nour mechanism is always at least as large as the exponential mechanism, and can\noffer improvements up to a factor of two. Our mechanism is simple to implement\nand runs in linear time.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:20:26 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12604","submitter":"Eduardo Pavez","authors":"Eduardo Pavez, Benjamin Girault, Antonio Ortega, Philip A. Chou","title":"Spectral folding and two-channel filter-banks on arbitrary graphs","comments":"submitted to ICASSP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the past decade, several multi-resolution representation theories for\ngraph signals have been proposed. Bipartite filter-banks stand out as the most\nnatural extension of time domain filter-banks, in part because perfect\nreconstruction, orthogonality and bi-orthogonality conditions in the graph\nspectral domain resemble those for traditional filter-banks. Therefore, many of\nthe well known orthogonal and bi-orthogonal designs can be easily adapted for\ngraph signals. A major limitation is that this framework can only be applied to\nthe normalized Laplacian of bipartite graphs. In this paper we extend this\ntheory to arbitrary graphs and positive semi-definite variation operators. Our\napproach is based on a different definition of the graph Fourier transform\n(GFT), where orthogonality is defined with the respect to the Q inner product.\nWe construct GFTs satisfying a spectral folding property, which allows us to\neasily construct orthogonal and bi-orthogonal perfect reconstruction\nfilter-banks. We illustrate signal representation and computational efficiency\nof our filter-banks on 3D point clouds with hundreds of thousands of points.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:21:22 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12605","submitter":"Alban Farchi","authors":"Alban Farchi and Patrick Laloyaux and Massimo Bonavita and Marc\n  Bocquet","title":"Using machine learning to correct model error in data assimilation and\n  forecast applications","comments":null,"journal-ref":null,"doi":"10.1002/qj.4116","report-no":null,"categories":"stat.ML cs.LG physics.data-an","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The idea of using machine learning (ML) methods to reconstruct the dynamics\nof a system is the topic of recent studies in the geosciences, in which the key\noutput is a surrogate model meant to emulate the dynamical model. In order to\ntreat sparse and noisy observations in a rigorous way, ML can be combined to\ndata assimilation (DA). This yields a class of iterative methods in which, at\neach iteration a DA step assimilates the observations, and alternates with a ML\nstep to learn the underlying dynamics of the DA analysis. In this article, we\npropose to use this method to correct the error of an existent, knowledge-based\nmodel. In practice, the resulting surrogate model is an hybrid model between\nthe original (knowledge-based) model and the ML model. We demonstrate\nnumerically the feasibility of the method using a two-layer, two-dimensional\nquasi-geostrophic channel model. Model error is introduced by the means of\nperturbed parameters. The DA step is performed using the strong-constraint\n4D-Var algorithm, while the ML step is performed using deep learning tools. The\nML models are able to learn a substantial part of the model error and the\nresulting hybrid surrogate models produce better short- to mid-range forecasts.\nFurthermore, using the hybrid surrogate models for DA yields a significantly\nbetter analysis than using the original model.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:30:45 GMT"},{"version":"v2","created":"Mon, 10 May 2021 06:46:32 GMT"}],"update_date":"2021-09-22"}
{"id":"2010.12606","submitter":"Roland Zimmermann","authors":"Judy Borowski, Roland S. Zimmermann, Judith Schepers, Robert Geirhos,\n  Thomas S. A. Wallis, Matthias Bethge, Wieland Brendel","title":"Exemplary Natural Images Explain CNN Activations Better than\n  State-of-the-Art Feature Visualization","comments":"Published at ICLR 2021. Joint first and last authors. Code is\n  available at https://bethgelab.github.io/testing_visualizations/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.HC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Feature visualizations such as synthetic maximally activating images are a\nwidely used explanation method to better understand the information processing\nof convolutional neural networks (CNNs). At the same time, there are concerns\nthat these visualizations might not accurately represent CNNs' inner workings.\nHere, we measure how much extremely activating images help humans to predict\nCNN activations. Using a well-controlled psychophysical paradigm, we compare\nthe informativeness of synthetic images by Olah et al. (2017) with a simple\nbaseline visualization, namely exemplary natural images that also strongly\nactivate a specific feature map. Given either synthetic or natural reference\nimages, human participants choose which of two query images leads to strong\npositive activation. The experiments are designed to maximize participants'\nperformance, and are the first to probe intermediate instead of final layer\nrepresentations. We find that synthetic images indeed provide helpful\ninformation about feature map activations ($82\\pm4\\%$ accuracy; chance would be\n$50\\%$). However, natural images - originally intended as a baseline -\noutperform synthetic images by a wide margin ($92\\pm2\\%$). Additionally,\nparticipants are faster and more confident for natural images, whereas\nsubjective impressions about the interpretability of the feature visualizations\nare mixed. The higher informativeness of natural images holds across most\nlayers, for both expert and lay participants as well as for hand- and\nrandomly-picked feature visualizations. Even if only a single reference image\nis given, synthetic images provide less information than natural images\n($65\\pm5\\%$ vs. $73\\pm4\\%$). In summary, synthetic images from a popular\nfeature visualization method are significantly less informative for assessing\nCNN activations than natural images. We argue that visualization methods should\nimprove over this baseline.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:31:13 GMT"},{"version":"v2","created":"Tue, 12 Jan 2021 10:00:47 GMT"},{"version":"v3","created":"Sun, 2 May 2021 19:27:06 GMT"}],"update_date":"2021-05-04"}
{"id":"2010.12607","submitter":"Ra\\'ul Nozal","authors":"Ra\\'ul Nozal, Jose Luis Bosque and Ramon Beivide","title":"Towards Co-execution on Commodity Heterogeneous Systems: Optimizations\n  for Time-Constrained Scenarios","comments":"8 pages, 6 figures, conference","journal-ref":"2019 International Conference on High Performance Computing &\n  Simulation (HPCS), pp. 628-635","doi":"10.1109/HPCS48598.2019.9188188","report-no":null,"categories":"cs.DC cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Heterogeneous systems are present from powerful supercomputers, to mobile\ndevices, including desktop computers, thanks to their excellent performance and\nenergy consumption. The ubiquity of these architectures in both desktop systems\nand medium-sized service servers allow enough variability to exploit a wide\nrange of problems, such as multimedia workloads, video encoding, image\nfiltering and inference in machine learning. Due to the heterogeneity, some\nefforts have been done to reduce the programming effort and preserve\nperformance portability, but these systems include a set of challenges. The\ncontext in which applications offload the workload along with the management\noverheads introduced when doing co-execution, penalize the performance gains\nunder time-constrained scenarios. Therefore, this paper proposes optimizations\nfor the EngineCL runtime to reduce the penalization when co-executing in\ncommodity systems, as well as algorithmic improvements when load balancing. An\nexhaustive experimental evaluation is performed, showing optimization\nimprovements of 7.5\\% and 17.4\\% for binary and ROI-based offloading modes,\nrespectively. Thanks to all the optimizations, the new load balancing algorithm\nis always the most efficient scheduling configuration, achieving an average\nefficiency of 0.84 under a pessimistic scenario.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:32:27 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12608","submitter":"Andrii Kyrylchuk","authors":"Alexander Quandt, Andrii Kyrylchuk, Gotthard Seifert, David Tom\\'anek","title":"Liquid Flow through Defective Layered Membranes: A Phenomenological\n  Description","comments":"10 pages, 4 figures","journal-ref":"Phys. Rev. Applied 14, 044038 (2020)","doi":"10.1103/PhysRevApplied.14.044038","report-no":null,"categories":"cond-mat.mtrl-sci physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a realistic phenomenological description of liquid transport\nthrough defective, layered membranes. We derive general expressions based on\nconventional models of laminar flow and extend the formalism to accommodate\nslip flow. We consider different types of defects including in-layer vacancies\nthat provide an activation-free tortuous path through the membrane. Of the many\nfactors that affect flow, the most important is the radius of in-layer vacancy\ndefects, which enters in the fourth power in expressions for the flux density.\nWe apply our formalism to water transport through defective multilayer graphene\noxide membranes and find that the flow remains in the laminar regime. Our\nresults show that observed high water permeability in this system can be\nexplained quantitatively by a sufficient density of in-layer pores that shorten\nthe effective diffusion path.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:36:06 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12609","submitter":"Hanlin Zhang","authors":"Hanlin Zhang, Shuai Lin, Weiyang Liu, Pan Zhou, Jian Tang, Xiaodan\n  Liang, Eric P. Xing","title":"Iterative Graph Self-Distillation","comments":"The Workshop on Self-Supervised Learning for the Web","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, there has been increasing interest in the challenge of how to\ndiscriminatively vectorize graphs. To address this, we propose a method called\nIterative Graph Self-Distillation (IGSD) which learns graph-level\nrepresentation in an unsupervised manner through instance discrimination using\na self-supervised contrastive learning approach. IGSD involves a\nteacher-student distillation process that uses graph diffusion augmentations\nand constructs the teacher model using an exponential moving average of the\nstudent model. The intuition behind IGSD is to predict the teacher network\nrepresentation of the graph pairs under different augmented views. As a natural\nextension, we also apply IGSD to semi-supervised scenarios by jointly\nregularizing the network with both supervised and self-supervised contrastive\nloss. Finally, we show that finetuning the IGSD-trained models with\nself-training can further improve the graph representation power. Empirically,\nwe achieve significant and consistent performance gain on various graph\ndatasets in both unsupervised and semi-supervised settings, which well\nvalidates the superiority of IGSD.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:37:06 GMT"},{"version":"v2","created":"Fri, 13 Aug 2021 09:29:07 GMT"},{"version":"v3","created":"Tue, 3 Jan 2023 22:09:23 GMT"}],"update_date":"2023-01-05"}
{"id":"2010.12610","submitter":"Ismail El Baggari","authors":"Ismail El Baggari, David J. Baek, Michael J. Zachman, Di Lu, Yasuyuki\n  Hikita, Harold Y. Hwang, Elizabeth A. Nowadnick, Lena F. Kourkoutis","title":"Charge order textures induced by non-linear lattice coupling in a\n  half-doped manganite","comments":null,"journal-ref":null,"doi":"10.1038/s41467-021-24026-7","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The self-organization of strongly interacting electrons into superlattice\nstructures underlies the properties of many quantum materials. How these\nelectrons arrange within the superlattice dictates what symmetries are broken\nand what ground states are stabilized. Here we show that cryogenic scanning\ntransmission electron microscopy enables direct mapping of local symmetries and\norder at the intra-unit-cell level in the model charge-ordered system\nNd$_{1/2}$Sr$_{1/2}$MnO$_{3}$. In addition to imaging the prototypical\nsite-centered charge order, we discover the nanoscale coexistence of an exotic\nintermediate state which mixes site and bond order and breaks inversion\nsymmetry. We further show that nonlinear coupling of distinct lattice modes\ncontrols the selection between competing ground states. The results demonstrate\nthe importance of lattice coupling for understanding and manipulating the\ncharacter of electronic self-organization and highlight a novel method for\nprobing local order in a broad range of strongly correlated systems.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:43:15 GMT"},{"version":"v2","created":"Sat, 31 Oct 2020 20:21:00 GMT"}],"update_date":"2021-07-14"}
{"id":"2010.12611","submitter":"Sorelle Friedler","authors":"Hannah C. Beilinson and Nasanbayar Ulzii-Orshikh and Ashkan\n  Bashardoust and Sorelle A. Friedler and Carlos E. Scheidegger and Suresh\n  Venkatasubramanian","title":"Clustering via Information Access in a Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Information flow in a graph (say, a social network) has typically been\nmodeled using standard influence propagation methods, with the goal of\ndetermining the most effective ways to spread information widely. More\nrecently, researchers have begun to study the differing access to information\nof individuals within a network. This previous work suggests that information\naccess is itself a potential aspect of privilege based on network position.\nWhile concerns about fairness usually focus on differences between demographic\ngroups, characterizing network position may itself give rise to new groups for\nstudy. But how do we characterize position? Rather than using standard grouping\nmethods for graph clustering, we design and explore a clustering that\nexplicitly incorporates models of how information flows on a network. Our goal\nis to identify clusters of nodes that are similar based on their access to\ninformation across the network. We show, both formally and experimentally, that\nthe resulting clustering method is a new approach to network clustering. Using\na wide variety of datasets, our experiments show that the introduced clustering\ntechnique clusters individuals together who are similar based on an external\ninformation access measure.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:46:37 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12612","submitter":"Maximiliano Isi","authors":"Maximiliano Isi, Simone Mastrogiovanni, Matthew Pitkin, and Ornella\n  Juliana Piccinni","title":"Establishing the significance of continuous gravitational-wave\n  detections from known pulsars","comments":"17 pages, 10 figures","journal-ref":"Phys. Rev. D 102, 123027 (2020)","doi":"10.1103/PhysRevD.102.123027","report-no":"LIGO-P2000413","categories":"gr-qc astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a method for assigning a statistical significance to detection\ncandidates in targeted searches for continuous gravitational waves from known\npulsars, without assuming the detector noise is Gaussian and stationary. We\ntake advantage of the expected Doppler phase modulation of the signal induced\nby Earth's orbital motion, as well as the amplitude modulation induced by\nEarth's spin, to effectively blind the search to real astrophysical signals\nfrom a given location in the sky. We use this \"sky-shifting\" to produce a large\nnumber of noise-only data realizations to empirically estimate the background\nof a search and assign detection significances, in a similar fashion to the use\nof timeslides in searches for compact binaries. We demonstrate the potential of\nthis approach by means of simulated signals, as well as hardware injections\ninto real detector data. In a study of simulated signals in non-Gaussian noise,\nwe find that our method outperforms another common strategy for evaluating\ndetection significance. We thus demonstrate that this and similar techniques\nhave the potential to enable a first confident detection of continuous\ngravitational waves.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:51:12 GMT"}],"update_date":"2021-01-04"}
{"id":"2010.12613","submitter":"Julia Siekiera","authors":"Julia Siekiera, Marius K\\\"oppel, Edwin Simpson, Kevin Stowe, Iryna\n  Gurevych, Stefan Kramer","title":"Ranking Creative Language Characteristics in Small Data Scenarios","comments":"10 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ability to rank creative natural language provides an important general\ntool for downstream language understanding and generation. However, current\ndeep ranking models require substantial amounts of labeled data that are\ndifficult and expensive to obtain for different domains, languages and creative\ncharacteristics. A recent neural approach, the DirectRanker, promises to reduce\nthe amount of training data needed but its application to text isn't fully\nexplored. We therefore adapt the DirectRanker to provide a new deep model for\nranking creative language with small data. We compare DirectRanker with a\nBayesian approach, Gaussian process preference learning (GPPL), which has\npreviously been shown to work well with sparse data. Our experiments with\nsparse training data show that while the performance of standard neural ranking\napproaches collapses with small training datasets, DirectRanker remains\neffective. We find that combining DirectRanker with GPPL increases performance\nacross different settings by leveraging the complementary benefits of both\nmodels. Our combined approach outperforms the previous state-of-the-art on\nhumor and metaphor novelty tasks, increasing Spearman's $\\rho$ by 14% and 16%\non average.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:57:47 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12614","submitter":"Fatemeh Kazemi","authors":"Fatemeh Kazemi, Sascha Kurz, Emina Soljanin, Alex Sprintson","title":"Efficient Storage Schemes for Desired Service Rate Regions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.DM math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A major concern in cloud/edge storage systems is serving a large number of\nusers simultaneously. The service rate region is introduced recently as an\nimportant performance metric for coded distributed systems, which is defined as\nthe set of all data access requests that can be simultaneously handled by the\nsystem. This paper studies the problem of designing a coded distributed storage\nsystem storing k files where a desired service rate region R of the system is\ngiven and the goal is 1) to determine the minimum number of storage nodes n(R)\n(or a lower bound on n(R)) for serving all demand vectors inside the set R and\n2) to design the most storage-efficient redundancy scheme with the service rate\nregion covering R. Towards this goal, we propose three general lower bounds for\nn(R). Also, for k=2, we characterize n(R), i.e., we show that the proposed\nlower bounds are tight via designing a novel storage-efficient redundancy\nscheme with n(R) storage nodes and the service rate region covering R.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:58:15 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12615","submitter":"Hamid Rahkooy","authors":"Hamid Rahkooy, Cristian Vargas Montero","title":"A Graph Theoretical Approach for Testing Binomiality of Reversible\n  Chemical Reaction Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SC math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study binomiality of the steady state ideals of chemical reaction\nnetworks. Considering rate constants as indeterminates, the concept of\nunconditional binomiality has been introduced and an algorithm based on linear\nalgebra has been proposed in a recent work for reversible chemical reaction\nnetworks, which has a polynomial time complexity upper bound on the number of\nspecies and reactions. In this article, using a modified version of\nspecies--reaction graphs, we present an algorithm based on graph theory which\nperforms by adding and deleting edges and changing the labels of the edges in\norder to test unconditional binomiality. We have implemented our graph\ntheoretical algorithm as well as the linear algebra one in Maple and made\nexperiments on biochemical models. Our experiments show that the performance of\nthe graph theoretical approach is similar to or better than the linear algebra\napproach, while it is drastically faster than Groebner basis and quantifier\nelimination methods.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:02:55 GMT"},{"version":"v2","created":"Thu, 14 Jan 2021 12:35:29 GMT"}],"update_date":"2021-01-15"}
{"id":"2010.12616","submitter":"Amarlingam Madapu","authors":"Komal Krishna Mogilipalepu, Sumanth Kumar Modukuri, Amarlingam Madapu\n  and Sundeep Prabhakar Chepuri","title":"Federated Deep Unfolding for Sparse Recovery","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a federated learning technique for deep algorithm\nunfolding with applications to sparse signal recovery and compressed sensing.\nWe refer to this architecture as Fed-CS. Specifically, we unfold and learn the\niterative shrinkage thresholding algorithm for sparse signal recovery without\ntransporting to a central location, the training data distributed across many\nclients. We propose a layer-wise federated learning technique, in which each\nclient uses local data to train a common model. Then we transmit only the model\nparameters of that layer from all the clients to the server, which aggregates\nthese local models to arrive at a consensus model. The proposed layer-wise\nfederated learning for sparse recovery is communication efficient and preserves\ndata privacy. Through numerical experiments on synthetic and real datasets, we\ndemonstrate Fed-CS's efficacy and present various trade-offs in terms of the\nnumber of participating clients and communications involved compared to a\ncentralized approach of deep unfolding.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:04:10 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12617","submitter":"Sara Mahdavi","authors":"S. Sara Mahdavi, Michael D. Peacock, William J. Morris, Ingrid T.\n  Spadinger","title":"Automatic dual air kerma strength treatment planning for focal\n  low-dose-rate prostate brachytherapy boost using dosimetric and geometric\n  constraints","comments":"16 pages, 3 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Purpose: Automatic planning for focal low-dose-rate prostate brachytherapy\n(LDR-PB) boost.\n  Methods: A simulated annealing approach was utilized for creating automatic\nfocal LDR-PB boost plans using both geometric (i.e. adherence of isodose\ncontours to structure contours) and dosimetric constraints. In 46 patients,\nfour unilateral focal lesion scenarios were considered as the boost region, in\nthe anterior/posterior and superior/inferior quadrants. Plans consisted of\nseeds with two air kerma strengths (0.740U and 0.351 or 0.354U) to achieve\nrequired dose coverage on these smaller focal targets. Plan characteristics\n(including PTV V100 and V150, Rectum V50, Urethra V150, and number of needles\nand seeds), were compared in terms of type of needle loading (dual vs. single\nair kerma needles), boost quadrant and prostate volume. Plans were blindly\nranked on 20 consecutive cases by two experienced radiation oncologists.\n  Results: Differences in plans generated using the two needle loading\ntechniques were not clinically significant, particularly in terms of the PTV\nV100 and V150 and Urethra V150, with single air kerma loaded needles\npotentially being more practical. A higher rectal dose was observed in the\nposterior boost quadrants (V50 >0.18), particularly in larger prostates (>40\ncc). In smaller prostates (<25 cc), obtaining adequate dose coverage while\nsparing the urethra was more challenging. 88% of the plans were considered\nclinically acceptable without (46%) or with (mostly minor) modifications.\n  Conclusions: The novel approach of using dual air kerma seeds combined with\ngeometric constraints within a simulated annealing-based automatic planning\nframework can lead to focal LDR-PB plans with high acceptability.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:05:02 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12618","submitter":"Serge Assaad","authors":"Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta,\n  Ricardo Henao, Fan Li, Lawrence Carin","title":"Counterfactual Representation Learning with Balancing Weights","comments":"Accepted to International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A key to causal inference with observational data is achieving balance in\npredictive features associated with each treatment type. Recent literature has\nexplored representation learning to achieve this goal. In this work, we discuss\nthe pitfalls of these strategies - such as a steep trade-off between achieving\nbalance and predictive power - and present a remedy via the integration of\nbalancing weights in causal learning. Specifically, we theoretically link\nbalance to the quality of propensity estimation, emphasize the importance of\nidentifying a proper target population, and elaborate on the complementary\nroles of feature balancing and weight adjustments. Using these concepts, we\nthen develop an algorithm for flexible, scalable and accurate estimation of\ncausal effects. Finally, we show how the learned weighted representations may\nserve to facilitate alternative causal learning procedures with appealing\nstatistical features. We conduct an extensive set of experiments on both\nsynthetic examples and standard benchmarks, and report encouraging results\nrelative to state-of-the-art baselines.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:06:03 GMT"},{"version":"v2","created":"Wed, 24 Feb 2021 03:01:10 GMT"}],"update_date":"2021-02-25"}
{"id":"2010.12619","submitter":"Alexander Rader","authors":"Alexander P. Rader, Ionela G. Mocanu, Vaishak Belle and Brendan Juba","title":"Learning Implicitly with Noisy Data in Linear Arithmetic","comments":"This is an extended version of our IJCAI21 paper of the same name","journal-ref":null,"doi":"10.24963/ijcai.2021/195","report-no":null,"categories":"cs.AI cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Robust learning in expressive languages with real-world data continues to be\na challenging task. Numerous conventional methods appeal to heuristics without\nany assurances of robustness. While probably approximately correct (PAC)\nSemantics offers strong guarantees, learning explicit representations is not\ntractable, even in propositional logic. However, recent work on so-called\n\"implicit\" learning has shown tremendous promise in terms of obtaining\npolynomial-time results for fragments of first-order logic. In this work, we\nextend implicit learning in PAC-Semantics to handle noisy data in the form of\nintervals and threshold uncertainty in the language of linear arithmetic. We\nprove that our extended framework keeps the existing polynomial-time complexity\nguarantees. Furthermore, we provide the first empirical investigation of this\nhitherto purely theoretical framework. Using benchmark problems, we show that\nour implicit approach to learning optimal linear programming objective\nconstraints significantly outperforms an explicit approach in practice.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:08:46 GMT"},{"version":"v2","created":"Tue, 7 Sep 2021 16:58:57 GMT"}],"update_date":"2021-09-08"}
{"id":"2010.12620","submitter":"Sarah Steiger","authors":"Alexander B. Walter, Neelay Fruitwala, Sarah Steiger, John I. Bailey\n  III, Nicholas Zobrist, Noah Swimmer, Isabel Lipartito, Jennifer Pearl Smith,\n  Seth R. Meeker, Clint Bockstiegel, Gregoire Coiffard, Rupert Dodkins, Paul\n  Szypryt, Kristina K. Davis, Miguel Daal, Bruce Bumble, Giulia Collura,\n  Olivier Guyon, Julien Lozi, Sebastien Vievard, Nemanja Jovanovic, Frantz\n  Martinache, Thayne Currie, and Benjamin A. Mazin","title":"The MKID Exoplanet Camera for Subaru SCExAO","comments":"To be published in Publications of the Astronomical Society of the\n  Pacific","journal-ref":null,"doi":"10.1088/1538-3873/abc60f","report-no":null,"categories":"astro-ph.IM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the MKID Exoplanet Camera (MEC), a z through J band (800 - 1400\nnm) integral field spectrograph located behind The Subaru Coronagraphic Extreme\nAdaptive Optics (SCExAO) at the Subaru Telescope on Maunakea that utilizes\nMicrowave Kinetic Inductance Detectors (MKIDs) as the enabling technology for\nhigh contrast imaging. MEC is the first permanently deployed near-infrared MKID\ninstrument and is designed to operate both as an IFU, and as a focal plane\nwavefront sensor in a multi-kHz feedback loop with SCExAO. The read noise free,\nfast time domain information attainable by MKIDs allows for the direct probing\nof fast speckle fluctuations that currently limit the performance of most high\ncontrast imaging systems on the ground and will help MEC achieve its ultimate\ngoal of reaching contrasts of $10^{-7}$ at 2$\\lambda / D$. Here we outline the\ninstrument details of MEC including the hardware, firmware, and data reduction\nand analysis pipeline. We then discuss MEC's current on-sky performance and end\nwith future upgrades and plans.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:11:48 GMT"}],"update_date":"2020-11-25"}
{"id":"2010.12621","submitter":"David Bieber","authors":"David Bieber, Charles Sutton, Hugo Larochelle, Daniel Tarlow","title":"Learning to Execute Programs with Instruction Pointer Attention Graph\n  Neural Networks","comments":"Accepted at NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph neural networks (GNNs) have emerged as a powerful tool for learning\nsoftware engineering tasks including code completion, bug finding, and program\nrepair. They benefit from leveraging program structure like control flow\ngraphs, but they are not well-suited to tasks like program execution that\nrequire far more sequential reasoning steps than number of GNN propagation\nsteps. Recurrent neural networks (RNNs), on the other hand, are well-suited to\nlong sequential chains of reasoning, but they do not naturally incorporate\nprogram structure and generally perform worse on the above tasks. Our aim is to\nachieve the best of both worlds, and we do so by introducing a novel GNN\narchitecture, the Instruction Pointer Attention Graph Neural Networks\n(IPA-GNN), which achieves improved systematic generalization on the task of\nlearning to execute programs using control flow graphs. The model arises by\nconsidering RNNs operating on program traces with branch decisions as latent\nvariables. The IPA-GNN can be seen either as a continuous relaxation of the RNN\nmodel or as a GNN variant more tailored to execution. To test the models, we\npropose evaluating systematic generalization on learning to execute using\ncontrol flow graphs, which tests sequential reasoning and use of program\nstructure. More practically, we evaluate these models on the task of learning\nto execute partial programs, as might arise if using the model as a heuristic\nfunction in program synthesis. Results show that the IPA-GNN outperforms a\nvariety of RNN and GNN baselines on both tasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:12:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12622","submitter":"Rahul Ragesh","authors":"Arunava Chakraborty, Rahul Ragesh, Mahir Shah, Nipun Kwatra","title":"S2cGAN: Semi-Supervised Training of Conditional GANs with Fewer Labels","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generative adversarial networks (GANs) have been remarkably successful in\nlearning complex high dimensional real word distributions and generating\nrealistic samples. However, they provide limited control over the generation\nprocess. Conditional GANs (cGANs) provide a mechanism to control the generation\nprocess by conditioning the output on a user defined input. Although training\nGANs requires only unsupervised data, training cGANs requires labelled data\nwhich can be very expensive to obtain. We propose a framework for\nsemi-supervised training of cGANs which utilizes sparse labels to learn the\nconditional mapping, and at the same time leverages a large amount of\nunsupervised data to learn the unconditional distribution. We demonstrate\neffectiveness of our method on multiple datasets and different conditional\ntasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:13:44 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12623","submitter":"Liangming Pan","authors":"Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang\n  Wang","title":"Unsupervised Multi-hop Question Answering by Question Generation","comments":"NAACL 2021 (long paper)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Obtaining training data for multi-hop question answering (QA) is\ntime-consuming and resource-intensive. We explore the possibility to train a\nwell-performed multi-hop QA model without referencing any human-labeled\nmulti-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose\nMQA-QG, an unsupervised framework that can generate human-like multi-hop\ntraining data from both homogeneous and heterogeneous data sources. MQA-QG\ngenerates questions by first selecting/generating relevant information from\neach data source and then integrating the multiple information to form a\nmulti-hop question. Using only generated training data, we can train a\ncompetent multi-hop QA which achieves 61% and 83% of the supervised learning\nperformance for the HybridQA and the HotpotQA dataset, respectively. We also\nshow that pretraining the QA system with the generated data would greatly\nreduce the demand for human-annotated training data. Our codes are publicly\navailable at https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:13:47 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 01:48:29 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12624","submitter":"Y. Eren Suyolcu","authors":"Y. Eren Suyolcu, Jiaxin Sun, Berit H. Goodge, Jisung Park, J\\\"urgen\n  Schubert, Lena F. Kourkoutis and Darrell G. Schlom","title":"a-axis YBa2Cu3O7-x/PrBa2Cu3O7-x/YBa2Cu3O7-x trilayers with subnanometer\n  rms roughness","comments":"Manuscript: 21 pages, 5 figures; supplementary materials: 12 pages, 1\n  table, 10 supplementary figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate a-axis YBa2Cu3O7-x/PrBa2Cu3O7-x/YBa2Cu3O7-x trilayers grown on\n(100) LaAlO3 substrates with improved interface smoothness. The trilayers are\nsynthesized by ozone-assisted molecular-beam epitaxy. The thickness of the\nPrBa2Cu3O7-x layer is held constant at 8 nm and the thickness of the\nYBa2Cu3O7-x layers is varied from 24 nm to 100 nm. X-ray diffraction\nmeasurements show all trilayers to have >95% a-axis content. The rms roughness\nof the thinnest trilayer is < 0.7 nm and this roughness increases with the\nthickness of the YBa2Cu3O7-x layers. The thickness of the YBa2Cu3O7-x layers\nalso affects the transport properties: while all samples exhibit an onset of\nthe superconducting transition at and above 85 K, the thinner samples show\nwider transition widths, {\\Delta}Tc. High-resolution scanning transmission\nelectron microscopy reveals coherent and chemically sharp interfaces, and that\ngrowth begins with a cubic (Y,Ba)CuO3-x perovskite phase that transforms into\na-axis oriented YBa2Cu3O7-x as the substrate temperature is ramped up.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:14:02 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12625","submitter":"Gengyu Xu","authors":"Gengyu Xu and George V. Eleftheriades and Sean V. Hum","title":"Approach to the Analysis and Synthesis of Cylindrical Metasurfaces with\n  Non-circular Cross Sections Based on Conformal Transformations","comments":null,"journal-ref":"Phys. Rev. B 102, 245305 (2020)","doi":"10.1103/PhysRevB.102.245305","report-no":null,"categories":"physics.optics physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present methods for analyzing and designing cylindrical electromagnetic\nmetasurfaces with non-circular cross sections based on conformal\ntransformations. It can be difficult to treat surfaces with non-canonical\ngeometries since they generally do not admit straightforward solutions to the\nHelmholtz wave equation subject to the appropriate boundary conditions. This\nleads to the reliance on full wave numerical techniques which are only suitable\nfor the analysis, but not the synthesis, of these surfaces. We address this\nissue by employing conformal transformations to map the physical space into a\ncomputational space in which the surface coincides with a circular cylinder.\nThe electromagnetic boundary conditions on the surface remain intact under the\ntransformations due to their angle-preserving nature. However, they are much\nmore easily enforced. As a result, analytical modal solutions for the scattered\nfields are readily obtainable, which facilitate closed-form analysis and\nsynthesis equations for general non-circular cylindrical metasurfaces. One\nimportant utility enabled by the proposed framework is the efficient\nidentification of electromagnetic field distributions that satisfy local power\nconservation. This leads to passive and lossless surface designs, which are\nhighly desirable in practice as they do not require active and/or lossy\ncomponents.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:14:23 GMT"},{"version":"v2","created":"Fri, 4 Dec 2020 20:28:40 GMT"}],"update_date":"2022-03-10"}
{"id":"2010.12626","submitter":"Laure Thompson","authors":"Laure Thompson, David Mimno","title":"Topic Modeling with Contextualized Word Representation Clusters","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Clustering token-level contextualized word representations produces output\nthat shares many similarities with topic models for English text collections.\nUnlike clusterings of vocabulary-level word embeddings, the resulting models\nmore naturally capture polysemy and can be used as a way of organizing\ndocuments. We evaluate token clusterings trained from several different output\nlayers of popular contextualized language models. We find that BERT and GPT-2\nproduce high quality clusterings, but RoBERTa does not. These cluster models\nare simple, reliable, and can perform as well as, if not better than, LDA topic\nmodels, maintaining high topic quality even when the number of topics is large\nrelative to the size of the local collection.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:16:59 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12627","submitter":"Tobias Eder","authors":"Tobias Eder, Viktor Hangya, Alexander Fraser","title":"Anchor-based Bilingual Word Embeddings for Low-Resource Languages","comments":"The Joint Conference of the 59th Annual Meeting of the Association\n  for Computational Linguistics and the 10th International Joint Conference on\n  Natural Language Processing","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Good quality monolingual word embeddings (MWEs) can be built for languages\nwhich have large amounts of unlabeled text. MWEs can be aligned to bilingual\nspaces using only a few thousand word translation pairs. For low resource\nlanguages training MWEs monolingually results in MWEs of poor quality, and thus\npoor bilingual word embeddings (BWEs) as well. This paper proposes a new\napproach for building BWEs in which the vector space of the high resource\nsource language is used as a starting point for training an embedding space for\nthe low resource target language. By using the source vectors as anchors the\nvector spaces are automatically aligned during training. We experiment on\nEnglish-German, English-Hiligaynon and English-Macedonian. We show that our\napproach results not only in improved BWEs and bilingual lexicon induction\nperformance, but also in improved target language MWE quality as measured using\nmonolingual word similarity.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:17:00 GMT"},{"version":"v2","created":"Tue, 27 Jul 2021 11:06:05 GMT"}],"update_date":"2021-07-28"}
{"id":"2010.12628","submitter":"Chia-Nan Yeh","authors":"Chia-Nan Yeh, Sergei Iskakov, Dominika Zgid and Emanuel Gull","title":"Electron correlations in cubic paramagnetic perovskite Sr(V,Mn)O$_{3}$\n  -- Results from fully self-consistent self-energy embedding calculations","comments":"13 pages, 13 figures, 2 tables","journal-ref":"Phys. Rev. B 103, 195149 (2021)","doi":"10.1103/PhysRevB.103.195149","report-no":null,"categories":"cond-mat.str-el cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we use the thermodynamically consistent and conserving\nself-energy embedding theory (SEET) to study the spectra of the prototypical\nundistorted cubic perovskites SrVO$_3$ and SrMnO$_3$. In the strongly\ncorrelated metallic SrVO$_3$ we find that the usual attribution of the\nsatellite peaks at -1.8eV to Hund or Hubbard physics in the $t_{2g}$ orbitals\nis inconsistent with our calculations. In the strongly correlated insulator\nSrMnO$_3$ we recover insulating behavior due to a feedback effect between the\nstrongly correlated orbitals and the weakly correlated environment. Our\ncalculation shows a systematic convergence of spectral features as the space of\nstrongly correlated orbitals is enlarged, paving the way to a systematic\nparameter free study of correlated perovskites.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:20:13 GMT"},{"version":"v2","created":"Tue, 1 Jun 2021 14:34:08 GMT"}],"update_date":"2021-06-02"}
{"id":"2010.12629","submitter":"Robin Kothari","authors":"Scott Aaronson and Shalev Ben-David and Robin Kothari and Shravas Rao\n  and Avishay Tal","title":"Degree vs. Approximate Degree and Quantum Implications of Huang's\n  Sensitivity Theorem","comments":"This subsumes an earlier preprint by a subset of the authors\n  (arXiv:2004.13231)","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.CC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Based on the recent breakthrough of Huang (2019), we show that for any total\nBoolean function $f$,\n  $\\bullet \\quad \\mathrm{deg}(f) = O(\\widetilde{\\mathrm{deg}}(f)^2)$: The\ndegree of $f$ is at most quadratic in the approximate degree of $f$. This is\noptimal as witnessed by the OR function.\n  $\\bullet \\quad \\mathrm{D}(f) = O(\\mathrm{Q}(f)^4)$: The deterministic query\ncomplexity of $f$ is at most quartic in the quantum query complexity of $f$.\nThis matches the known separation (up to log factors) due to Ambainis, Balodis,\nBelovs, Lee, Santha, and Smotrovs (2017).\n  We apply these results to resolve the quantum analogue of the\nAanderaa--Karp--Rosenberg conjecture. We show that if $f$ is a nontrivial\nmonotone graph property of an $n$-vertex graph specified by its adjacency\nmatrix, then $\\mathrm{Q}(f)=\\Omega(n)$, which is also optimal. We also show\nthat the approximate degree of any read-once formula on $n$ variables is\n$\\Theta(\\sqrt{n})$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:21:28 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12630","submitter":"Sholeh Razavian","authors":"Sholeh Razavian, Matteo G. A. Paris, and Marco G. Genoni","title":"On the quantumness of multiparameter estimation problems for qubit\n  systems","comments":"14 pages, 2 figures","journal-ref":"Entropy 22, 1197 (2020)","doi":"10.3390/e22111197","report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The estimation of more than one parameter in quantum mechanics is a\nfundamental problem with relevant practical applications. In fact, the ultimate\nlimits in the achievable estimation precision are ultimately linked with the\nnon-commutativity of different observables, a peculiar property of quantum\nmechanics. We here consider several estimation problems for qubit systems and\nevaluate the corresponding quantumness R, a measure that has been recently\nintroduced in order to quantify how much incompatible are the parameters to be\nestimated. In particular, R is an upper bound for the renormalized difference\nbetween the (asymptotically achievable) Holevo bound and the SLD Cram\\'er-Rao\nbound (i.e. the matrix generalization of the single-parameter quantum\nCram\\'er-Rao bound). For all the estimation problems considered, we evaluate\nthe quantumness R and, in order to better understand its usefulness in\ncharacterizing a multiparameter quantum statistical model, we compare it with\nthe renormalized difference between the Holevo and the SLD-bound. Our results\ngive evidence that R is a useful quantity to characterize multiparameter\nestimation problems, as for several quantum statistical model it is equal to\nthe difference between the bounds and, in general, their behaviour\nqualitatively coincide. On the other hand, we also find evidence that for\ncertain quantum statistical models the bound is not in tight, and thus R may\noverestimate the degree of quantum incompatibility between parameters.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:21:50 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12631","submitter":"Cunjian Chen","authors":"Cunjian Chen and Arun Ross","title":"Attention-Guided Network for Iris Presentation Attack Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Convolutional Neural Networks (CNNs) are being increasingly used to address\nthe problem of iris presentation attack detection. In this work, we propose\nattention-guided iris presentation attack detection (AG-PAD) to augment CNNs\nwith attention mechanisms. Two types of attention modules are independently\nappended on top of the last convolutional layer of the backbone network.\nSpecifically, the channel attention module is used to model the inter-channel\nrelationship between features, while the position attention module is used to\nmodel inter-spatial relationship between features. An element-wise sum is\nemployed to fuse these two attention modules. Further, a novel hierarchical\nattention mechanism is introduced. Experiments involving both a JHU-APL\nproprietary dataset and the benchmark LivDet-Iris-2017 dataset suggest that the\nproposed method achieves promising results. To the best of our knowledge, this\nis the first work that exploits the use of attention mechanisms in iris\npresentation attack detection.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:23:51 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12632","submitter":"David Lipshutz","authors":"David Lipshutz, Cengiz Pehlevan, Dmitri B. Chklovskii","title":"Biologically plausible single-layer networks for nonnegative independent\n  component analysis","comments":"Updated version includes a second single-layer network with indirect\n  lateral connections for solving NICA","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.NE q-bio.NC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An important problem in neuroscience is to understand how brains extract\nrelevant signals from mixtures of unknown sources, i.e., perform blind source\nseparation. To model how the brain performs this task, we seek a biologically\nplausible single-layer neural network implementation of a blind source\nseparation algorithm. For biological plausibility, we require the network to\nsatisfy the following three basic properties of neuronal circuits: (i) the\nnetwork operates in the online setting; (ii) synaptic learning rules are local;\n(iii) neuronal outputs are nonnegative. Closest is the work by Pehlevan et al.\n[Neural Computation, 29, 2925--2954 (2017)], which considers Nonnegative\nIndependent Component Analysis (NICA), a special case of blind source\nseparation that assumes the mixture is a linear combination of uncorrelated,\nnonnegative sources. They derive an algorithm with a biologically plausible\n2-layer network implementation. In this work, we improve upon their result by\nderiving 2 algorithms for NICA, each with a biologically plausible single-layer\nnetwork implementation. The first algorithm maps onto a network with indirect\nlateral connections mediated by interneurons. The second algorithm maps onto a\nnetwork with direct lateral connections and multi-compartmental output neurons.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:31:49 GMT"},{"version":"v2","created":"Fri, 4 Mar 2022 20:14:57 GMT"}],"update_date":"2022-03-08"}
{"id":"2010.12633","submitter":"Seyyid Emre Sofuoglu","authors":"Seyyid Emre Sofuoglu and Selin Aviyente","title":"Low-rank on Graphs plus Temporally Smooth Sparse Decomposition for\n  Anomaly Detection in Spatiotemporal Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.DS eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Anomaly detection in spatiotemporal data is a challenging problem encountered\nin a variety of applications including hyperspectral imaging, video\nsurveillance, and urban traffic monitoring. Existing anomaly detection methods\nare most suited for point anomalies in sequence data and cannot deal with\ntemporal and spatial dependencies that arise in spatiotemporal data. In recent\nyears, tensor-based methods have been proposed for anomaly detection to address\nthis problem. These methods rely on conventional tensor decomposition models,\nnot taking the structure of the anomalies into account, and are supervised or\nsemi-supervised. We introduce an unsupervised tensor-based anomaly detection\nmethod that takes the sparse and temporally continuous nature of anomalies into\naccount. In particular, the anomaly detection problem is formulated as a robust\nlowrank + sparse tensor decomposition with a regularization term that minimizes\nthe temporal variation of the sparse part, so that the extracted anomalies are\ntemporally persistent. We also approximate rank minimization with graph total\nvariation minimization to reduce the complexity of the optimization algorithm.\nThe resulting optimization problem is convex, scalable, and is shown to be\nrobust against missing data and noise. The proposed framework is evaluated on\nboth synthetic and real spatiotemporal urban traffic data and compared with\nbaseline methods.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:34:40 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12634","submitter":"Yusen Zhang","authors":"Yusen Zhang, Xiangyu Dong, Shuaichen Chang, Tao Yu, Peng Shi and Rui\n  Zhang","title":"Did You Ask a Good Question? A Cross-Domain Question Intention\n  Classification Benchmark for Text-to-SQL","comments":"8 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural models have achieved significant results on the text-to-SQL task, in\nwhich most current work assumes all the input questions are legal and generates\na SQL query for any input. However, in the real scenario, users can input any\ntext that may not be able to be answered by a SQL query. In this work, we\npropose TriageSQL, the first cross-domain text-to-SQL question intention\nclassification benchmark that requires models to distinguish four types of\nunanswerable questions from answerable questions. The baseline RoBERTa model\nachieves a 60% F1 score on the test set, demonstrating the need for further\nimprovement on this task. Our dataset is available at\nhttps://github.com/chatc/TriageSQL.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:36:57 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12635","submitter":"John Brennan","authors":"John Brennan, Stephen Bonner, Amir Atapour-Abarghouei, Philip T\n  Jackson, Boguslaw Obara, Andrew Stephen McGough","title":"Not Half Bad: Exploring Half-Precision in Graph Convolutional Neural\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the growing significance of graphs as an effective representation of\ndata in numerous applications, efficient graph analysis using modern machine\nlearning is receiving a growing level of attention. Deep learning approaches\noften operate over the entire adjacency matrix -- as the input and intermediate\nnetwork layers are all designed in proportion to the size of the adjacency\nmatrix -- leading to intensive computation and large memory requirements as the\ngraph size increases. It is therefore desirable to identify efficient measures\nto reduce both run-time and memory requirements allowing for the analysis of\nthe largest graphs possible. The use of reduced precision operations within the\nforward and backward passes of a deep neural network along with novel\nspecialised hardware in modern GPUs can offer promising avenues towards\nefficiency. In this paper, we provide an in-depth exploration of the use of\nreduced-precision operations, easily integrable into the highly popular PyTorch\nframework, and an analysis of the effects of Tensor Cores on graph\nconvolutional neural networks. We perform an extensive experimental evaluation\nof three GPU architectures and two widely-used graph analysis tasks (vertex\nclassification and link prediction) using well-known benchmark and\nsynthetically generated datasets. Thus allowing us to make important\nobservations on the effects of reduced-precision operations and Tensor Cores on\ncomputational and memory usage of graph convolutional neural networks -- often\nneglected in the literature.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:47:42 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12636","submitter":"Yunjin Tong","authors":"Shiying Xiong, Yunjin Tong, Xingzhe He, Shuqi Yang, Cheng Yang, Bo Zhu","title":"Nonseparable Symplectic Neural Networks","comments":"ICLR2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CE stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Predicting the behaviors of Hamiltonian systems has been drawing increasing\nattention in scientific machine learning. However, the vast majority of the\nliterature was focused on predicting separable Hamiltonian systems with their\nkinematic and potential energy terms being explicitly decoupled while building\ndata-driven paradigms to predict nonseparable Hamiltonian systems that are\nubiquitous in fluid dynamics and quantum mechanics were rarely explored. The\nmain computational challenge lies in the effective embedding of symplectic\npriors to describe the inherently coupled evolution of position and momentum,\nwhich typically exhibits intricate dynamics. To solve the problem, we propose a\nnovel neural network architecture, Nonseparable Symplectic Neural Networks\n(NSSNNs), to uncover and embed the symplectic structure of a nonseparable\nHamiltonian system from limited observation data. The enabling mechanics of our\napproach is an augmented symplectic time integrator to decouple the position\nand momentum energy terms and facilitate their evolution. We demonstrated the\nefficacy and versatility of our method by predicting a wide range of\nHamiltonian systems, both separable and nonseparable, including chaotic\nvortical flows. We showed the unique computational merits of our approach to\nyield long-term, accurate, and robust predictions for large-scale Hamiltonian\nsystems by rigorously enforcing symplectomorphism.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:50:13 GMT"},{"version":"v2","created":"Mon, 29 Mar 2021 05:33:32 GMT"},{"version":"v3","created":"Sat, 19 Feb 2022 22:35:35 GMT"}],"update_date":"2022-02-22"}
{"id":"2010.12637","submitter":"Dhivya Chandrasekaran","authors":"Dhivya Chandrasekaran and Vijay Mago","title":"Comparative analysis of word embeddings in assessing semantic similarity\n  of complex sentences","comments":"14 pages, 6 figures, submitted to IEEE Access","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Semantic textual similarity is one of the open research challenges in the\nfield of Natural Language Processing. Extensive research has been carried out\nin this field and near-perfect results are achieved by recent transformer-based\nmodels in existing benchmark datasets like the STS dataset and the SICK\ndataset. In this paper, we study the sentences in these datasets and analyze\nthe sensitivity of various word embeddings with respect to the complexity of\nthe sentences. We build a complex sentences dataset comprising of 50 sentence\npairs with associated semantic similarity values provided by 15 human\nannotators. Readability analysis is performed to highlight the increase in\ncomplexity of the sentences in the existing benchmark datasets and those in the\nproposed dataset. Further, we perform a comparative analysis of the performance\nof various word embeddings and language models on the existing benchmark\ndatasets and the proposed dataset. The results show the increase in complexity\nof the sentences has a significant impact on the performance of the embedding\nmodels resulting in a 10-20% decrease in Pearson's and Spearman's correlation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:55:11 GMT"},{"version":"v2","created":"Tue, 9 Feb 2021 03:44:56 GMT"},{"version":"v3","created":"Fri, 9 Jul 2021 21:15:24 GMT"}],"update_date":"2021-07-13"}
{"id":"2010.12638","submitter":"Hao Cheng","authors":"Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao","title":"Posterior Differential Regularization with f-divergence for Improving\n  Model Robustness","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We address the problem of enhancing model robustness through regularization.\nSpecifically, we focus on methods that regularize the model posterior\ndifference between clean and noisy inputs. Theoretically, we provide a\nconnection of two recent methods, Jacobian Regularization and Virtual\nAdversarial Training, under this framework. Additionally, we generalize the\nposterior differential regularization to the family of $f$-divergences and\ncharacterize the overall regularization framework in terms of Jacobian matrix.\nEmpirically, we systematically compare those regularizations and standard BERT\ntraining on a diverse set of tasks to provide a comprehensive profile of their\neffect on model in-domain and out-of-domain generalization. For both fully\nsupervised and semi-supervised settings, our experiments show that regularizing\nthe posterior differential with $f$-divergence can result in well-improved\nmodel robustness. In particular, with a proper $f$-divergence, a BERT-base\nmodel can achieve comparable generalization as its BERT-large counterpart for\nin-domain, adversarial and domain shift scenarios, indicating the great\npotential of the proposed framework for boosting model generalization for NLP\nmodels.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:58:01 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 17:22:04 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12639","submitter":"Jesse Thomason","authors":"Shurjo Banerjee, Jesse Thomason, Jason J. Corso","title":"The RobotSlang Benchmark: Dialog-guided Robot Localization and\n  Navigation","comments":"Conference on Robot Learning 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.CL cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Autonomous robot systems for applications from search and rescue to assistive\nguidance should be able to engage in natural language dialog with people. To\nstudy such cooperative communication, we introduce Robot Simultaneous\nLocalization and Mapping with Natural Language (RobotSlang), a benchmark of 169\nnatural language dialogs between a human Driver controlling a robot and a human\nCommander providing guidance towards navigation goals. In each trial, the pair\nfirst cooperates to localize the robot on a global map visible to the\nCommander, then the Driver follows Commander instructions to move the robot to\na sequence of target objects. We introduce a Localization from Dialog History\n(LDH) and a Navigation from Dialog History (NDH) task where a learned agent is\ngiven dialog and visual observations from the robot platform as input and must\nlocalize in the global map or navigate towards the next target object,\nrespectively. RobotSlang is comprised of nearly 5k utterances and over 1k\nminutes of robot camera and control streams. We present an initial model for\nthe NDH task, and show that an agent trained in simulation can follow the\nRobotSlang dialog-based navigation instructions for controlling a physical\nrobot platform. Code and data are available at https://umrobotslang.github.io/.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:58:17 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12640","submitter":"Ibrahim Yilmaz","authors":"ibrahim Yilmaz and Ambareen Siraj","title":"Avoiding Occupancy Detection from Smart Meter using Adversarial Machine\n  Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  More and more conventional electromechanical meters are being replaced with\nsmart meters because of their substantial benefits such as providing faster\nbi-directional communication between utility services and end users, enabling\ndirect load control for demand response, energy saving, and so on. However, the\nfine-grained usage data provided by smart meter brings additional\nvulnerabilities from users to companies. Occupancy detection is one such\nexample which causes privacy violation of smart meter users. Detecting the\noccupancy of a home is straightforward with time of use information as there is\na strong correlation between occupancy and electricity usage. In this work, our\nmajor contributions are twofold. First, we validate the viability of an\noccupancy detection attack based on a machine learning technique called Long\nShort Term Memory (LSTM) method and demonstrate improved results. In addition,\nwe introduce an Adversarial Machine Learning Occupancy Detection Avoidance\n(AMLODA) framework as a counter attack in order to prevent abuse of energy\nconsumption. Essentially, the proposed privacy-preserving framework is designed\nto mask real-time or near real-time electricity usage information using\ncalculated optimum noise without compromising users' billing systems\nfunctionality. Our results show that the proposed privacy-aware billing\ntechnique upholds users' privacy strongly.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:02:48 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12641","submitter":"Eleonora Losiouk","authors":"Marco Casagrande, Mauro Conti, Eleonora Losiouk","title":"Contact Tracing Made Un-relay-able","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Automated contact tracing is a key solution to control the spread of airborne\ntransmittable diseases: it traces contacts among individuals in order to alert\npeople about their potential risk of being infected. The current SARS-CoV-2\npandemic put a heavy strain on the healthcare system of many countries.\nGovernments chose different approaches to face the spread of the virus and the\ncontact tracing apps were considered the most effective ones. In particular, by\nleveraging on the Bluetooth Low-Energy technology, mobile apps allow to achieve\na privacy-preserving contact tracing of citizens. While researchers proposed\nseveral contact tracing approaches, each government developed its own national\ncontact tracing app.\n  In this paper, we demonstrate that many popular contact tracing apps (e.g.,\nthe ones promoted by the Italian, French, Swiss government) are vulnerable to\nrelay attacks. Through such attacks people might get misleadingly diagnosed as\npositive to SARS-CoV-2, thus being enforced to quarantine and eventually\nleading to a breakdown of the healthcare system. To tackle this vulnerability,\nwe propose a novel and lightweight solution that prevents relay attacks, while\nproviding the same privacy-preserving features as the current approaches. To\nevaluate the feasibility of both the relay attack and our novel defence\nmechanism, we developed a proof of concept against the Italian contact tracing\napp (i.e., Immuni). The design of our defence allows it to be integrated into\nany contact tracing app.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:03:31 GMT"},{"version":"v2","created":"Mon, 2 Nov 2020 16:56:56 GMT"}],"update_date":"2020-11-03"}
{"id":"2010.12642","submitter":"Louis Faury","authors":"Marc Abeille, Louis Faury and Cl\\'ement Calauz\\`enes","title":"Instance-Wise Minimax-Optimal Algorithms for Logistic Bandits","comments":"40 pages. AISTATS 2021, oral","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Logistic Bandits have recently attracted substantial attention, by providing\nan uncluttered yet challenging framework for understanding the impact of\nnon-linearity in parametrized bandits. It was shown by Faury et al. (2020) that\nthe learning-theoretic difficulties of Logistic Bandits can be embodied by a\nlarge (sometimes prohibitively) problem-dependent constant $\\kappa$,\ncharacterizing the magnitude of the reward's non-linearity. In this paper we\nintroduce a novel algorithm for which we provide a refined analysis. This\nallows for a better characterization of the effect of non-linearity and yields\nimproved problem-dependent guarantees. In most favorable cases this leads to a\nregret upper-bound scaling as $\\tilde{\\mathcal{O}}(d\\sqrt{T/\\kappa})$, which\ndramatically improves over the $\\tilde{\\mathcal{O}}(d\\sqrt{T}+\\kappa)$\nstate-of-the-art guarantees. We prove that this rate is minimax-optimal by\nderiving a $\\Omega(d\\sqrt{T/\\kappa})$ problem-dependent lower-bound. Our\nanalysis identifies two regimes (permanent and transitory) of the regret, which\nultimately re-conciliates Faury et al. (2020) with the Bayesian approach of\nDong et al. (2019). In contrast to previous works, we find that in the\npermanent regime non-linearity can dramatically ease the\nexploration-exploitation trade-off. While it also impacts the length of the\ntransitory phase in a problem-dependent fashion, we show that this impact is\nmild in most reasonable configurations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:07:31 GMT"},{"version":"v2","created":"Tue, 9 Mar 2021 11:09:05 GMT"}],"update_date":"2021-03-10"}
{"id":"2010.12643","submitter":"Jacopo Staiano","authors":"Arij Riabi, Thomas Scialom, Rachel Keraron, Beno\\^it Sagot, Djam\\'e\n  Seddah, Jacopo Staiano","title":"Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question\n  Answering","comments":"7 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coupled with the availability of large scale datasets, deep learning\narchitectures have enabled rapid progress on the Question Answering task.\nHowever, most of those datasets are in English, and the performances of\nstate-of-the-art multilingual models are significantly lower when evaluated on\nnon-English data. Due to high data collection costs, it is not realistic to\nobtain annotated data for each language one desires to support.\n  We propose a method to improve the Cross-lingual Question Answering\nperformance without requiring additional annotated data, leveraging Question\nGeneration models to produce synthetic samples in a cross-lingual fashion. We\nshow that the proposed method allows to significantly outperform the baselines\ntrained on English data only. We report a new state-of-the-art on four\nmultilingual datasets: MLQA, XQuAD, SQuAD-it and PIAF (fr).\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:09:01 GMT"},{"version":"v2","created":"Thu, 14 Oct 2021 11:41:34 GMT"}],"update_date":"2021-10-15"}
{"id":"2010.12644","submitter":"David Lipshutz","authors":"David Lipshutz, Charlie Windolf, Siavash Golkar, Dmitri B. Chklovskii","title":"A biologically plausible neural network for Slow Feature Analysis","comments":"17 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC cs.LG cs.NE stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning latent features from time series data is an important problem in\nboth machine learning and brain function. One approach, called Slow Feature\nAnalysis (SFA), leverages the slowness of many salient features relative to the\nrapidly varying input signals. Furthermore, when trained on naturalistic\nstimuli, SFA reproduces interesting properties of cells in the primary visual\ncortex and hippocampus, suggesting that the brain uses temporal slowness as a\ncomputational principle for learning latent features. However, despite the\npotential relevance of SFA for modeling brain function, there is currently no\nSFA algorithm with a biologically plausible neural network implementation, by\nwhich we mean an algorithm operates in the online setting and can be mapped\nonto a neural network with local synaptic updates. In this work, starting from\nan SFA objective, we derive an SFA algorithm, called Bio-SFA, with a\nbiologically plausible neural network implementation. We validate Bio-SFA on\nnaturalistic stimuli.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:09:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12645","submitter":"Yash Chandak","authors":"Yash Chandak, Scott M. Jordan, Georgios Theocharous, Martha White,\n  Philip S. Thomas","title":"Towards Safe Policy Improvement for Non-Stationary MDPs","comments":"Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many real-world sequential decision-making problems involve critical systems\nwith financial risks and human-life risks. While several works in the past have\nproposed methods that are safe for deployment, they assume that the underlying\nproblem is stationary. However, many real-world problems of interest exhibit\nnon-stationarity, and when stakes are high, the cost associated with a false\nstationarity assumption may be unacceptable. We take the first steps towards\nensuring safety, with high confidence, for smoothly-varying non-stationary\ndecision problems. Our proposed method extends a type of safe algorithm, called\na Seldonian algorithm, through a synthesis of model-free reinforcement learning\nwith time-series analysis. Safety is ensured using sequential hypothesis\ntesting of a policy's forecasted performance, and confidence intervals are\nobtained using wild bootstrap.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:13:51 GMT"},{"version":"v2","created":"Thu, 17 Dec 2020 20:26:20 GMT"}],"update_date":"2020-12-21"}
{"id":"2010.12646","submitter":"Bruno Suzuki","authors":"Elizabeth Gasparim, Bruno Suzuki","title":"Curvature Grafted by Instantons","comments":"12 pages, 10 figures","journal-ref":"Indian J Phys 95, 1631-1638 (2021)","doi":"10.1007/s12648-021-02125-x","report-no":null,"categories":"math.AG math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that an instanton with high charge can provoke the creation of extra\ncurvature on the space that holds it. Geometrically, this corresponds to a new\nsurgery operation, which we name grafting. Curvature around a sphere increases\nby grafting when the charge of an instanton decays.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:16:20 GMT"},{"version":"v2","created":"Tue, 10 Nov 2020 17:26:35 GMT"}],"update_date":"2022-02-21"}
{"id":"2010.12647","submitter":"Changfeng Yu","authors":"Changfeng Yu, Cheng Zhang and Jie Wang","title":"Extracting Body Text from Academic PDF Documents for Text Mining","comments":"8 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accurate extraction of body text from PDF-formatted academic documents is\nessential in text-mining applications for deeper semantic understandings. The\nobjective is to extract complete sentences in the body text into a txt file\nwith the original sentence flow and paragraph boundaries. Existing tools for\nextracting text from PDF documents would often mix body and nonbody texts. We\ndevise and implement a system called PDFBoT to detect multiple-column layouts\nusing a line-sweeping technique, remove nonbody text using computed text\nfeatures and syntactic tagging in backward traversal, and align the remaining\ntext back to sentences and paragraphs. We show that PDFBoT is highly accurate\nwith average F1 scores of, respectively, 0.99 on extracting sentences, 0.96 on\nextracting paragraphs, and 0.98 on removing text on tables, figures, and charts\nover a corpus of PDF documents randomly selected from arXiv.org across multiple\nacademic disciplines.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:18:54 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12648","submitter":"Blair Chen","authors":"Blair Chen, Liu Ziyin, Zihao Wang, Paul Pu Liang","title":"An Investigation of how Label Smoothing Affects Generalization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It has been hypothesized that label smoothing can reduce overfitting and\nimprove generalization, and current empirical evidence seems to corroborate\nthese effects. However, there is a lack of mathematical understanding of when\nand why such empirical improvements occur. In this paper, as a step towards\nunderstanding why label smoothing is effective, we propose a theoretical\nframework to show how label smoothing provides in controlling the\ngeneralization loss. In particular, we show that this benefit can be precisely\nformulated and identified in the label noise setting, where the training is\npartially mislabeled. Our theory also predicts the existence of an optimal\nlabel smoothing point, a single value for the label smoothing hyperparameter\nthat minimizes generalization loss. Extensive experiments are done to confirm\nthe predictions of our theory. We believe that our findings will help both\ntheoreticians and practitioners understand label smoothing, and better apply\nthem to real-world datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:26:25 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12649","submitter":"Aida Abiad","authors":"Aida Abiad, Gabriel Coutinho, Miquel Angel Fiol, Bruno Nogueira,\n  Sjanne Zeijlemaker","title":"Optimization of eigenvalue bounds for the independence and chromatic\n  number of graph powers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The $k^{\\text{th}}$ power of a graph $G=(V,E)$, $G^k$, is the graph whose\nvertex set is $V$ and in which two distinct vertices are adjacent if and only\nif their distance in $G$ is at most $k$. This article proves various eigenvalue\nbounds for the independence number and chromatic number of $G^k$ which purely\ndepend on the spectrum of $G$, together with a method to optimize them. Our\nbounds for the $k$-independence number also work for its quantum counterpart,\nwhich is not known to be a computable parameter in general, thus justifying the\nuse of integer programming to optimize them. Some of the bounds previously\nknown in the literature follow as a corollary of our main results. Infinite\nfamilies of graphs where the bounds are sharp are presented as well.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:27:15 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12650","submitter":"Andreas Bugler","authors":"Andreas Bugler, Bryan Pardo, Prem Seetharaman","title":"A Study of Transfer Learning in Music Source Separation","comments":"4 pages + 1 reference page. 3 figures. Submitted to ICASSP","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Supervised deep learning methods for performing audio source separation can\nbe very effective in domains where there is a large amount of training data.\nWhile some music domains have enough data suitable for training a separation\nsystem, such as rock and pop genres, many musical domains do not, such as\nclassical music, choral music, and non-Western music traditions. It is well\nknown that transferring learning from related domains can result in a\nperformance boost for deep learning systems, but it is not always clear how\nbest to do pretraining. In this work we investigate the effectiveness of data\naugmentation during pretraining, the impact on performance as a result of\npretraining and downstream datasets having similar content domains, and also\nexplore how much of a model must be retrained on the final target task, once\npretrained.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:29:47 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12651","submitter":"Aurelien Alfonsi","authors":"Aur\\'elien Alfonsi and Adel Cherchali and Jose Arturo Infante Acevedo","title":"Multilevel Monte-Carlo for computing the SCR with the standard formula\n  and other stress tests","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.CP q-fin.RM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the multilevel Monte-Carlo estimator for the expectation\nof a maximum of conditional expectations. This problem arises naturally when\nconsidering many stress tests and appears in the calculation of the interest\nrate module of the standard formula for the SCR. We obtain theoretical\nconvergence results that complements the recent work of Giles and Goda and\ngives some additional tractability through a parameter that somehow describes\nregularity properties around the maximum. We then apply the MLMC estimator to\nthe calculation of the SCR at future dates with the standard formula for an ALM\nsavings business on life insurance. We compare it with estimators obtained with\nLeast Square Monte-Carlo or Neural Networks. We find that the MLMC estimator is\ncomputationally more efficient and has the main advantage to avoid regression\nissues, which is particularly significant in the context of projection of a\nbalance sheet by an insurer due to the path dependency. Last, we discuss the\npotentiality of this numerical method and analyze in particular the effect of\nthe portfolio allocation on the SCR at future~dates.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:29:59 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 09:25:18 GMT"}],"update_date":"2021-04-14"}
{"id":"2010.12652","submitter":"Orhan Firat","authors":"Mahdis Mahdieh, Mia Xu Chen, Yuan Cao, Orhan Firat","title":"Rapid Domain Adaptation for Machine Translation with Monolingual Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One challenge of machine translation is how to quickly adapt to unseen\ndomains in face of surging events like COVID-19, in which case timely and\naccurate translation of in-domain information into multiple languages is\ncritical but little parallel data is available yet. In this paper, we propose\nan approach that enables rapid domain adaptation from the perspective of\nunsupervised translation. Our proposed approach only requires in-domain\nmonolingual data and can be quickly applied to a preexisting translation system\ntrained on general domain, reaching significant gains on in-domain translation\nquality with little or no drop on general-domain. We also propose an effective\nprocedure of simultaneous adaptation for multiple domains and languages. To the\nbest of our knowledge, this is the first attempt that aims to address\nunsupervised multilingual domain adaptation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:31:37 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12653","submitter":"Nithin Rao Koluguri","authors":"Nithin Rao Koluguri, Jason Li, Vitaly Lavrukhin, Boris Ginsburg","title":"SpeakerNet: 1D Depth-wise Separable Convolutional Network for\n  Text-Independent Speaker Recognition and Verification","comments":"Preprint, submitted to ICASSP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose SpeakerNet - a new neural architecture for speaker recognition and\nspeaker verification tasks. It is composed of residual blocks with 1D\ndepth-wise separable convolutions, batch-normalization, and ReLU layers. This\narchitecture uses x-vector based statistics pooling layer to map\nvariable-length utterances to a fixed-length embedding (q-vector). SpeakerNet-M\nis a simple lightweight model with just 5M parameters. It doesn't use voice\nactivity detection (VAD) and achieves close to state-of-the-art performance\nscoring an Equal Error Rate (EER) of 2.10% on the VoxCeleb1 cleaned and 2.29%\non the VoxCeleb1 trial files.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:34:54 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12654","submitter":"Alexandre P. dos Santos","authors":"Ivan Palaia, Igor M. Telles, Alexandre P. dos Santos and Emmanuel\n  Trizac","title":"Electroosmosis as a probe for electrostatic correlations","comments":"accepted for publication in Soft Matter","journal-ref":"Soft Matter 16 (47), 10688-10696 (2020)","doi":"10.1039/D0SM01523G","report-no":null,"categories":"cond-mat.soft physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the role of ionic correlations on the electroosmotic flow in planar\ndouble-slit channels, without salt. We propose an analytical theory, based on\nrecent advances in the understanding of correlated systems. We compare the\ntheory with mean-field results and validate it by means of dissipative particle\ndynamics simulations. Interestingly, for some surface separations, correlated\nsystems exhibit a larger flow than predicted by mean-field. We conclude that\nthe electroosmotic properties of a charged system can be used, in general, to\ninfer and weight the importance of electrostatic correlations therein.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:35:33 GMT"}],"update_date":"2021-02-04"}
{"id":"2010.12655","submitter":"Stuart Thomson","authors":"Stuart J. Thomson, Matthew Durey, Rodolfo R. Rosales","title":"A discrete complex Ginzburg-Landau equation for a hydrodynamic active\n  lattice","comments":"38 pages (1.5 spacing), 6 figures","journal-ref":"Phys. Rev. E 103, 062215 (2021)","doi":"10.1103/PhysRevE.103.062215","report-no":null,"categories":"nlin.PS math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A discrete and periodic complex Ginzburg-Landau equation, coupled to a\ndiscrete mean equation, is systematically derived from a driven and dissipative\noscillator model, close to the onset of a supercritical Hopf bifurcation. The\noscillator model is inspired by recent experiments exploring active vibrations\nof quasi-one-dimensional lattices of self-propelled millimetric droplets\nbouncing on a vertically vibrating fluid bath. Our systematic derivation\nprovides a direct link between the constitutive properties of the lattice\nsystem and the coefficients of the resultant amplitude equations, paving the\nway to compare the emergent nonlinear dynamics---namely discrete bright and\ndark solitons, breathers, and traveling waves---against experiments. Further,\nthe amplitude equations allow us to rationalize the successive bifurcations\nleading to these distinct dynamical states. The framework presented herein is\nexpected to be applicable to a wider class of oscillators characterized by the\npresence of a dynamic coupling potential between particles. More broadly, our\nresults point to deeper connections between nonlinear oscillators and the\nphysics of active and driven matter.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:37:55 GMT"}],"update_date":"2021-06-30"}
{"id":"2010.12656","submitter":"Jaan Parts","authors":"Jaan Parts","title":"A small 6-chromatic two-distance graph in the plane","comments":null,"journal-ref":"Geombinatorics 29/3 (2020) 111-115","doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give a new, simple proof for the lower bound of the chromatic number of\nthe Euclidean plane with two forbidden distances, based on a graph with only 16\nvertices.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:43:43 GMT"},{"version":"v2","created":"Sun, 26 Mar 2023 13:01:21 GMT"}],"update_date":"2023-03-28"}
{"id":"2010.12657","submitter":"Joshua Lovell","authors":"J. B. Lovell, M. C. Wyatt, M. Ansdell, M. Kama, G. M. Kennedy, C. F.\n  Manara, S. Marino, L. Matr\\`a, G. Rosotti, M. Tazzari, L. Testi, J. P.\n  Williams","title":"ALMA Survey of Lupus Class III Stars: Early Planetesimal Belt Formation\n  and Rapid Disk Dispersal","comments":"30 pages, 20 figures. This is a pre-copyedited, author-produced PDF\n  of an article accepted for publication in MNRAS following peer review","journal-ref":null,"doi":"10.1093/mnras/staa3335","report-no":null,"categories":"astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Class III stars are those in star forming regions without large\nnon-photospheric infrared emission, suggesting recent dispersal of their\nprotoplanetary disks. We observed 30 class III stars in the 1-3 Myr Lupus\nregion with ALMA at ${\\sim}856\\mu$m, resulting in 4 detections that we\nattribute to circumstellar dust. Inferred dust masses are\n$0.036{-}0.093M_\\oplus$, ${\\sim}1$ order of magnitude lower than any previous\nmeasurements; one disk is resolved with radius ${\\sim}80$ au. Two class II\nsources in the field of view were also detected, and 11 other sources,\nconsistent with sub-mm galaxy number counts. Stacking non-detections yields a\nmarginal detection with mean dust mass ${\\sim}0.0048M_\\oplus$. We searched for\ngas emission from the CO J=3-2 line, and present its detection to NO Lup\ninferring a gas mass ($4.9 {\\pm} 1.1$) ${\\times}10^{-5} M_\\oplus$ and\ngas-to-dust ratio $1.0{\\pm}0.4$. Combining our survey with class II sources\nshows a gap in the disk mass distribution from $0.09{-}2M_\\oplus$ for\n${>}0.7M_\\odot$ Lupus stars, evidence of rapid dispersal of mm-sized dust from\nprotoplanetary disks. The class III disk mass distribution is consistent with a\npopulation model of planetesimal belts that go on to replenish the debris disks\nseen around main sequence stars. This suggests that planetesimal belt formation\ndoes not require long-lived protoplanetary disks, i.e., planetesimals form\nwithin ${\\sim}$2 Myr. While all 4 class III disks are consistent with\ncollisional replenishment, for two the gas and/or mid-IR emission could\nindicate primordial circumstellar material in the final stages of\nprotoplanetary disk dispersal. Two class III stars without sub-mm detections\nexhibit hot emission that could arise from ongoing planet formation processes\ninside ${\\sim}1$ au.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:44:49 GMT"}],"update_date":"2020-11-04"}
{"id":"2010.12658","submitter":"Cheng Zhang","authors":"Cheng Zhang, Yicheng Sun, Hejia Chen, Jie Wang","title":"Generating Adequate Distractors for Multiple-Choice Questions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a novel approach to automatic generation of adequate\ndistractors for a given question-answer pair (QAP) generated from a given\narticle to form an adequate multiple-choice question (MCQ). Our method is a\ncombination of part-of-speech tagging, named-entity tagging, semantic-role\nlabeling, regular expressions, domain knowledge bases, word embeddings, word\nedit distance, WordNet, and other algorithms. We use the US SAT (Scholastic\nAssessment Test) practice reading tests as a dataset to produce QAPs and\ngenerate three distractors for each QAP to form an MCQ. We show that, via\nexperiments and evaluations by human judges, each MCQ has at least one adequate\ndistractor and 84\\% of MCQs have three adequate distractors.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:47:58 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12660","submitter":"Siavash Golkar","authors":"Siavash Golkar, David Lipshutz, Yanis Bahroun, Anirvan M. Sengupta,\n  Dmitri B. Chklovskii","title":"A simple normative network approximates local non-Hebbian learning in\n  the cortex","comments":"Body and supplementary materials of NeurIPS 2020 paper. 19 pages, 7\n  figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC cs.LG cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To guide behavior, the brain extracts relevant features from high-dimensional\ndata streamed by sensory organs. Neuroscience experiments demonstrate that the\nprocessing of sensory inputs by cortical neurons is modulated by instructive\nsignals which provide context and task-relevant information. Here, adopting a\nnormative approach, we model these instructive signals as supervisory inputs\nguiding the projection of the feedforward data. Mathematically, we start with a\nfamily of Reduced-Rank Regression (RRR) objective functions which include\nReduced Rank (minimum) Mean Square Error (RRMSE) and Canonical Correlation\nAnalysis (CCA), and derive novel offline and online optimization algorithms,\nwhich we call Bio-RRR. The online algorithms can be implemented by neural\nnetworks whose synaptic learning rules resemble calcium plateau potential\ndependent plasticity observed in the cortex. We detail how, in our model, the\ncalcium plateau potential can be interpreted as a backpropagating error signal.\nWe demonstrate that, despite relying exclusively on biologically plausible\nlocal learning rules, our algorithms perform competitively with existing\nimplementations of RRMSE and CCA.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:49:44 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12661","submitter":"Jaan Parts","authors":"Jaan Parts","title":"The chromatic number of the plane is at least 5 -- a human-verifiable\n  proof","comments":null,"journal-ref":"Geombinatorics 30/2 (2020) 77-102","doi":null,"report-no":null,"categories":"math.CO math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a new proof of the known fact that the chromatic number of the\nplane is at least 5. The main difference of this proof is that it can be\nverified manually without the help of the computer.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:51:07 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12662","submitter":"Yunjie Zhang","authors":"Yunjie Zhang, Fei Tao, Xudong Liu, Runze Su, Xiaorong Mei, Weicong\n  Ding, Zhichen Zhao, Lei Yuan, Ji Liu","title":"Short Video-based Advertisements Evaluation System: Self-Organizing\n  Learning Approach","comments":"Submitting to ICASSP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MM cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the rising of short video apps, such as TikTok, Snapchat and Kwai,\nadvertisement in short-term user-generated videos (UGVs) has become a trending\nform of advertising. Prediction of user behavior without specific user profile\nis required by advertisers, as they expect to acquire advertisement performance\nin advance in the scenario of cold start. Current recommender system do not\ntake raw videos as input; additionally, most previous work of Multi-Modal\nMachine Learning may not deal with unconstrained videos like UGVs. In this\npaper, we proposed a novel end-to-end self-organizing framework for user\nbehavior prediction. Our model is able to learn the optimal topology of neural\nnetwork architecture, as well as optimal weights, through training data. We\nevaluate our proposed method on our in-house dataset. The experimental results\nreveal that our model achieves the best performance in all our experiments.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:52:24 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12663","submitter":"Nadezhda Chirkova","authors":"Nadezhda Chirkova, Sergey Troshin","title":"A Simple Approach for Handling Out-of-Vocabulary Identifiers in Deep\n  Learning for Source Code","comments":"Published at the 2021 Annual Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is an emerging interest in the application of natural language\nprocessing models to source code processing tasks. One of the major problems in\napplying deep learning to software engineering is that source code often\ncontains a lot of rare identifiers, resulting in huge vocabularies. We propose\na simple, yet effective method, based on identifier anonymization, to handle\nout-of-vocabulary (OOV) identifiers. Our method can be treated as a\npreprocessing step and, therefore, allows for easy implementation. We show that\nthe proposed OOV anonymization method significantly improves the performance of\nthe Transformer in two code processing tasks: code completion and bug fixing.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:52:46 GMT"},{"version":"v2","created":"Tue, 27 Apr 2021 15:28:30 GMT"}],"update_date":"2021-04-28"}
{"id":"2010.12664","submitter":"Gholamali Aminian","authors":"Gholamali Aminian, Laura Toni, Miguel R. D. Rodrigues","title":"Jensen-Shannon Information Based Characterization of the Generalization\n  Error of Learning Algorithms","comments":"Accepted in ITW 2020 conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT math.ST stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generalization error bounds are critical to understanding the performance of\nmachine learning models. In this work, we propose a new information-theoretic\nbased generalization error upper bound applicable to supervised learning\nscenarios. We show that our general bound can specialize in various previous\nbounds. We also show that our general bound can be specialized under some\nconditions to a new bound involving the Jensen-Shannon information between a\nrandom variable modelling the set of training samples and another random\nvariable modelling the hypothesis. We also prove that our bound can be tighter\nthan mutual information-based bounds under some conditions.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:53:07 GMT"},{"version":"v2","created":"Fri, 8 Jan 2021 15:27:01 GMT"}],"update_date":"2021-01-11"}
{"id":"2010.12665","submitter":"Jaan Parts","authors":"Jaan Parts","title":"Graph minimization, focusing on the example of 5-chromatic unit-distance\n  graphs in the plane","comments":"Fixed typos in matrices. Some changes in references","journal-ref":"Geombinatorics 29/4 (2020) 137-166","doi":null,"report-no":null,"categories":"math.CO math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a new graph minimization method, in which it is required to\npreserve some graph property and there is an effective procedure for checking\nthis property. We applied this method to minimize 5-chromatic unit-distance\ngraphs and obtained a graph with 509 vertices and 2442 edges.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:57:44 GMT"},{"version":"v2","created":"Tue, 28 Jun 2022 05:19:54 GMT"}],"update_date":"2022-06-29"}
{"id":"2010.12666","submitter":"Yu. A. Simonov","authors":"Yu. A. Simonov","title":"Proton and neutron form factors with quark orbital excitations","comments":"24 pages,3 tables, no figures","journal-ref":null,"doi":"10.1140/epja/s10050-021-00546-0","report-no":null,"categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nucleon form factors play an especially important role in studying the\ndynamics of nucleons and explicit structure of the wave functions at arbitrary\nnucleon velocity. The purpose of the paper is to explain theoretically all four\nnucleon form factors measured experimentally in the cross section measurements\n(by the Rosenbluth method), yielding almost equal normalized form factors\n$G^p_E,G^p_M,G^n_M$, as well as in the polarization transfer experiments, where\na strongly decreasing proton electric form factor has been discovered. It is\nshown, using relativistic hyperspherical formalism, that the nucleon wave\nfunctions in the lowest approximation provide almost equal normalized form\nfactors as seen in the Rosenbluth cross sections, but in the higher components\nthey contain a large admixture of the quark orbital momenta, which strongly\ndecreases $G^p_E$ and this effect is possibly detected in the polarization\ntransfer method (not seen in the classical cross section experiments).\nMoreover, the same admixture of the higher components explains the small\npositive form factor $G^n_E$. The resulting form factors,\n$G^p_M(Q),G^p_E(Q),G^n_M(Q)$ are calculated up to $Q^2\\approx 10$ GeV$^2$,\nusing the standard and the Lorentz contracted wave functions and shown to be in\nreasonable agreement with experimental data.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:58:48 GMT"},{"version":"v2","created":"Sat, 7 Nov 2020 11:55:59 GMT"},{"version":"v3","created":"Mon, 21 Dec 2020 10:50:38 GMT"},{"version":"v4","created":"Tue, 9 Feb 2021 17:43:33 GMT"},{"version":"v5","created":"Thu, 27 May 2021 10:51:29 GMT"},{"version":"v6","created":"Mon, 21 Jun 2021 11:26:38 GMT"}],"update_date":"2021-07-28"}
{"id":"2010.12667","submitter":"Amy Steele","authors":"Amy Steele, John Debes, Siyi Xu, Sherry Yeh, and Patrick Dufour","title":"A Characterization of the Circumstellar Gas around WD 1124-293 using\n  Cloudy","comments":"Accepted for publication in The Astrophysical Journal, 13 pages, 9\n  figures, 4 tables","journal-ref":null,"doi":"10.3847/1538-4357/abc262","report-no":null,"categories":"astro-ph.EP astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Between 30 - 50% of white dwarfs (WDs) show heavy elements in their\natmospheres. This \"pollution\" is thought to arise from the accretion of\nplanetesimals perturbed by outer planet(s) to within the WD's tidal disruption\nradius. A small fraction of these WDs show either emission or absorption from\ncircumstellar (C-S) gas. The abundances of metals in the photospheres of WDs\nwith C-S gas are mostly similar to the bulk composition of the Earth. The C-S\ncomponent arises from gas produced through collisions and/or the sublimation of\ndisintegrating planetesimals. High resolution spectroscopic observations of WD\n1124-293 reveal photospheric and C-S absorption of Ca in multiple transitions.\nHere, we present high signal-to-noise ratio spectra, an updated WD atmosphere\nanalysis, and a self-consistent model of its C-S gas. We constrain the\nabundances of Ca, Mg, and Fe in the photosphere of WD 1124-293, and find\nagreement with the abundances of these 3 species in the C-S gas. We find the\nlocation of the C-S gas is about a hundred white dwarf radii, the C-S and\nphotospheric compositions are thus far consistent, the gas is not isothermal,\nand the amount of C-S Ca has not changed in two decades. We also demonstrate\nhow to use Cloudy to model C-S gas viewed in absorption around polluted WDs.\nModeling the abundances of C-S gas around polluted WDs with Cloudy provides a\nnew method to measure the composition of exo-planetesimals and will allow a\ndirect comparison to the composition of rocky bodies in the Solar System.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:03:52 GMT"},{"version":"v2","created":"Tue, 27 Oct 2020 14:28:59 GMT"}],"update_date":"2021-04-21"}
{"id":"2010.12668","submitter":"Jaan Parts","authors":"Jaan Parts","title":"What percent of the plane can be properly 5- and 6-colored?","comments":null,"journal-ref":"Geombinatorics 30/1 (2020) 25-39","doi":null,"report-no":null,"categories":"math.CO math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a tiling of more than 99.985698% of the Euclidean plane with six\ncolors, reducing the previous record for uncovered fraction of the plane by\nabout 12.8%. We also present a tiling of more than 95.99% of the plane with\nfive colors. It is thus shown that any unit-distance graph of order at most\n6992 and 24 in the plane can be properly 6-colored and 5-colored, respectively.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:04:18 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12669","submitter":"Prasun Roy","authors":"Prasun Roy, Saumik Bhattacharya, Partha Pratim Roy, Umapada Pal","title":"Position and Rotation Invariant Sign Language Recognition from 3D Kinect\n  Data with Recurrent Neural Networks","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sign language is a gesture-based symbolic communication medium among speech\nand hearing impaired people. It also serves as a communication bridge between\nnon-impaired and impaired populations. Unfortunately, in most situations, a\nnon-impaired person is not well conversant in such symbolic languages\nrestricting the natural information flow between these two categories.\nTherefore, an automated translation mechanism that seamlessly translates sign\nlanguage into natural language can be highly advantageous. In this paper, we\nattempt to perform recognition of 30 basic Indian sign gestures. Gestures are\nrepresented as temporal sequences of 3D maps (RGB + depth), each consisting of\n3D coordinates of 20 body joints captured by the Kinect sensor. A recurrent\nneural network (RNN) is employed as the classifier. To improve the classifier's\nperformance, we use geometric transformation for the alignment correction of\ndepth frames. In our experiments, the model achieves 84.81% accuracy.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:07:40 GMT"},{"version":"v2","created":"Tue, 14 Mar 2023 15:20:15 GMT"}],"update_date":"2023-03-15"}
{"id":"2010.12670","submitter":"Djamila Aouada","authors":"Alexandre Saint, Anis Kacem, Kseniya Cherenkova, Djamila Aouada","title":"3DBooSTeR: 3D Body Shape and Texture Recovery","comments":null,"journal-ref":"SHARP Workshop, European Conference on Computer Vision (ECCV),\n  2020","doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose 3DBooSTeR, a novel method to recover a textured 3D body mesh from\na textured partial 3D scan. With the advent of virtual and augmented reality,\nthere is a demand for creating realistic and high-fidelity digital 3D human\nrepresentations. However, 3D scanning systems can only capture the 3D human\nbody shape up to some level of defects due to its complexity, including\nocclusion between body parts, varying levels of details, shape deformations and\nthe articulated skeleton. Textured 3D mesh completion is thus important to\nenhance 3D acquisitions. The proposed approach decouples the shape and texture\ncompletion into two sequential tasks. The shape is recovered by an\nencoder-decoder network deforming a template body mesh. The texture is\nsubsequently obtained by projecting the partial texture onto the template mesh\nbefore inpainting the corresponding texture map with a novel approach. The\napproach is validated on the 3DBodyTex.v2 dataset.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:07:59 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12671","submitter":"Maria Manolopoulou Miss","authors":"Maria Manolopoulou, Ben Hoyle, Robert G. Mann, Martin Sahlen and\n  Seshadri Nadathur","title":"Environmental dependence of X-ray and optical properties of galaxy\n  clusters","comments":"13 pages, 7 figures, 2 tables, accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/staa3341","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Galaxy clusters are widely used to constrain cosmological parameters through\ntheir properties, such as masses, luminosity and temperature distributions. One\nshould take into account all kind of biases that could affect these analyses in\norder to obtain reliable constraints. In this work, we study the difference in\nthe properties of clusters residing in different large scale environments,\ndefined by their position within or outside of voids, and the density of their\nsurrounding space. We use both observational and simulation cluster and void\ncatalogues, i.e. XCS and redMaPPer clusters, BOSS voids, and Magneticum\nsimulations. We devise two different environmental proxies for the clusters and\nstudy their redshift, richness, mass, X-ray luminosity and temperature\ndistributions as well as some properties of their galaxy populations. We use\nthe Kolmogorov-Smirnov two-sample test to discover that richer and more massive\nclusters are more prevalent in overdense regions and outside of voids. We also\nfind that clusters of matched richness and mass in overdense regions and\noutside voids tend to have higher X-ray luminosities and temperatures. These\ndifferences could have important implications for precision cosmology with\nclusters of galaxies, since cluster mass calibrations can vary with\nenvironment.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:08:15 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12672","submitter":"Davoud Hejazi","authors":"Davoud Hejazi, Renda Tan, Neda Kari Rezapour, Mehrnaz Mojtabavi, Meni\n  Wanunu, and Swastik Kar","title":"2D-MoS2 with Narrowest Excitonic Linewidths Grown by Flow-Less Direct\n  Heating of Bulk Powders","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Developing techniques for high-quality synthesis of mono and few-layered 2D\nmaterials with lowered complexity and cost continues to remain an important\ngoal, both for accelerating fundamental research and for applications\ndevelopment. We present the simplest conceivable technique to synthesize\nmicrometer-scale single-crystal triangular monolayers of MoS2, i.e. by direct\nheating of bulk MoS2 powder onto proximally-placed substrates. Room-temperature\nexcitonic linewidth values of our samples are narrower and more uniform than\nthose of 2D-MoS2 obtained by most other techniques reported in literature, and\ncomparable to those of ultraflat h-BN-capped mechanically exfoliated samples,\nindicative of their high quality. Feature-rich Raman spectra absent in samples\ngrown or obtained by most other techniques, also stand out as a testament of\nthe high quality of our samples. A contact-growth mode facilitates direct\ngrowth of crystallographically-strained circular samples, which allows us to\ndirectly compare the optoelectronic properties of flat vs. strained growth from\nthe same growth runs. Our method allows, for the first time, to quantitatively\ncompare the impact of strain on excitonic and Raman peak positions on\nidentically-synthesized 2D-MoS2. Strain leads to average Red-shifts of ~ 30 meV\nin the A-exciton position, and ~ 2 cm-1 in the E12g Raman peak in these\nsamples. Our findings open-up several new possibilities that expand 2D material\nresearch. By eliminating the need for carrier gas flow, mechanical motion or\nchemical reactions, our method can be either miniaturized for substantially\nlow-cost, high-quality scientific research or potentially scaled-up for\nmass-production of 2D crystals for commercial purposes. Moreover, we believe\nthis technique can also be extended to other transition metal dichalcogenides\nand other layered materials.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:09:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12673","submitter":"Liang Lu","authors":"Liang Lu, Zhong Meng, Naoyuki Kanda, Jinyu Li, and Yifan Gong","title":"On Minimum Word Error Rate Training of the Hybrid Autoregressive\n  Transducer","comments":"5 pages, 1 figure. Accepted to ICASSP 2021, but we withdrawn due to a\n  bug in code. We updated the results after the bug fix, and submitted the\n  paper to Interspeech 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hybrid Autoregressive Transducer (HAT) is a recently proposed end-to-end\nacoustic model that extends the standard Recurrent Neural Network Transducer\n(RNN-T) for the purpose of the external language model (LM) fusion. In HAT, the\nblank probability and the label probability are estimated using two separate\nprobability distributions, which provides a more accurate solution for internal\nLM score estimation, and thus works better when combining with an external LM.\nPrevious work mainly focuses on HAT model training with the negative\nlog-likelihood loss, while in this paper, we study the minimum word error rate\n(MWER) training of HAT -- a criterion that is closer to the evaluation metric\nfor speech recognition, and has been successfully applied to other types of\nend-to-end models such as sequence-to-sequence (S2S) and RNN-T models. From\nexperiments with around 30,000 hours of training data, we show that MWER\ntraining can improve the accuracy of HAT models, while at the same time,\nimproving the robustness of the model against the decoding hyper-parameters\nsuch as length normalization and decoding beam during inference.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:16:30 GMT"},{"version":"v2","created":"Fri, 20 Nov 2020 20:12:23 GMT"},{"version":"v3","created":"Fri, 26 Mar 2021 17:35:00 GMT"}],"update_date":"2021-03-29"}
{"id":"2010.12674","submitter":"Thomas Schoegje","authors":"Thomas Schoegje, Chris Kamphuis, Koen Dercksen, Djoerd Hiemstra, Toine\n  Pieters, Arjen de Vries","title":"Exploring task-based query expansion at the TREC-COVID track","comments":"Update version 2: Improved title Update version 3: corrected\n  terminology hyponym -> hypernym in two instances Documents our participation\n  to the TREC-COVID track. Contains 16 pages, 0 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore how to generate effective queries based on search tasks. Our\napproach has three main steps: 1) identify search tasks based on research\ngoals, 2) manually classify search queries according to those tasks, and 3)\ncompare three methods to improve search rankings based on the task context. The\nmost promising approach is based on expanding the user's query terms using task\nterms, which slightly improved the NDCG@20 scores over a BM25 baseline. Further\nimprovements might be gained if we can identify more specific search tasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:16:33 GMT"},{"version":"v2","created":"Thu, 29 Oct 2020 11:10:44 GMT"},{"version":"v3","created":"Mon, 16 Nov 2020 13:10:33 GMT"}],"update_date":"2020-11-17"}
{"id":"2010.12675","submitter":"David Gaddy","authors":"David Gaddy, Alex Kouzemtchenko, Pavankumar Reddy Muddireddy, Prateek\n  Kolhar, and Rushin Shah","title":"Overcoming Conflicting Data when Updating a Neural Semantic Parser","comments":"Accepted at Workshop on NLP for Conversational AI (NLP4ConvAI) at\n  EMNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we explore how to use a small amount of new data to update a\ntask-oriented semantic parsing model when the desired output for some examples\nhas changed. When making updates in this way, one potential problem that arises\nis the presence of conflicting data, or out-of-date labels in the original\ntraining set. To evaluate the impact of this understudied problem, we propose\nan experimental setup for simulating changes to a neural semantic parser. We\nshow that the presence of conflicting data greatly hinders learning of an\nupdate, then explore several methods to mitigate its effect. Our multi-task and\ndata selection methods lead to large improvements in model accuracy compared to\na naive data-mixing strategy, and our best method closes 86% of the accuracy\ngap between this baseline and an oracle upper bound.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:19:03 GMT"},{"version":"v2","created":"Fri, 24 Sep 2021 23:38:14 GMT"},{"version":"v3","created":"Thu, 9 Dec 2021 23:19:40 GMT"}],"update_date":"2021-12-13"}
{"id":"2010.12676","submitter":"Chunchuan Lyu Mr.","authors":"Chunchuan Lyu, Shay B. Cohen, Ivan Titov","title":"A Differentiable Relaxation of Graph Segmentation and Alignment for AMR\n  Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Abstract Meaning Representations (AMR) are a broad-coverage semantic\nformalism which represents sentence meaning as a directed acyclic graph. To\ntrain most AMR parsers, one needs to segment the graph into subgraphs and align\neach such subgraph to a word in a sentence; this is normally done at\npreprocessing, relying on hand-crafted rules. In contrast, we treat both\nalignment and segmentation as latent variables in our model and induce them as\npart of end-to-end training.\n  As marginalizing over the structured latent variables is infeasible, we use\nthe variational autoencoding framework.\n  To ensure end-to-end differentiable optimization, we introduce a\ndifferentiable relaxation of the segmentation and alignment problems. We\nobserve that inducing segmentation yields substantial gains over using a\n`greedy' segmentation heuristic. The performance of our method also approaches\nthat of a model that relies on the segmentation rules of\n\\citet{lyu-titov-2018-amr}, which were hand-crafted to handle individual AMR\nconstructions.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:22:50 GMT"},{"version":"v2","created":"Mon, 24 Oct 2022 22:19:48 GMT"}],"update_date":"2022-10-26"}
{"id":"2010.12677","submitter":"Mu-Tao Wang","authors":"Mu-Tao Wang","title":"Quasi-local mass and isometric embedding with reference to a static\n  spacetime","comments":"to appear in Advanced Studies in Pure Mathematics 85, 2020, The Role\n  of Metrics in the Theory of Partial Differential Equations","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc math-ph math.AP math.DG math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The mathematical theory of isometric embedding is applied to study the notion\nof quasilocal mass in general relativity. In particular, I shall report some\nrecent progress of quasilocal mass with reference to a cosmological spacetime,\nsuch as the de Sitter or the Anti-de Sitter spacetime, or a blackhole\nspacetime, such as the Schwarzschild spacetime. This article is based on joint\nwork with Po-Ning Chen, Ye-Kai Wang, and Shing-Tung Yau.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:30:22 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12678","submitter":"Baihong Jin","authors":"Jieyi Lu and Baihong Jin","title":"Super-Resolution Reconstruction of Interval Energy Data","comments":"Accepted as a poster abstract by BuildSys'20","journal-ref":null,"doi":"10.1145/3408308.3431115","report-no":null,"categories":"eess.SP cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  High-resolution data are desired in many data-driven applications; however,\nin many cases only data whose resolution is lower than expected are available\ndue to various reasons. It is then a challenge how to obtain as much useful\ninformation as possible from the low-resolution data. In this paper, we target\ninterval energy data collected by Advanced Metering Infrastructure (AMI), and\npropose a Super-Resolution Reconstruction (SRR) approach to upsample\nlow-resolution (hourly) interval data into higher-resolution (15-minute) data\nusing deep learning. Our preliminary results show that the proposed SRR\napproaches can achieve much improved performance compared to the baseline\nmodel.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:34:22 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12679","submitter":"Marco Mingione","authors":"Pierfrancesco Alaimo Di Loro, Fabio Divino, Alessio Farcomeni,\n  Giovanna Jona Lasinio, Gianfranco Lovison, Antonello Maruotti and Marco\n  Mingione","title":"Nowcasting COVID-19 incidence indicators during the Italian first\n  outbreak","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A novel parametric regression model is proposed to fit incidence data\ntypically collected during epidemics. The proposal is motivated by real-time\nmonitoring and short-term forecasting of the main epidemiological indicators\nwithin the first outbreak of COVID-19 in Italy. Accurate short-term\npredictions, including the potential effect of exogenous or external variables\nare provided; this ensures to accurately predict important characteristics of\nthe epidemic (e.g., peak time and height), allowing for a better allocation of\nhealth resources over time. Parameters estimation is carried out in a maximum\nlikelihood framework. All computational details required to reproduce the\napproach and replicate the results are provided.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:42:48 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12680","submitter":"Diego Lonardoni","authors":"Luca Riz, Francesco Pederiva, Diego Lonardoni, and Stefano Gandolfi","title":"Spin Susceptibility in Neutron Matter from Quantum Monte Carlo\n  Calculations","comments":"15 pages, 10 figures","journal-ref":"Particles 2020, 3(4), 706-718","doi":"10.3390/particles3040046","report-no":"LA-UR-20-28566","categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The spin susceptibility in pure neutron matter is computed from auxiliary\nfield diffusion Monte Carlo calculations over a wide range of densities. The\ncalculations are performed for different spin asymmetries, while using\ntwist-averaged boundary conditions to reduce finite-size effects. The employed\nnuclear interactions include both the phenomenological Argonne AV8$^\\prime$+UIX\npotential and local interactions that are derived from chiral effective field\ntheory up to next-to-next-to-leading order.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:47:17 GMT"},{"version":"v2","created":"Fri, 27 Nov 2020 16:47:19 GMT"}],"update_date":"2020-11-30"}
{"id":"2010.12681","submitter":"Armineh Nourbakhsh","authors":"Natraj Raman, Armineh Nourbakhsh, Sameena Shah, Manuela Veloso","title":"Robust Document Representations using Latent Topics and Metadata","comments":"9 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Task specific fine-tuning of a pre-trained neural language model using a\ncustom softmax output layer is the de facto approach of late when dealing with\ndocument classification problems. This technique is not adequate when labeled\nexamples are not available at training time and when the metadata artifacts in\na document must be exploited. We address these challenges by generating\ndocument representations that capture both text and metadata artifacts in a\ntask agnostic manner. Instead of traditional auto-regressive or auto-encoding\nbased training, our novel self-supervised approach learns a soft-partition of\nthe input space when generating text embeddings. Specifically, we employ a\npre-learned topic model distribution as surrogate labels and construct a loss\nfunction based on KL divergence. Our solution also incorporates metadata\nexplicitly rather than just augmenting them with text. The generated document\nembeddings exhibit compositional characteristics and are directly used by\ndownstream classification tasks to create decision boundaries from a small\nnumber of labeled examples, thereby eschewing complicated recognition methods.\nWe demonstrate through extensive evaluation that our proposed cross-model\nfusion solution outperforms several competitive baselines on multiple datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:52:38 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12682","submitter":"Mehmet Ayg\\\"un","authors":"Mehmet Ayg\\\"un, Zorah L\\\"ahner, Daniel Cremers","title":"Unsupervised Dense Shape Correspondence using Heat Kernels","comments":"In International Conference on 3D Vision (3DV), 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we propose an unsupervised method for learning dense\ncorrespondences between shapes using a recent deep functional map framework.\nInstead of depending on ground-truth correspondences or the computationally\nexpensive geodesic distances, we use heat kernels. These can be computed\nquickly during training as the supervisor signal. Moreover, we propose a\ncurriculum learning strategy using different heat diffusion times which provide\ndifferent levels of difficulty during optimization without any sampling\nmechanism or hard example mining. We present the results of our method on\ndifferent benchmarks which have various challenges like partiality, topological\nnoise and different connectivity.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:54:10 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12683","submitter":"Jyun-Yu Jiang","authors":"Jyun-Yu Jiang, Chenyan Xiong, Chia-Jung Lee and Wei Wang","title":"Long Document Ranking with Query-Directed Sparse Transformer","comments":"Accepted by EMNLP 2020, 12 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The computing cost of transformer self-attention often necessitates breaking\nlong documents to fit in pretrained models in document ranking tasks. In this\npaper, we design Query-Directed Sparse attention that induces IR-axiomatic\nstructures in transformer self-attention. Our model, QDS-Transformer, enforces\nthe principle properties desired in ranking: local contextualization,\nhierarchical representation, and query-oriented proximity matching, while it\nalso enjoys efficiency from sparsity. Experiments on one fully supervised and\nthree few-shot TREC document ranking benchmarks demonstrate the consistent and\nrobust advantage of QDS-Transformer over previous approaches, as they either\nretrofit long documents into BERT or use sparse attention without emphasizing\nIR principles. We further quantify the computing complexity and demonstrates\nthat our sparse attention with TVM implementation is twice more efficient than\nthe fully-connected self-attention. All source codes, trained model, and\npredictions of this work are available at\nhttps://github.com/hallogameboy/QDS-Transformer.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:57:56 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12684","submitter":"Valentin Hofmann","authors":"Valentin Hofmann, Janet B. Pierrehumbert, Hinrich Sch\\\"utze","title":"Dynamic Contextualized Word Embeddings","comments":"ACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Static word embeddings that represent words by a single vector cannot capture\nthe variability of word meaning in different linguistic and extralinguistic\ncontexts. Building on prior work on contextualized and dynamic word embeddings,\nwe introduce dynamic contextualized word embeddings that represent words as a\nfunction of both linguistic and extralinguistic context. Based on a pretrained\nlanguage model (PLM), dynamic contextualized word embeddings model time and\nsocial space jointly, which makes them attractive for a range of NLP tasks\ninvolving semantic variability. We highlight potential application scenarios by\nmeans of qualitative and quantitative analyses on four English datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:02:40 GMT"},{"version":"v2","created":"Thu, 6 May 2021 16:34:30 GMT"},{"version":"v3","created":"Tue, 8 Jun 2021 13:08:12 GMT"}],"update_date":"2021-06-09"}
{"id":"2010.12685","submitter":"Aritra De","authors":"Aritra De and Rafid Mahbub","title":"Numerically modeling stochastic inflation in slow-roll and beyond","comments":"34 pages, 22 figures","journal-ref":null,"doi":"10.1103/PhysRevD.102.123509","report-no":null,"categories":"astro-ph.CO gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a complete numerical treatment of inflationary dynamics under the\ninfluence of stochastic corrections from sub-Hubble modes. We discuss how to\nexactly model the stochastic noise terms arising from the sub-Hubble quantum\nmodes that give rise to the coarse-grained inflaton dynamics in the form of\nstochastic differential equations. The stochastic differential equations are\nsolved event-by-event on a discrete time grid. We then compute the power\nspectrum of curvature perturbations that can be compared with the power\nspectrum computed in the traditional fashion using the Mukhanov-Sasaki equation\nby canonically quantizing the inflaton fluctuations. Our numerical procedure\nhelps us to easily extend the formalism to ultra slow-roll inflation and study\nthe possibility of primordial black hole formation.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:05:34 GMT"}],"update_date":"2020-12-02"}
{"id":"2010.12686","submitter":"Frantisek Farka","authors":"Franti\\v{s}ek Farka, Aleksandar Nanevski, Anindya Banerjee, Germ\\'an\n  Andr\\'es Delbianco, Ignacio F\\'abregas","title":"On Algebraic Abstractions for Concurrent Separation Logics","comments":"35 pages","journal-ref":"Proc. ACM Program. Lang. 5, POPL, Article 5 (January 2021)","doi":"10.1145/3434286","report-no":null,"categories":"cs.PL cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Concurrent separation logic is distinguished by transfer of state ownership\nupon parallel composition and framing. The algebraic structure that underpins\nownership transfer is that of partial commutative monoids (PCMs). Extant\nresearch considers ownership transfer primarily from the logical perspective\nwhile comparatively less attention is drawn to the algebraic considerations.\nThis paper provides an algebraic formalization of ownership transfer in\nconcurrent separation logic by means of structure-preserving partial functions\n(i.e., morphisms) between PCMs, and an associated notion of separating\nrelations. Morphisms of structures are a standard concept in algebra and\ncategory theory, but haven't seen ubiquitous use in separation logic before.\nSeparating relations are binary relations that generalize disjointness and\ncharacterize the inputs on which morphisms preserve structure. The two\nabstractions facilitate verification by enabling concise ways of writing specs,\nby providing abstract views of threads' states that are preserved under\nownership transfer, and by enabling user-level construction of new PCMs out of\nexisting ones.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:06:12 GMT"},{"version":"v2","created":"Mon, 16 Nov 2020 11:06:02 GMT"},{"version":"v3","created":"Thu, 4 Mar 2021 19:37:31 GMT"}],"update_date":"2021-03-08"}
{"id":"2010.12687","submitter":"Siddharth Jain","authors":"Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck","title":"Robust Correction of Sampling Bias Using Cumulative Distribution\n  Functions","comments":"Accepted in Neurips 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.IT cs.LG math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Varying domains and biased datasets can lead to differences between the\ntraining and the target distributions, known as covariate shift. Current\napproaches for alleviating this often rely on estimating the ratio of training\nand target probability density functions. These techniques require parameter\ntuning and can be unstable across different datasets. We present a new method\nfor handling covariate shift using the empirical cumulative distribution\nfunction estimates of the target distribution by a rigorous generalization of a\nrecent idea proposed by Vapnik and Izmailov. Further, we show experimentally\nthat our method is more robust in its predictions, is not reliant on parameter\ntuning and shows similar classification performance compared to the current\nstate-of-the-art techniques on synthetic and real datasets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:13:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12688","submitter":"Oshin Agarwal","authors":"Oshin Agarwal, Heming Ge, Siamak Shakeri, Rami Al-Rfou","title":"Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced\n  Language Model Pre-training","comments":"Accepted at NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Prior work on Data-To-Text Generation, the task of converting knowledge graph\n(KG) triples into natural text, focused on domain-specific benchmark datasets.\nIn this paper, however, we verbalize the entire English Wikidata KG, and\ndiscuss the unique challenges associated with a broad, open-domain, large-scale\nverbalization. We further show that verbalizing a comprehensive, encyclopedic\nKG like Wikidata can be used to integrate structured KGs and natural language\ncorpora. In contrast to the many architectures that have been developed to\nintegrate these two sources, our approach converts the KG into natural text,\nallowing it to be seamlessly integrated into existing language models. It\ncarries the further advantages of improved factual accuracy and reduced\ntoxicity in the resulting language model. We evaluate this approach by\naugmenting the retrieval corpus in a retrieval language model and showing\nsignificant improvements on the knowledge intensive tasks of open domain QA and\nthe LAMA knowledge probe.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:14:50 GMT"},{"version":"v2","created":"Sat, 13 Mar 2021 18:25:01 GMT"}],"update_date":"2021-03-16"}
{"id":"2010.12689","submitter":"Claudia Faggian","authors":"Ugo Dal Lago, Claudia Faggian, Simona Ronchi Della Rocca","title":"Intersection Types and (Positive) Almost-Sure Termination","comments":null,"journal-ref":"Proc. ACM Program. Lang. 5, POPL (2021)","doi":"10.1145/3434313","report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Randomized higher-order computation can be seen as being captured by a lambda\ncalculus endowed with a single algebraic operation, namely a construct for\nbinary probabilistic choice. What matters about such computations is the\nprobability of obtaining any given result, rather than the possibility or the\nnecessity of obtaining it, like in (non)deterministic computation. Termination,\narguably the simplest kind of reachability problem, can be spelled out in at\nleast two ways, depending on whether it talks about the probability of\nconvergence or about the expected evaluation time, the second one providing a\nstronger guarantee. In this paper, we show that intersection types are capable\nof precisely characterizing both notions of termination inside a single system\nof types: the probability of convergence of any lambda-term can be\nunderapproximated by its type, while the underlying derivation's weight gives a\nlower bound to the term's expected number of steps to normal form. Noticeably,\nboth approximations are tight -- not only soundness but also completeness\nholds. The crucial ingredient is non-idempotency, without which it would be\nimpossible to reason on the expected number of reduction steps which are\nnecessary to completely evaluate any term. Besides, the kind of approximation\nwe obtain is proved to be optimal recursion theoretically: no recursively\nenumerable formal system can do better than that.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:17:08 GMT"},{"version":"v2","created":"Wed, 23 Dec 2020 11:22:50 GMT"}],"update_date":"2020-12-24"}
{"id":"2010.12690","submitter":"Jiawei Yang","authors":"Jiawei Yang and Jeffrey M. Hausdorff","title":"Loss-analysis via Attention-scale for Physiologic Time Series","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG eess.SP physics.data-an","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Physiologic signals have properties across multiple spatial and temporal\nscales, which can be shown by the complexity-analysis of the coarse-grained\nphysiologic signals by scaling techniques such as the multiscale.\nUnfortunately, the results obtained from the coarse-grained signals by the\nmultiscale may not fully reflect the properties of the original signals because\nthere is a loss caused by scaling techniques and the same scaling technique may\nbring different losses to different signals. Another problem is that multiscale\ndoes not consider the key observations inherent in the signal. Here, we show a\nnew analysis method for time series called the loss-analysis via\nattention-scale. We show that multiscale is a special case of attention-scale.\nThe loss-analysis can complement to the complexity-analysis to capture aspects\nof the signals that are not captured using previously developed measures. This\ncan be used to study ageing, diseases, and other physiologic phenomenon.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:22:38 GMT"},{"version":"v2","created":"Sun, 8 Nov 2020 20:37:01 GMT"}],"update_date":"2020-11-10"}
{"id":"2010.12691","submitter":"Wenrui Zhang","authors":"Wenrui Zhang, Peng Li","title":"Skip-Connected Self-Recurrent Spiking Neural Networks with Joint\n  Intrinsic Parameter and Synaptic Weight Training","comments":"9 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As an important class of spiking neural networks (SNNs), recurrent spiking\nneural networks (RSNNs) possess great computational power and have been widely\nused for processing sequential data like audio and text. However, most RSNNs\nsuffer from two problems. 1. Due to a lack of architectural guidance, random\nrecurrent connectivity is often adopted, which does not guarantee good\nperformance. 2. Training of RSNNs is in general challenging, bottlenecking\nachievable model accuracy. To address these problems, we propose a new type of\nRSNNs called Skip-Connected Self-Recurrent SNNs (ScSr-SNNs). Recurrence in\nScSr-SNNs is introduced in a stereotyped manner by adding self-recurrent\nconnections to spiking neurons, which implements local memory. The network\ndynamics is enriched by skip connections between nonadjacent layers.\nConstructed by simplified self-recurrent and skip connections, ScSr-SNNs are\nable to realize recurrent behaviors similar to those of more complex RSNNs\nwhile the error gradients can be more straightforwardly calculated due to the\nmostly feedforward nature of the network. Moreover, we propose a new\nbackpropagation (BP) method called backpropagated intrinsic plasticity (BIP) to\nfurther boost the performance of ScSr-SNNs by training intrinsic model\nparameters. Unlike standard intrinsic plasticity rules that adjust the neuron's\nintrinsic parameters according to neuronal activity, the proposed BIP methods\noptimize intrinsic parameters based on the backpropagated error gradient of a\nwell-defined global loss function in addition to synaptic weight training.\nBased upon challenging speech and neuromorphic speech datasets including\nTI46-Alpha, TI46-Digits, and N-TIDIGITS, the proposed ScSr-SNNs can boost\nperformance by up to 2.55% compared with other types of RSNNs trained by\nstate-of-the-art BP methods.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:27:13 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12692","submitter":"Saurabh Kataria","authors":"Saurabh Kataria, Shi-Xiong Zhang, Dong Yu","title":"Multi-Channel Speaker Verification for Single and Multi-talker Speech","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To improve speaker verification in real scenarios with interference speakers,\nnoise, and reverberation, we propose to bring together advancements made in\nmulti-channel speech features. Specifically, we combine spectral, spatial, and\ndirectional features, which includes inter-channel phase difference,\nmulti-channel sinc convolutions, directional power ratio features, and angle\nfeatures. To maximally leverage supervised learning, our framework is also\nequipped with multi-channel speech enhancement and voice activity detection. On\nall simulated, replayed, and real recordings, we observe large and consistent\nimprovements at various degradation levels. On real recordings of multi-talker\nspeech, we achieve a 36% relative reduction in equal error rate w.r.t.\nsingle-channel baseline. We find the improvements from speaker-dependent\ndirectional features more consistent in multi-talker conditions than clean.\nLastly, we investigate if the learned multi-channel speaker embedding space can\nbe made more discriminative through a contrastive loss-based fine-tuning. With\na simple choice of Triplet loss, we observe a further 8.3% relative reduction\nin EER.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:31:09 GMT"},{"version":"v2","created":"Fri, 9 Apr 2021 15:37:58 GMT"}],"update_date":"2021-04-12"}
{"id":"2010.12693","submitter":"Nadezhda Chirkova","authors":"Nadezhda Chirkova","title":"On the Embeddings of Variables in Recurrent Neural Networks for Source\n  Code","comments":"Published at the 2021 Annual Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Source code processing heavily relies on the methods widely used in natural\nlanguage processing (NLP), but involves specifics that need to be taken into\naccount to achieve higher quality. An example of this specificity is that the\nsemantics of a variable is defined not only by its name but also by the\ncontexts in which the variable occurs. In this work, we develop dynamic\nembeddings, a recurrent mechanism that adjusts the learned semantics of the\nvariable when it obtains more information about the variable's role in the\nprogram. We show that using the proposed dynamic embeddings significantly\nimproves the performance of the recurrent neural network, in code completion\nand bug fixing tasks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:32:11 GMT"},{"version":"v2","created":"Tue, 27 Apr 2021 16:05:27 GMT"}],"update_date":"2021-04-28"}
{"id":"2010.12694","submitter":"Sayali Kulkarni","authors":"Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, Eugene Ie","title":"AQuaMuSe: Automatically Generating Datasets for Query-Based\n  Multi-Document Summarization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Summarization is the task of compressing source document(s) into coherent and\nsuccinct passages. This is a valuable tool to present users with concise and\naccurate sketch of the top ranked documents related to their queries.\nQuery-based multi-document summarization (qMDS) addresses this pervasive need,\nbut the research is severely limited due to lack of training and evaluation\ndatasets as existing single-document and multi-document summarization datasets\nare inadequate in form and scale. We propose a scalable approach called\nAQuaMuSe to automatically mine qMDS examples from question answering datasets\nand large document corpora. Our approach is unique in the sense that it can\ngeneral a dual dataset -- for extractive and abstractive summaries both. We\npublicly release a specific instance of an AQuaMuSe dataset with 5,519\nquery-based summaries, each associated with an average of 6 input documents\nselected from an index of 355M documents from Common Crawl. Extensive\nevaluation of the dataset along with baseline summarization model experiments\nare provided.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:38:18 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12695","submitter":"Leif Andersen","authors":"Leif Andersen, Michael Ballantyne, Matthias Felleisen","title":"Adding Interactive Visual Syntax to Textual Code","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many programming problems call for turning geometrical thoughts into code:\ntables, hierarchical structures, nests of objects, trees, forests, graphs, and\nso on. Linear text does not do justice to such thoughts. But, it has been the\ndominant programming medium for the past and will remain so for the foreseeable\nfuture.\n  This paper proposes a novel mechanism for conveniently extending textual\nprogramming languages with problem-specific visual syntax. It argues the\nnecessity of this language feature, demonstrates the feasibility with a robust\nprototype, and sketches a design plan for adapting the idea to other languages.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:42:54 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12696","submitter":"Xiaotian Zheng","authors":"Xiaotian Zheng, Athanasios Kottas and Bruno Sans\\'o","title":"On Construction and Estimation of Stationary Mixture Transition\n  Distribution Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mixture transition distribution time series models build high-order\ndependence through a weighted combination of first-order transition densities\nfor each one of a specified number of lags. We present a framework to construct\nstationary transition mixture distribution models that extend beyond linear,\nGaussian dynamics. We study conditions for first-order strict stationarity\nwhich allow for different constructions with either continuous or discrete\nfamilies for the first-order transition densities given a pre-specified family\nfor the marginal density, and with general forms for the resulting conditional\nexpectations. Inference and prediction are developed under the Bayesian\nframework with particular emphasis on flexible, structured priors for the\nmixture weights. Model properties are investigated both analytically and\nthrough synthetic data examples. Finally, Poisson and Lomax examples are\nillustrated through real data applications.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:44:10 GMT"},{"version":"v2","created":"Wed, 16 Jun 2021 23:35:07 GMT"}],"update_date":"2021-06-18"}
{"id":"2010.12697","submitter":"Bilal Alsallakh","authors":"Vivek Miglani and Narine Kokhlikyan and Bilal Alsallakh and Miguel\n  Martin and Orion Reblitz-Richardson","title":"Investigating Saturation Effects in Integrated Gradients","comments":"Presented at ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2020)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Integrated Gradients has become a popular method for post-hoc model\ninterpretability. De-spite its popularity, the composition and relative impact\nof different regions of the integral path are not well understood. We explore\nthese effects and find that gradients in saturated regions of this path, where\nmodel output changes minimally, contribute disproportionately to the computed\nattribution. We propose a variant of IntegratedGradients which primarily\ncaptures gradients in unsaturated regions and evaluate this method on ImageNet\nclassification networks. We find that this attribution technique shows higher\nmodel faithfulness and lower sensitivity to noise com-pared with standard\nIntegrated Gradients. A note-book illustrating our computations and results is\navailable at https://github.com/vivekmig/captum-1/tree/ExpandedIG.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:48:02 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12698","submitter":"Gideon Stein","authors":"Gideon Stein, Andrey Filchenkov, Arip Asadulaev","title":"Stabilizing Transformer-Based Action Sequence Generation For Q-Learning","comments":"Transformers, Reinforcement Learning, 8 pages, AAAI format","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Since the publication of the original Transformer architecture (Vaswani et\nal. 2017), Transformers revolutionized the field of Natural Language\nProcessing. This, mainly due to their ability to understand timely dependencies\nbetter than competing RNN-based architectures. Surprisingly, this architecture\nchange does not affect the field of Reinforcement Learning (RL), even though\nRNNs are quite popular in RL, and time dependencies are very common in RL.\nRecently, Parisotto et al. 2019) conducted the first promising research of\nTransformers in RL. To support the findings of this work, this paper seeks to\nprovide an additional example of a Transformer-based RL method. Specifically,\nthe goal is a simple Transformer-based Deep Q-Learning method that is stable\nover several environments. Due to the unstable nature of Transformers and RL,\nan extensive method search was conducted to arrive at a final method that\nleverages developments around Transformers as well as Q-learning. The proposed\nmethod can match the performance of classic Q-learning on control environments\nwhile showing potential on some selected Atari benchmarks. Furthermore, it was\ncritically evaluated to give additional insights into the relation between\nTransformers and RL.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:55:04 GMT"},{"version":"v2","created":"Fri, 18 Dec 2020 17:16:38 GMT"}],"update_date":"2020-12-21"}
{"id":"2010.12699","submitter":"Stefan Gr\\\"unewald","authors":"Stefan Gr\\\"unewald, Annemarie Friedrich, Jonas Kuhn","title":"Applying Occam's Razor to Transformer-Based Dependency Parsing: What\n  Works, What Doesn't, and What is Really Necessary","comments":"14 pages, 1 figure; camera-ready version for IWPT 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The introduction of pre-trained transformer-based contextualized word\nembeddings has led to considerable improvements in the accuracy of graph-based\nparsers for frameworks such as Universal Dependencies (UD). However, previous\nworks differ in various dimensions, including their choice of pre-trained\nlanguage models and whether they use LSTM layers. With the aims of\ndisentangling the effects of these choices and identifying a simple yet widely\napplicable architecture, we introduce STEPS, a new modular graph-based\ndependency parser. Using STEPS, we perform a series of analyses on the UD\ncorpora of a diverse set of languages. We find that the choice of pre-trained\nembeddings has by far the greatest impact on parser performance and identify\nXLM-R as a robust choice across the languages in our study. Adding LSTM layers\nprovides no benefits when using transformer-based embeddings. A multi-task\ntraining setup outputting additional UD features may contort results. Taking\nthese insights together, we propose a simple but widely applicable parser\narchitecture and configuration, achieving new state-of-the-art results (in\nterms of LAS) for 10 out of 12 diverse languages.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:58:26 GMT"},{"version":"v2","created":"Sat, 13 Mar 2021 12:44:18 GMT"},{"version":"v3","created":"Thu, 29 Jul 2021 12:30:13 GMT"}],"update_date":"2021-07-30"}
{"id":"2010.12700","submitter":"Jiajie Chen","authors":"Jiajie Chen","title":"On the Slightly Perturbed De Gregorio Model on $S^1$","comments":"19 pages. Added discussions in the introduction","journal-ref":null,"doi":"10.1007/s00205-021-01685-w","report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is conjectured that the generalization of the Constantin-Lax-Majda model\n(gCLM) $\\omega_t + a u\\omega_x = u_x \\omega$ due to Okamoto, Sakajo and Wunsch\ncan develop a finite time singularity from smooth initial data for $a < 1$. For\nthe endpoint case where $a$ is close to and less than $1$, we prove finite time\nasymptotically self-similar blowup of gCLM on a circle from a class of smooth\ninitial data. For the gCLM on a circle with the same initial data, if the\nstrength of advection $a$ is slightly larger than $1$, we prove that the\nsolution exists globally with $|| \\omega(t)||_{H^1}$ decaying in a rate of\n$O(t^{-1})$ for large time. The transition threshold between two different\nbehaviors is $a=1$, which corresponds to the De Gregorio model.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:58:48 GMT"},{"version":"v2","created":"Sat, 7 Nov 2020 07:54:55 GMT"}],"update_date":"2021-06-14"}
{"id":"2010.12701","submitter":"Joshua Swanson","authors":"Sara C. Billey and Joshua P. Swanson","title":"The moduli space of limit laws for $q$-hook formulas","comments":"51 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In earlier work, Billey--Konvalinka--Swanson studied the asymptotic\ndistribution of the coefficients of Stanley's $q$-hook length formula, or\nequivalently the major index on standard tableaux of straight shape and certain\nskew shapes. We extend those investigations to Stanley's $q$-hook-content\nformula related to semistandard tableaux and $q$-hook length formulas of\nBj\\\"orner--Wachs related to linear extensions of labeled forests. We show that,\nwhile their coefficients are \"generically\" asymptotically normal, there are\nuncountably many non-normal limit laws. More precisely, we introduce and\ncompletely describe the compact closure of the moduli space of distributions of\nthese statistics in several regimes. The additional limit distributions involve\ngeneralized uniform sum distributions which are topologically parameterized by\ncertain decreasing sequence spaces with bounded $2$-norm. The closure of the\nmoduli space of these distributions in the L\\'evy metric gives rise to the\nmoduli space of DUSTPAN distributions. As an application, we completely\nclassify the limiting distributions of the size statistic on plane partitions\nfitting in a box.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:04:08 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12702","submitter":"Juan Carlos Seck Tuoh Mora","authors":"Juan Carlos Seck-Tuoh-Mora, Nayeli J. Escamilla-Serna, Joselito\n  Medina-Marin, Norberto Hernandez-Romero, Irving Barragan-Vite, Jose R.\n  Corona-Armenta","title":"A global-local neighborhood search algorithm and tabu search for\n  flexible job shop scheduling problem","comments":"33 pages, 25 figures, Submitted to: PeerJ Comput. Sci","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Flexible Job Shop Scheduling Problem (FJSP) is a combinatorial problem\nthat continues to be studied extensively due to its practical implications in\nmanufacturing systems and emerging new variants, in order to model and optimize\nmore complex situations that reflect the current needs of the industry better.\nThis work presents a new meta-heuristic algorithm called GLNSA (Global-local\nneighborhood search algorithm), in which the neighborhood concepts of a\ncellular automaton are used, so that a set of leading solutions called\n\"smart_cells\" generates and shares information that helps to optimize instances\nof FJSP. The GLNSA algorithm is complemented with a tabu search that implements\na simplified version of the Nopt1 neighborhood defined in [1] to complement the\noptimization task. The experiments carried out show a satisfactory performance\nof the proposed algorithm, compared with other results published in recent\nalgorithms and widely cited in the specialized bibliography, using 86 test\nproblems, improving the optimal result reported in previous works in two of\nthem.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:08:51 GMT"},{"version":"v2","created":"Tue, 3 Nov 2020 20:09:27 GMT"}],"update_date":"2020-11-05"}
{"id":"2010.12703","submitter":"Alessandro Lovato","authors":"Krishnan Raghavan, Prasanna Balaprakash, Alessandro Lovato, Noemi\n  Rocco, Stefan M. Wild","title":"Machine learning-based inversion of nuclear responses","comments":"12 pages, 10 figures","journal-ref":"Phys. Rev. C 103, 035502 (2021)","doi":"10.1103/PhysRevC.103.035502","report-no":"FERMILAB-PUB-20-559-T","categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A microscopic description of the interaction of atomic nuclei with external\nelectroweak probes is required for elucidating aspects of short-range nuclear\ndynamics and for the correct interpretation of neutrino oscillation\nexperiments. Nuclear quantum Monte Carlo methods infer the nuclear electroweak\nresponse functions from their Laplace transforms. Inverting the Laplace\ntransform is a notoriously ill-posed problem; and Bayesian techniques, such as\nmaximum entropy, are typically used to reconstruct the original response\nfunctions in the quasielastic region. In this work, we present a\nphysics-informed artificial neural network architecture suitable for\napproximating the inverse of the Laplace transform. Utilizing simulated, albeit\nrealistic, electromagnetic response functions, we show that this\nphysics-informed artificial neural network outperforms maximum entropy in both\nthe low-energy transfer and the quasielastic regions, thereby allowing for\nrobust calculations of electron scattering and neutrino scattering on nuclei\nand inclusive muon capture rates.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:09:17 GMT"}],"update_date":"2021-03-17"}
{"id":"2010.12704","submitter":"Ashkan Vakil","authors":"Ashkan Vakil, Farzad Niknia, Ali Mirzaeian, Avesta Sasan, Naghmeh\n  Karimi","title":"Learning Assisted Side Channel Delay Test for Detection of Recycled ICs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the outsourcing of design flow, ensuring the security and\ntrustworthiness of integrated circuits has become more challenging. Among the\nsecurity threats, IC counterfeiting and recycled ICs have received a lot of\nattention due to their inferior quality, and in turn, their negative impact on\nthe reliability and security of the underlying devices. Detecting recycled ICs\nis challenging due to the effect of process variations and process drift\noccurring during the chip fabrication. Moreover, relying on a golden chip as a\nbasis for comparison is not always feasible. Accordingly, this paper presents a\nrecycled IC detection scheme based on delay side-channel testing. The proposed\nmethod relies on the features extracted during the design flow and the sample\ndelays extracted from the target chip to build a Neural Network model using\nwhich the target chip can be truly identified as new or recycled. The proposed\nmethod classifies the timing paths of the target chip into two groups based on\ntheir vulnerability to aging using the information collected from the design\nand detects the recycled ICs based on the deviation of the delay of these two\nsets from each other.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:13:16 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12705","submitter":"Mohsen Soltanifar","authors":"Mohsen Soltanifar, Michael Escobar, Annie Dupuis, and Russell Schachar","title":"A Bayesian Mixture Modelling of Stop Signal Reaction Time Distributions","comments":"26 pages, 7 figures","journal-ref":"Brain Sciences. 2021; 11(8):1102","doi":"10.3390/brainsci11081102","report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The distribution of single Stop Signal Reaction Times (SSRT) in the stop\nsignal task (SST) as a measurement of the latency of the unobservable stopping\nprocess has been modeled with a nonparametric method by Hans Colonius (1990)\nand with a Bayesian parametric method by Eric-Jan Wagenmakers and colleagues\n(2012). These methods assume equal impact of the preceding trial type (go/stop)\nin the SST trials on the SSRT distributional estimation without addressing the\ncase of the violated assumption. This study presents the required model by\nconsidering two-state mixture model for the SSRT distribution. It then compares\nthe Bayesian parametric single SSRT and mixture SSRT distributions in the usual\nstochastic order at the individual and the population level under the\nex-Gaussian distributional format. It shows that compared to a single SSRT\ndistribution, the mixture SSRT distribution is more diverse, more positively\nskewed, more leptokurtic, and larger in stochastic order. The size of the\ndisparities in the results also depends on the choice of weights in the mixture\nSSRT distribution. This study confirms that mixture SSRT indices as a constant\nor distribution are significantly larger than their single SSRT counterparts in\nthe related order. This offers a vital improvement in the SSRT estimations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:20:42 GMT"},{"version":"v2","created":"Wed, 6 Jan 2021 23:19:47 GMT"}],"update_date":"2022-06-07"}
{"id":"2010.12706","submitter":"Deepak K. Agrawal","authors":"Deepak. K. Agrawal, Bradford J. Smith, Peter D. Sottile, and David J.\n  Albers","title":"A damaged-informed lung model for ventilator waveforms","comments":"22 pages, 7 figure, 1 table and Supplementary File","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The acute respiratory distress syndrome (ARDS) is characterized by the acute\ndevelopment of diffuse alveolar damage (DAD) resulting in increased vascular\npermeability and decreased alveolar gas exchange. Mechanical ventilation is a\npotentially lifesaving intervention to improve oxygen exchange but has the\npotential to cause ventilator-induced lung injury (VILI). A general strategy to\nreduce VILI is to use low tidal volume and low-pressure ventilation, but\noptimal ventilator settings for an individual patient are difficult for the\nbedside physician to determine and mortality from ARDS remains unacceptably\nhigh. Motivated by the need to minimize VILI, scientists have developed models\nof varying complexity to understand diseased pulmonary physiology. However,\nsimple models often fail to capture real-world injury while complex models tend\nto not be estimable with clinical data, limiting the clinical utility of\nexisting models. To address this gap, we present a physiologically anchored\ndata-driven model to better model lung injury. Our approach relies on using\nclinically relevant features in the ventilator waveform data that contain\ninformation about pulmonary physiology, patients-ventilator interaction and\nventilator settings. Our lung model can reproduce essential physiology and\npathophysiology dynamics of differently damaged lungs for both controlled mouse\nmodel data and uncontrolled human ICU data. The estimated parameters values\nthat are correlated with a known measure of lung physiology agree with the\nobserved lung damage. In future endeavors, this model could be used to\nphenotype ventilator waveforms and serve as a basis for predicting the course\nof ARDS and improving patient care.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:23:31 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12707","submitter":"Dorottya Demszky","authors":"Dorottya Demszky, Devyani Sharma, Jonathan H. Clark, Vinodkumar\n  Prabhakaran, Jacob Eisenstein","title":"Learning to Recognize Dialect Features","comments":"NAACL camera-ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Building NLP systems that serve everyone requires accounting for dialect\ndifferences. But dialects are not monolithic entities: rather, distinctions\nbetween and within dialects are captured by the presence, absence, and\nfrequency of dozens of dialect features in speech and text, such as the\ndeletion of the copula in \"He {} running\". In this paper, we introduce the task\nof dialect feature detection, and present two multitask learning approaches,\nboth based on pretrained transformers. For most dialects, large-scale annotated\ncorpora for these features are unavailable, making it difficult to train\nrecognizers. We train our models on a small number of minimal pairs, building\non how linguists typically define dialect features. Evaluation on a test set of\n22 dialect features of Indian English demonstrates that these models learn to\nrecognize many features with high accuracy, and that a few minimal pairs can be\nas effective for training as thousands of labeled examples. We also demonstrate\nthe downstream applicability of dialect feature detection both as a measure of\ndialect density and as a dialect classifier.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:25:00 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 05:23:13 GMT"},{"version":"v3","created":"Thu, 6 May 2021 22:27:50 GMT"}],"update_date":"2021-05-10"}
{"id":"2010.12708","submitter":"Flavia Luane Rommel","authors":"F. L. Rommel (1, 2 and 3), F. Braga-Ribas (2, 1 and 3), J. Desmars (4\n  and 5), J. I. B. Camargo (1 and 3), J. L. Ortiz (6), B. Sicardy (7), R.\n  Vieira-Martins (1 and 3), M. Assafin (8 and 3), P. Santos-Sanz (6), R.\n  Duffard (6), E. Fern\\'andez-Valenzuela (9), J. Lecacheux (7), B. E. Morgado\n  (7, 1 and 3), G. Benedetti-Rossi (7 and 3), A. R. Gomes-J\\'unior (10), C. L.\n  Pereira (2 and 3), D. Herald (11, 12 and 13), W. Hanna (11 and 12), J.\n  Bradshaw (14), N. Morales (6), J. Brimacombe (15), A. Burtovoi (16 and 17),\n  T. Carruthers (18), J. R. de Barros (19), M. Fiori (20 and 17), A. Gilmore\n  (21), D. Hooper (11 and 12), K. Hornoch (22), C. Jacques (19), T. Janik (11),\n  S. Kerr (12 and 13), P. Kilmartin (21), Jan Maarten Winkel (11), G. Naletto\n  (20 and 17), D. Nardiello (24 and 17), V. Nascimbeni (17 and 20), J. Newman\n  (11 and 13), A. Ossola (25), A. P\\'al (26, 27 and 28), E. Pimentel (19), P.\n  Pravec (22), S. Sposetti (25), A. Stechina (29), R. Sz\\'akats (26), Y. Ueno\n  (30), L. Zampieri (17), J. Broughton (31 and 12), J. B. Dunham (11), D. W.\n  Dunham (11), D. Gault (12), T. Hayamizu (30), K. Hosoi (30), E. Jehin (32),\n  R. Jones (11), K. Kitazaki (30), R. Kom\\v{z}\\'ik (33), A. Marciniak (34), A.\n  Maury (35), H. Miku\\v{z} (36), P. Nosworthy (12), J. F\\'abrega Polleri (37),\n  S. Rahvar (38), R. Sfair (10), P. B. Siqueira (10), C. Snodgrass (39), P.\n  Sogorb (40), H. Tomioka (30), J. Tregloan-Reed (41), and O. C. Winter (10)\n  ((1) Observat\\'orio Nacional/MCTIC, R. General Jos\\'e Cristino 77, Bairro\n  Imperial de S\\~ao Crist\\'ov\\~ao, Rio de Janeiro (RJ), Brazil, (2) Federal\n  University of Technology - Paran\\'a (UTFPR / DAFIS), Rua Sete de Setembro,\n  3165, Curitiba (PR), Brazil, (3) Laborat\\'orio Interinstitucional de\n  e-Astronomia - LIneA and INCT do e-Universo, Rua Gal. Jos\\'e Cristino 77,\n  Bairro Imperial de S\\~ao Crist\\'ov\\~ao, Rio de Janeiro (RJ), Brazil, (4)\n  Institut Polytechnique des Sciences Avanc\\'ees IPSA, 63 boulevard de\n  Brandebourg, F-94200 Ivry-sur-Seine, France, (5) Institut de M\\'ecanique\n  C\\'eleste et de Calcul des \\'Eph\\'em\\'erides, IMCCE, Observatoire de Paris,\n  PSL Research University, CNRS, Sorbonne Universit\\'es, UPMC Univ Paris 06,\n  Univ. Lille, 77, Av. Denfert-Rochereau, F-75014 Paris, France, (6) Instituto\n  de Astrof\\'isica de Andaluc\\'ia, IAA-CSIC, Glorieta de la Astronom\\'ia s/n,\n  18008 Granada, Spain, (7) LESIA, Observatoire de Paris, Universit\\'e PSL,\n  CNRS, Sorbonne Universit\\'e, Univ. Paris Diderot, Sorbonne Paris Cit\\'e, 5\n  place Jules Janssen, 92195 Meudon, France, (8) Observat\\'orio do\n  Valongo/UFRJ, Ladeira Pedro Ant\\^onio 43, Rio de Janeiro (RJ), Brazil, (9)\n  Florida Space Institute, University of Central Florida, 12354 Research\n  Parkway, Partnership 1, Orlando, FL, USA, (10) UNESP - S\\~ao Paulo State\n  University, Grupo de Din\\^amica Orbital e Planetologia, CEP 12516-410,\n  Guaratinguet\\'a, SP, Brazil, (11) International Occultation Timing\n  Association (IOTA), P.O. Box 423, Greenbelt, MD 20768, USA, (12) Trans -\n  Tasman Occultation Alliance (TTOA), Wellington PO Box 3181, New Zealand, (13)\n  Canberra Astronomical Society, Canberra, ACT, Australia, (14) Samford Valley\n  Observatory (Q79), Queensland, Australia, (15) Coral Towers Observatory,\n  Cairns, QLD 4870, Australia, (16) Centre of Studies and Activities for Space\n  (CISAS) 'G. Colombo', University of Padova, Via Venezia 15, 35131, (17) INAF\n  - Astronomical Observatory of Padova, Vicolo dell'Osservatorio 5, I-35122\n  Padova, Italy, (18) Jewel Box Observatory, 69 Falcon St, Bayview Heights QLD\n  4868, Australia, (19) SONEAR Observatory, Oliveira (MG), Brazil, (20)\n  Department of Physics and Astronomy 'G. Galilei', University of Padova, Via\n  F. Marzolo 8, 35131, Padova, Italy, (21) Mount John University Observatory,\n  University of Canterbury, P.O. Box 56, Lake Tekapo 7945, New Zealand, (22)\n  Astronomical Institute, Academy of Sciences of the Czech Republic,\n  Fri\\v{c}ova 298, 251 65 Ond\\v{r}ejov, Czech Republic, (23) Astronomical\n  Association of Queensland, 5 Curtis Street, Pimpama QLD 4209, Australia, (24)\n  Aix Marseille Univ, CNRS, CNES, LAM, Marseille, France, (25) SOTAS - Stellar\n  Occultation Timing Association Switzerland, Swiss Astronomical Society,\n  Switzerland, (26) Konkoly Observatory, Research Centre for Astronomy and\n  Earth Sciences, Konkoly - Thege Mikl\\'os \\'ut 15 - 17, 1121 Budapest,\n  Hungary, (27) E\\\"otv\\\"os Lor\\'and University, Department of Astronomy,\n  P\\'azm\\'any P\\'eter s\\'et\\'any 1/A, 1117 Budapest, Hungary, (28) ELTE\n  E\\\"otv\\\"os Lor\\'and University, Institute of Physics, P\\'azm\\'any P\\'eter\n  s\\'et\\'any 1/A, 1117 Budapest, Hungary, (29) Centro de Amigos de la\n  Astronomia Reconquista - CAAR, Reconquista, Argentina, (30) Japan Occultation\n  Information Network (JOIN), Japan, (31) Reedy Creek Observatory, Gold Coast,\n  Queensland, Australia, (32) STAR Institute, Universit\\'e de Li\\`ege, All\\'ee\n  du 6 ao\\^ut, 19C, 4000 Li\\`ege, Belgium, (33) Astronomical Institute, Slovak\n  Academy of Sciences, 059 60 Tatransk\\'a Lomnica, Slovakia, (34) Astronomical\n  Observatory Institute, Faculty of Physics, Adam Mickiewicz University,\n  Poznan, Poland, (35) San Pedro de Atacama Celestial Explorations - SPACE,\n  Chile, (36) University of Ljubljana, Faculty of Mathematics and Physics,\n  Jadranska 19, 1000 Ljubljana, Slovenia, (37) Panamanian Observatory in San\n  Pedro de Atacama - OPSPA, (38) Department of Physics, Sharif University of\n  Technology, P.O. Box 11155-9161 Tehran, Iran, (39) Institute for Astronomy,\n  University of Edinburgh, Royal Observatory, Edinburgh EH9 3HJ, UK, (40) Club\n  d'astronomie Luberon Sud Astro, La Bastide des Jourdans, France, (41) Centro\n  de Astronom\\'ia (CITEVA), Universidad de Antofagasta, Avenida U. de\n  Antofagasta, 02800 Antofagasta, Chile )","title":"Stellar occultations enable milliarcsecond astrometry for\n  Trans-Neptunian objects and Centaurs","comments":"16 pages, 28 figures. The manuscript was accepted and is to be\n  published","journal-ref":"A&A 644, A40 (2020)","doi":"10.1051/0004-6361/202039054","report-no":null,"categories":"astro-ph.EP astro-ph.IM","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Trans-Neptunian objects (TNOs) and Centaurs are remnants of our planetary\nsystem formation, and their physical properties have invaluable information for\nevolutionary theories. Stellar occultation is a ground-based method for\nstudying these small bodies and has presented exciting results. These\nobservations can provide precise profiles of the involved body, allowing an\naccurate determination of its size and shape. The goal is to show that even\nsingle-chord detections of TNOs allow us to measure their milliarcsecond\nastrometric positions in the reference frame of the Gaia second data release\n(DR2). Accurated ephemerides can then be generated, allowing predictions of\nstellar occultations with much higher reliability. We analyzed data from\nstellar occultations to obtain astrometric positions of the involved bodies.\nThe events published before the Gaia era were updated so that the Gaia DR2\ncatalog is the reference. Previously determined sizes were used to calculate\nthe position of the object center and its corresponding error with respect to\nthe detected chord and the International Celestial Reference System (ICRS)\npropagated Gaia DR2 star position. We derive 37 precise astrometric positions\nfor 19 TNOs and 4 Centaurs. Twenty-one of these events are presented here for\nthe first time. Although about 68\\% of our results are based on single-chord\ndetection, most have intrinsic precision at the submilliarcsecond level. Lower\nlimits on the diameter and shape constraints for a few bodies are also\npresented as valuable byproducts. Using the Gaia DR2 catalog, we show that even\na single detection of a stellar occultation allows improving the object\nephemeris significantly, which in turn enables predicting a future stellar\noccultation with high accuracy. Observational campaigns can be efficiently\norganized with this help, and may provide a full physical characterization of\nthe involved object.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:26:22 GMT"}],"update_date":"2021-01-04"}
{"id":"2010.12709","submitter":"Ana Melva Champi Farfan A. Champi","authors":"Sergio L. L. M. Ramos, Marcos A. Pimenta and Ana Champi","title":"Multiple-excitation study of the double-resonance Raman bands in\n  rhombohedral graphite","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The double-resonance (DR) Raman process is a signature of all sp2 carbon\nmaterial and provide fundamental information of the electronic structure and\nphonon dispersion in graphene, carbon nanotubes and different graphite-type\nmaterials. We have performed in this work the study of different DR Raman bands\nof rhombohedral graphite using five different excitation laser energies and\nobtained the dispersion of the different DR features by changing the laser\nenergy. Results are compared with those of Bernal graphite and shows that\nrhombohedral graphite exhibit a richer DR Raman spectrum. For example, the 2D\nband of rhombohedral graphite is broader and composed by several maxima that\nexhibit different dispersive behavior. The occurrence of more DR conditions in\nrhombohedral graphite is ascribed to the fact that the volume of its Brillouin\nzone (BZ) is twice the volume of the Bernal BZ, allowing thus more channels for\nthe resonance condition. The spectra of the intervalley TO-LA band of\nrhombohedral graphite, around 2450 cm-1, is also broader and richer in features\ncompared to that of Bernal graphite. Results and analysis of the spectral\nregion 1700-1850 cm-1, where different intravalley processes involving acoustic\nand optical phonons occurs, are also presented.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:33:47 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12710","submitter":"Maria Phillips","authors":"Debajyoti Datta, Maria Phillips, Jennifer Chiu, Ginger S. Watson,\n  James P. Bywater, Laura Barnes, and Donald Brown","title":"Improving Classification through Weak Supervision in Context-specific\n  Conversational Agent Development for Teacher Education","comments":"Preprint: Under Review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CY cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning techniques applied to the Natural Language Processing (NLP)\ncomponent of conversational agent development show promising results for\nimproved accuracy and quality of feedback that a conversational agent can\nprovide. The effort required to develop an educational scenario specific\nconversational agent is time consuming as it requires domain experts to label\nand annotate noisy data sources such as classroom videos. Previous approaches\nto modeling annotations have relied on labeling thousands of examples and\ncalculating inter-annotator agreement and majority votes in order to model the\nnecessary scenarios. This method, while proven successful, ignores individual\nannotator strengths in labeling a data point and under-utilizes examples that\ndo not have a majority vote for labeling. We propose using a multi-task weak\nsupervision method combined with active learning to address these concerns.\nThis approach requires less labeling than traditional methods and shows\nsignificant improvements in precision, efficiency, and time-requirements than\nthe majority vote method (Ratner 2019). We demonstrate the validity of this\nmethod on the Google Jigsaw data set and then propose a scenario to apply this\nmethod using the Instructional Quality Assessment(IQA) to define the categories\nfor labeling. We propose using probabilistic modeling of annotator labeling to\ngenerate active learning examples to further label the data. Active learning is\nable to iteratively improve the training performance and accuracy of the\noriginal classification model. This approach combines state-of-the art labeling\ntechniques of weak supervision and active learning to optimize results in the\neducational domain and could be further used to lessen the data requirements\nfor expanded scenarios within the education domain through transfer learning.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:39:40 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12711","submitter":"Poorya Mianjy","authors":"Poorya Mianjy and Raman Arora","title":"On Convergence and Generalization of Dropout Training","comments":null,"journal-ref":"In Proceedings of Advances in Neural Information Processing\n  Systems (NeurIPS), 2020","doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study dropout in two-layer neural networks with rectified linear unit\n(ReLU) activations. Under mild overparametrization and assuming that the\nlimiting kernel can separate the data distribution with a positive margin, we\nshow that dropout training with logistic loss achieves $\\epsilon$-suboptimality\nin test error in $O(1/\\epsilon)$ iterations.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:41:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12712","submitter":"Shuguang Chen","authors":"Shuguang Chen, Gustavo Aguilar, Leonardo Neves, Thamar Solorio","title":"Can images help recognize entities? A study of the role of images for\n  Multimodal NER","comments":"Accepted to W-NUT 2021 at EMNLP","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multimodal named entity recognition (MNER) requires to bridge the gap between\nlanguage understanding and visual context. While many multimodal neural\ntechniques have been proposed to incorporate images into the MNER task, the\nmodel's ability to leverage multimodal interactions remains poorly understood.\nIn this work, we conduct in-depth analyses of existing multimodal fusion\ntechniques from different perspectives and describe the scenarios where adding\ninformation from the image does not always boost performance. We also study the\nuse of captions as a way to enrich the context for MNER. Experiments on three\ndatasets from popular social platforms expose the bottleneck of existing\nmultimodal models and the situations where using captions is beneficial.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:41:51 GMT"},{"version":"v2","created":"Sun, 19 Sep 2021 22:56:24 GMT"}],"update_date":"2021-09-21"}
{"id":"2010.12713","submitter":"Ashutosh Pandey","authors":"Ashutosh Pandey and DeLiang Wang","title":"Dual-path Self-Attention RNN for Real-Time Speech Enhancement","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a dual-path self-attention recurrent neural network (DP-SARNN) for\ntime-domain speech enhancement. We improve dual-path RNN (DP-RNN) by augmenting\ninter-chunk and intra-chunk RNN with a recently proposed efficient attention\nmechanism. The combination of inter-chunk and intra-chunk attention improves\nthe attention mechanism for long sequences of speech frames. DP-SARNN\noutperforms a baseline DP-RNN by using a frame shift four times larger than in\nDP-RNN, which leads to a substantially reduced computation time per utterance.\nAs a result, we develop a real-time DP-SARNN by using long short-term memory\n(LSTM) RNN and causal attention in inter-chunk SARNN. DP-SARNN significantly\noutperforms existing approaches to speech enhancement, and on average takes 7.9\nms CPU time to process a signal chunk of 32 ms.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:42:37 GMT"},{"version":"v2","created":"Thu, 29 Apr 2021 16:36:10 GMT"}],"update_date":"2021-04-30"}
{"id":"2010.12714","submitter":"Arlene Cristina Aguilar","authors":"A. C. Aguilar, M. N. Ferreira, J. Papavassiliou","title":"Gluon dynamics from an ordinary differential equation","comments":"35 pages, 12 figures, 2 tables","journal-ref":null,"doi":"10.1140/epjc/s10052-021-08849-8","report-no":null,"categories":"hep-ph hep-lat hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a novel method for computing the nonperturbative kinetic term of\nthe gluon propagator from an exactly solvable ordinary differential equation,\nwhose origin is the fundamental Slavnov-Taylor identity satisfied by the\nthree-gluon vertex, evaluated in a special kinematic limit. The main\ningredients comprising the solution are a well-known projection of the\nthree-gluon vertex, simulated on the lattice, and a particular derivative of\nthe ghost-gluon kernel, whose approximate form is derived from a standard\nSchwinger-Dyson equation. Crucially, the physical requirement of a pole-free\nanswer determines completely the form of the initial condition, whose value is\ncalculated from a specific integral containing the same ingredients as the\nsolution itself. This outstanding feature fixes uniquely, at least in\nprinciple, the form of the kinetic term, once the ingredients of the\ndifferential equation have been accurately evaluated. Furthermore, in the case\nwhere the gluon propagator has been independently accessed from the lattice,\nthis property leads to the unambiguous extraction of the momentum-dependent\neffective gluon mass. The practical implementation of this method is carried\nout in detail, and the required approximations and theoretical assumptions are\nduly highlighted. The systematic improvement of this approach through the\ndetailed computation of one of its pivotal components is briefly outlined.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:44:50 GMT"}],"update_date":"2021-02-03"}
{"id":"2010.12715","submitter":"Jagadeesh Balam","authors":"Jagadeesh Balam, Jocelyn Huang, Vitaly Lavrukhin, Slyne Deng,\n  Somshubra Majumdar, Boris Ginsburg","title":"Improving Noise Robustness of an End-to-End Neural Model for Automatic\n  Speech Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present our experiments in training robust to noise an end-to-end\nautomatic speech recognition (ASR) model using intensive data augmentation. We\nexplore the efficacy of fine-tuning a pre-trained model to improve noise\nrobustness, and we find it to be a very efficient way to train for various\nnoisy conditions, especially when the conditions in which the model will be\nused, are unknown. Starting with a model trained on clean data helps establish\nbaseline performance on clean speech. We carefully fine-tune this model to both\nmaintain the performance on clean speech, and improve the model accuracy in\nnoisy conditions. With this schema, we trained robust to noise English and\nMandarin ASR models on large public corpora. All described models and training\nrecipes are open sourced in NeMo, a toolkit for conversational AI.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:46:29 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12716","submitter":"Luis Enrique Padilla Abores","authors":"Luis E. Padilla, Tanja Rindler-Daller, Paul R. Shapiro, Tonatiuh\n  Matos, and J. Alberto V\\'azquez","title":"Core-Halo Mass Relation in Scalar Field Dark Matter Models and its\n  Consequences for the Formation of Supermassive Black Holes","comments":"27 pages, 7 figures, minor updates to accord with the published\n  version in Phys. Rev. D","journal-ref":"Phys. Rev. D 103, 063012 (2021)","doi":"10.1103/PhysRevD.103.063012","report-no":null,"categories":"astro-ph.GA gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Scalar-field dark matter (SFDM) halos exhibit a core-envelope structure with\nsoliton-like cores and CDM-like envelopes. Simulations without self-interaction\n(free-field case) report a core-halo mass relation $M_c\\propto M_{h}^{\\beta}$,\nwith either $\\beta=1/3$ or $\\beta=5/9$, which can be understood if core and\nhalo obey certain energy or velocity scalings. We extend the core-halo mass\nrelations to include SFDM with self-interaction (SI), either repulsive or\nattractive, and investigate its implications for the gravitational instability\nand collapse of solitonic cores, leading to supermassive black hole (SMBH)\nformation. For SFDM parameters that make $\\sim$ Kpc-sized cores and CDM-like\nstructure formation on large scales but suppressed on small scales, cores are\nstable for all galactic halos of interest, from the free-field to the repulsive\nSI limit. For attractive SI, however, halos masses $M_h\\sim (10^{10}-10^{12})\nM_\\odot$ have cores that collapse to SMBHs with $M_{SMBH}\\sim 10^{6}-10^8\nM_\\odot$, as observations seem to require, while smaller-mass halos have stable\ncores, for particle masses $m\\simeq (2.14\\times 10^{-22}-9.9\\times\n10^{-20})\\rm{eV}/c^2$, if the free-field has $\\beta=1/3$, or $m = 2.23\\times\n10^{-21}-1.7\\times 10^{-18}\\rm{eV}/c^2$, if $\\beta=5/9$. For free-field and\nrepulsive cases, however, if previous constraints on particle parameters are\nrelaxed to allow much smaller (sub-galactic scale) cores, then halos can also\nform SMBHs, for the same range of halo and BH masses, as long as $\\beta = 5/9$\nis correct for the free-field. In that case, structure formation in SFDM would\nbe largely indistinguishable from Cold Dark Matter (CDM). Such SFDM models\nmight not resolve the small-scale structure problems of CDM, but they would\nexplain the formation of SMBHs quite naturally. Since CDM, itself, has not yet\nbeen ruled out, such SFDM models must also be viable (Abbreviated).\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:48:37 GMT"},{"version":"v2","created":"Sat, 13 Feb 2021 07:06:05 GMT"},{"version":"v3","created":"Mon, 19 Apr 2021 22:57:54 GMT"}],"update_date":"2022-11-08"}
{"id":"2010.12717","submitter":"Isura Nirmal B.A","authors":"Isura Nirmal, Abdelwahed Khamis, Mahbub Hassan, Wen Hu, Xiaoqing Zhu","title":"Deep Learning for Radio-based Human Sensing: Recent Advances and Future\n  Directions","comments":null,"journal-ref":"23, 2021, 995-1019","doi":"10.1109/COMST.2021.3058333","report-no":null,"categories":"eess.SP cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While decade-long research has clearly demonstrated the vast potential of\nradio frequency (RF) for many human sensing tasks, scaling this technology to\nlarge scenarios remained problematic with conventional approaches. Recently,\nresearchers have successfully applied deep learning to take radio-based sensing\nto a new level. Many different types of deep learning models have been proposed\nto achieve high sensing accuracy over a large population and activity set, as\nwell as in unseen environments. Deep learning has also enabled detection of\nnovel human sensing phenomena that were previously not possible. In this\nsurvey, we provide a comprehensive review and taxonomy of recent research\nefforts on deep learning based RF sensing. We also identify and compare several\npublicly released labeled RF sensing datasets that can facilitate such deep\nlearning research. Finally, we summarize the lessons learned and discuss the\ncurrent limitations and future directions of deep learning based RF sensing.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:51:56 GMT"},{"version":"v2","created":"Sun, 7 Feb 2021 23:47:07 GMT"}],"update_date":"2021-07-07"}
{"id":"2010.12718","submitter":"Tanmay Gangwani","authors":"Tanmay Gangwani, Yuan Zhou, Jian Peng","title":"Learning Guidance Rewards with Trajectory-space Smoothing","comments":"NeurIPS 2020 camera-ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Long-term temporal credit assignment is an important challenge in deep\nreinforcement learning (RL). It refers to the ability of the agent to attribute\nactions to consequences that may occur after a long time interval. Existing\npolicy-gradient and Q-learning algorithms typically rely on dense environmental\nrewards that provide rich short-term supervision and help with credit\nassignment. However, they struggle to solve tasks with delays between an action\nand the corresponding rewarding feedback. To make credit assignment easier,\nrecent works have proposed algorithms to learn dense \"guidance\" rewards that\ncould be used in place of the sparse or delayed environmental rewards. This\npaper is in the same vein -- starting with a surrogate RL objective that\ninvolves smoothing in the trajectory-space, we arrive at a new algorithm for\nlearning guidance rewards. We show that the guidance rewards have an intuitive\ninterpretation, and can be obtained without training any additional neural\nnetworks. Due to the ease of integration, we use the guidance rewards in a few\npopular algorithms (Q-learning, Actor-Critic, Distributional-RL) and present\nresults in single-agent and multi-agent tasks that elucidate the benefit of our\napproach when the environmental rewards are sparse or delayed.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 23:55:06 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12719","submitter":"Falcon Dai","authors":"Falcon Z. Dai","title":"Word2vec Conjecture and A Limitative Result","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Being inspired by the success of \\texttt{word2vec}\n\\citep{mikolov2013distributed} in capturing analogies, we study the conjecture\nthat analogical relations can be represented by vector spaces. Unlike many\nprevious works that focus on the distributional semantic aspect of\n\\texttt{word2vec}, we study the purely \\emph{representational} question: can\n\\emph{all} semantic word-word relations be represented by differences (or\ndirections) of vectors? We call this the word2vec conjecture and point out some\nof its desirable implications. However, we will exhibit a class of relations\nthat cannot be represented in this way, thus falsifying the conjecture and\nestablishing a limitative result for the representability of semantic relations\nby vector spaces over fields of characteristic 0, e.g., real or complex\nnumbers.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:14:04 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12720","submitter":"Mattheus Aguiar","authors":"Mattheus Aguiar and Pavel Zalesski","title":"The profinite completion of the fundamental group of infinite graphs of\n  groups","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Let $(\\mathcal{G},\\Gamma)$ be an abstract graph of finite groups. If $\\Gamma$\nis finite, we can construct a profinite graph of groups in a natural way\n$(\\hat{\\mathcal{G}},\\Gamma)$, where $\\hat{\\mathcal{G}}(m)$ is the profinite\ncompletion of $\\mathcal{G}(m)$ for all $m \\in \\Gamma$. The main reason for this\nis that $\\Gamma$ is finite, so it is already profinite. In this paper we deal\nwith the infinite case, by constructing a profinite graph $\\overline{\\Gamma}$\nwhere $\\Gamma$ is densely embedded and then defining a profinite graph of\ngroups $(\\widehat{\\mathcal{G}},\\overline{\\Gamma})$. We also prove that the\nfundamental group $\\Pi_1(\\widehat{\\mathcal{G}},\\overline{\\Gamma})$ is the\nprofinite completion of $\\Pi_1^{abs}(\\mathcal{G},\\Gamma)$. This answers Open\nQuestion 6.7.1 of the book Profinite Graphs and Groups, published by Luis Ribes\nin 2017. Later we generalise the main theorem of a paper by Luis Ribes and the\nsecond author, proving that if $R$ is a virtually free abstract group and $H$\nis a finitely generated subgroup of $R$, then\n$\\overline{N_{R}(H)}=N_{\\hat{R}}(\\overline{H})$ answering Open Question\n15.11.10 of the book of Ribes. Finally, we generalise the main theorem of a\npaper by Sheila Chagas and the second author, showing that every virtually free\ngroup is subgroup conjugacy separable. This answers Open Question 15.11.11 of\nthe same book of Ribes.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:14:55 GMT"},{"version":"v2","created":"Thu, 6 May 2021 12:56:30 GMT"}],"update_date":"2021-05-07"}
{"id":"2010.12721","submitter":"Alireza Mehrtash","authors":"Alireza Mehrtash, Purang Abolmaesumi, Polina Golland, Tina Kapur,\n  Demian Wassermann, William M. Wells III","title":"PEP: Parameter Ensembling by Perturbation","comments":"NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ensembling is now recognized as an effective approach for increasing the\npredictive performance and calibration of deep networks. We introduce a new\napproach, Parameter Ensembling by Perturbation (PEP), that constructs an\nensemble of parameter values as random perturbations of the optimal parameter\nset from training by a Gaussian with a single variance parameter. The variance\nis chosen to maximize the log-likelihood of the ensemble average ($\\mathbb{L}$)\non the validation data set. Empirically, and perhaps surprisingly, $\\mathbb{L}$\nhas a well-defined maximum as the variance grows from zero (which corresponds\nto the baseline model). Conveniently, calibration level of predictions also\ntends to grow favorably until the peak of $\\mathbb{L}$ is reached. In most\nexperiments, PEP provides a small improvement in performance, and, in some\ncases, a substantial improvement in empirical calibration. We show that this\n\"PEP effect\" (the gain in log-likelihood) is related to the mean curvature of\nthe likelihood function and the empirical Fisher information. Experiments on\nImageNet pre-trained networks including ResNet, DenseNet, and Inception showed\nimproved calibration and likelihood. We further observed a mild improvement in\nclassification accuracy on these networks. Experiments on classification\nbenchmarks such as MNIST and CIFAR-10 showed improved calibration and\nlikelihood, as well as the relationship between the PEP effect and overfitting;\nthis demonstrates that PEP can be used to probe the level of overfitting that\noccurred during training. In general, no special training procedure or network\narchitecture is needed, and in the case of pre-trained networks, no additional\ntraining is needed.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:16:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12722","submitter":"David Arnas","authors":"David Arnas and Richard Linares","title":"A set of orbital elements to fully represent the zonal harmonics around\n  an oblate celestial body","comments":"38 pages, 7 figures","journal-ref":null,"doi":"10.1093/mnras/staa4040","report-no":null,"categories":"astro-ph.EP math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work introduces a new set of orbital elements to fully represent the\nzonal harmonics problem around an oblate celestial body. This new set of\norbital elements allows to obtain a complete linear system for the unperturbed\nproblem and, in addition, a complete polynomial system when considering the\nperturbation produced by the zonal harmonics from the gravitational force of an\noblate celestial body. These orbital elements present no singularities and are\nable to represent any kind of orbit, including elliptic, parabolic and\nhyperbolic orbits. In addition, an application to this formulation of the\nPoincar\\'e-Lindstedt perturbation method is included to obtain an approximate\nfirst order solution of the problem for the case of the J2 perturbation.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:21:29 GMT"}],"update_date":"2021-01-13"}
{"id":"2010.12723","submitter":"Yuning Mao","authors":"Yuning Mao, Xiang Ren, Heng Ji, Jiawei Han","title":"Constrained Abstractive Summarization: Preserving Factual Consistency\n  with Constrained Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite significant progress, state-of-the-art abstractive summarization\nmethods are still prone to hallucinate content inconsistent with the source\ndocument. In this paper, we propose Constrained Abstractive Summarization\n(CAS), a general setup that preserves the factual consistency of abstractive\nsummarization by specifying tokens as constraints that must be present in the\nsummary. We adopt lexically constrained decoding, a technique generally\napplicable to autoregressive generative models, to fulfill CAS and conduct\nexperiments in two scenarios: (1) automatic summarization without human\ninvolvement, where keyphrases are extracted from the source document and used\nas constraints; (2) human-guided interactive summarization, where human\nfeedback in the form of manual constraints are used to guide summary\ngeneration. Automatic and human evaluations on two benchmark datasets\ndemonstrate that CAS improves both lexical overlap (ROUGE) and factual\nconsistency of abstractive summarization. In particular, we observe up to 13.8\nROUGE-2 gains when only one manual constraint is used in interactive\nsummarization.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:27:44 GMT"},{"version":"v2","created":"Thu, 16 Dec 2021 05:20:15 GMT"}],"update_date":"2021-12-17"}
{"id":"2010.12724","submitter":"Guobao Wang","authors":"Yang Zuo, Javier E. Lopez, Thomas W. Smith, Cameron C. Foster, Richard\n  E. Carson, Ramsey D. Badawi, Guobao Wang","title":"Multiparametric Cardiac 18F-FDG PET: Pilot Comparison of FDG Delivery\n  Rate with 82Rb Myocardial Blood Flow","comments":null,"journal-ref":null,"doi":"10.1088/1361-6560/ac15a6","report-no":null,"categories":"physics.med-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Myocardial blood flow (MBF) and flow reserve are usually quantified in the\nclinic with positron emission tomography (PET) using a perfusion-specific\nradiotracer (e.g. 82Rbchloride). However, the clinical accessibility of\nexisting perfusion tracers remains limited. Meanwhile, 18F-fluorodeoxyglucose\n(FDG) is a commonly used radiotracer for PET metabolic imaging without similar\nlimitations. In this paper, we explore the potential of 18F-FDG for myocardial\nperfusion imaging by comparing the myocardial FDG delivery rate K1 with MBF as\ndetermined by dynamic 82Rb PET in fourteen human subjects with heart disease.\nTwo sets of FDG K1 were derived from one-hour dynamic FDG scans. One was the\noriginal FDG K1 estimates and the other was the corresponding K1 values that\nwere linearly normalized for blood glucose levels. A generalized Renkin-Crone\nmodel was used to fit FDG K1 with Rb MBF, which then allowed for a nonlinear\nextraction fraction correction for converting FDG K1 to MBF. The linear\ncorrelation between FDG-derived MBF and Rb MBF was moderate (r=0.79) before the\nglucose normalization and became much improved (r>0.9) after glucose\nnormalization. The extraction fraction of FDG was also similar to that of\nRb-chloride in the myocardium. The results from this pilot study suggest that\ndynamic cardiac FDG-PET with tracer kinetic modeling has the potential to\nprovide MBF in addition to its conventional use for metabolic imaging.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:27:47 GMT"},{"version":"v2","created":"Tue, 23 Feb 2021 02:28:05 GMT"},{"version":"v3","created":"Wed, 10 Mar 2021 05:05:22 GMT"},{"version":"v4","created":"Tue, 13 Jul 2021 02:07:47 GMT"}],"update_date":"2021-09-01"}
{"id":"2010.12725","submitter":"Peter Shaw","authors":"Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova","title":"Compositional Generalization and Natural Language Variation: Can a\n  Semantic Parsing Approach Handle Both?","comments":"ACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Sequence-to-sequence models excel at handling natural language variation, but\nhave been shown to struggle with out-of-distribution compositional\ngeneralization. This has motivated new specialized architectures with stronger\ncompositional biases, but most of these approaches have only been evaluated on\nsynthetically-generated datasets, which are not representative of natural\nlanguage variation. In this work we ask: can we develop a semantic parsing\napproach that handles both natural language variation and compositional\ngeneralization? To better assess this capability, we propose new train and test\nsplits of non-synthetic datasets. We demonstrate that strong existing\napproaches do not perform well across a broad set of evaluations. We also\npropose NQG-T5, a hybrid model that combines a high-precision grammar-based\napproach with a pre-trained sequence-to-sequence model. It outperforms existing\napproaches across several compositional generalization challenges on\nnon-synthetic data, while also being competitive with the state-of-the-art on\nstandard evaluations. While still far from solving this problem, our study\nhighlights the importance of diverse evaluations and the open challenge of\nhandling both compositional generalization and natural language variation in\nsemantic parsing.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:38:27 GMT"},{"version":"v2","created":"Tue, 1 Jun 2021 21:25:04 GMT"}],"update_date":"2021-06-03"}
{"id":"2010.12726","submitter":"Shatadal Mishra","authors":"Karishma Patnaik, Shatadal Mishra, Seyed Mostafa Rezayat Sorkhabadi,\n  Wenlong Zhang","title":"Design and Control of SQUEEZE: A Spring-augmented QUadrotor for\n  intEractions with the Environment to squeeZE-and-fly","comments":"Accepted to International Conference on Intelligent Robots and\n  Systems (IROS) 2020","journal-ref":null,"doi":"10.1109/IROS45743.2020.9341730","report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents the design and control of a novel quadrotor with a\nvariable geometry to physically interact with cluttered environments and fly\nthrough narrow gaps and passageways. This compliant quadrotor with passive\nmorphing capabilities is designed using torsional springs at every arm hinge to\nallow for rotation driven by external forces. We derive the dynamic model of\nthis variable geometry quadrotor (SQUEEZE), and develop an adaptive controller\nfor trajectory tracking. The corresponding Lyapunov stability proof of attitude\ntracking is also presented. Further, an admittance controller is designed to\naccount for changes in yaw due to physical interactions with the environment.\nFinally, the proposed design is validated in flight tests with two setups: a\nsmall gap and a passageway. The experimental results demonstrate the unique\ncapability of the SQUEEZE in navigating through constrained narrow spaces.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:43:34 GMT"}],"update_date":"2021-03-09"}
{"id":"2010.12727","submitter":"Allan Alinea","authors":"Allan L. Alinea","title":"Cognitive Reflection Test and the Polarizing Force-Identification\n  Questions in the FCI","comments":"9 pages, 5 figures, 2 tables","journal-ref":"Eur. J. Phys. (2020) 41 065707","doi":"10.1088/1361-6404/aba8e9","report-no":null,"categories":"physics.ed-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The set of polarizing force-identification (PFI) questions in the FCI\nconsists of six items all basically asking only one question: the set of forces\nacting on a given body. Although it may sound trivial, these questions are\namong the most challenging in the FCI. In this work involving 163 students, we\ninvestigate the correlation between student performance on the set of PFI\nquestions and the Cognitive Reflection Test. We find that for both scores in\nthe FCI as a whole and in the PFI questions, the range of values of the Pearson\ncoefficient at 95\\% confidence interval, is suggestive that cognitive\nreflection may be one of the contributing factors in the student performance in\nthe FCI. This is consistent with the idea that high level of cognitive\nreflection may help in eliminating seemingly valid choices (misconceptions) in\nthe FCI that are intuitive from everyday experience or \"common sense\" but\notherwise misleading. The ability to activate System 2 in Dual Process Theory,\nwhether from System 1 or right after reading a physics problem, may contribute\nin narrowing down the set of prospective valid answers in a given physics\nproblem. Complementary to cognitive reflection are other factors associated\nwith deep understanding of physics whose effects are expected to become more\nevident with the level of difficulty of a set of physics problems. Given two\nstudents with the same level of cognitive reflection, the one with deeper\nunderstanding of physics is more likely to get the correct answer. In our\nanalysis, the range of correlation coefficient for the set of PFI questions is\ndownshifted with respect to that for the FCI as a whole. This may be attributed\nto the more challenging nature of the latter compared to a significant fraction\nof the remaining questions in the former.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:56:23 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12728","submitter":"Ying Mao","authors":"Ying Mao, Weifeng Yan, Yun Song, Yue Zeng, Ming Chen, Long Cheng, and\n  Qingzhi Liu","title":"Differentiate Quality of Experience Scheduling for Deep Learning\n  Inferences with Docker Containers in the Cloud","comments":null,"journal-ref":null,"doi":"10.1109/TCC.2022.3154117","report-no":null,"categories":"cs.DC cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the prevalence of big-data-driven applications, such as face recognition\non smartphones and tailored recommendations from Google Ads, we are on the road\nto a lifestyle with significantly more intelligence than ever before. Various\nneural network powered models are running at the back end of their intelligence\nto enable quick responses to users. Supporting those models requires lots of\ncloud-based computational resources, e.g., CPUs and GPUs. The cloud providers\ncharge their clients by the amount of resources that they occupy. Clients have\nto balance the budget and quality of experiences (e.g., response time). The\nbudget leans on individual business owners, and the required Quality of\nExperience (QoE) depends on usage scenarios of different applications. For\ninstance, an autonomous vehicle requires an real-time response, but unlocking\nyour smartphone can tolerate delays. However, cloud providers fail to offer a\nQoE-based option to their clients. In this paper, we propose DQoES,\ndifferentiated quality of experience scheduler for deep learning inferences.\nDQoES accepts clients' specifications on targeted QoEs, and dynamically adjusts\nresources to approach their targets. Through the extensive cloud-based\nexperiments, DQoES demonstrates that it can schedule multiple concurrent jobs\nwith respect to various QoEs and achieve up to 8x times more satisfied models\nwhen compared to the existing system\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 00:57:31 GMT"},{"version":"v2","created":"Thu, 22 Sep 2022 22:23:28 GMT"}],"update_date":"2022-09-26"}
{"id":"2010.12729","submitter":"Adina Williams","authors":"Adina Williams, Tristan Thrush, Douwe Kiela","title":"ANLIzing the Adversarial Natural Language Inference Dataset","comments":"33 pages, 1 figure, 24 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We perform an in-depth error analysis of Adversarial NLI (ANLI), a recently\nintroduced large-scale human-and-model-in-the-loop natural language inference\ndataset collected over multiple rounds. We propose a fine-grained annotation\nscheme of the different aspects of inference that are responsible for the gold\nclassification labels, and use it to hand-code all three of the ANLI\ndevelopment sets. We use these annotations to answer a variety of interesting\nquestions: which inference types are most common, which models have the highest\nperformance on each reasoning type, and which types are the most challenging\nfor state of-the-art models? We hope that our annotations will enable more\nfine-grained evaluation of models trained on ANLI, provide us with a deeper\nunderstanding of where models fail and succeed, and help us determine how to\ntrain better models in future.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:03:51 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12730","submitter":"Gustavo Aguilar","authors":"Gustavo Aguilar, Bryan McCann, Tong Niu, Nazneen Rajani, Nitish\n  Keskar, Thamar Solorio","title":"Char2Subword: Extending the Subword Embedding Space Using Robust\n  Character Compositionality","comments":"Findings of EMNLP 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword\ntokenization process of language models as it provides multiple benefits.\nHowever, this process is solely based on pre-training data statistics, making\nit hard for the tokenizer to handle infrequent spellings. On the other hand,\nthough robust to misspellings, pure character-level models often lead to\nunreasonably long sequences and make it harder for the model to learn\nmeaningful words. To alleviate these challenges, we propose a character-based\nsubword module (char2subword) that learns the subword embedding table in\npre-trained models like BERT. Our char2subword module builds representations\nfrom characters out of the subword vocabulary, and it can be used as a drop-in\nreplacement of the subword embedding table. The module is robust to\ncharacter-level alterations such as misspellings, word inflection, casing, and\npunctuation. We integrate it further with BERT through pre-training while\nkeeping BERT transformer parameters fixed--and thus, providing a practical\nmethod. Finally, we show that incorporating our module to mBERT significantly\nimproves the performance on the social media linguistic code-switching\nevaluation (LinCE) benchmark.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:08:28 GMT"},{"version":"v2","created":"Sun, 4 Apr 2021 17:17:23 GMT"},{"version":"v3","created":"Fri, 24 Sep 2021 02:09:51 GMT"}],"update_date":"2021-09-27"}
{"id":"2010.12731","submitter":"Weiqing Wang","authors":"Weiqing Wang, Danwei Cai, Xiaoyi Qin, Ming Li","title":"The DKU-DukeECE Systems for VoxCeleb Speaker Recognition Challenge 2020","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present the system submission for the VoxCeleb Speaker\nRecognition Challenge 2020 (VoxSRC-20) by the DKU-DukeECE team. For track 1, we\nexplore various kinds of state-of-the-art front-end extractors with different\npooling layers and objective loss functions. For track 3, we employ an\niterative framework for self-supervised speaker representation learning based\non a deep neural network (DNN). For track 4, we investigate the whole system\npipeline for speaker diarization, including voice activity detection (VAD),\nuniform segmentation, speaker embedding extraction, and clustering.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:16:59 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12732","submitter":"Sunil Bhave","authors":"Sen Dai, Sunil A. Bhave and Renyuan Wang","title":"Octave-Tunable Magnetostatic Wave YIG Resonators on a Chip","comments":null,"journal-ref":null,"doi":"10.1109/TUFFC.2020.3000055","report-no":null,"categories":"physics.app-ph cond-mat.mes-hall eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have designed, fabricated, and characterized magnetostatic wave (MSW)\nresonators on a chip. The resonators are fabricated by patterning\nsingle-crystal yttrium iron garnet (YIG) film on a gadolinium gallium garnet\n(GGG) substrate and excited by loop-inductor transducers. We achieved this\ntechnology breakthrough by developing a YIG film etching process and\nfabricating thick aluminum coplanar waveguide (CPW) inductor loop around each\nresonator to individually address and excite MSWs. At 4.77 GHz, the 0.68 square\nmm resonator achieves a quality factor Q > 5000 with a bias field of 987 Oe. We\nalso demonstrate YIG resonator tuning by more than one octave from 3.63 to 7.63\nGHz by applying an in-plane external magnetic field. The measured quality\nfactor of the resonator is consistently over 3000 above 4 GHz. The\nmicromachining technology enables the fabrication of multiple single- and\ntwo-port YIG resonators on the same chip with all resonators demonstrating\noctave tunability and high Q .\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:17:10 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12733","submitter":"Zitao Liu","authors":"Hang Li, Wenbiao Ding, Zhongqin Wu, Zitao Liu","title":"Learning Fine-Grained Cross Modality Excitement for Speech Emotion\n  Recognition","comments":"The Interspeech Conference, 2021 (INTERSPEECH 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech emotion recognition is a challenging task because the emotion\nexpression is complex, multimodal and fine-grained. In this paper, we propose a\nnovel multimodal deep learning approach to perform fine-grained emotion\nrecognition from real-life speeches. We design a temporal alignment mean-max\npooling mechanism to capture the subtle and fine-grained emotions implied in\nevery utterance. In addition, we propose a cross modality excitement module to\nconduct sample-specific adjustment on cross modality embeddings and adaptively\nrecalibrate the corresponding values by its aligned latent features from the\nother modality. Our proposed model is evaluated on two well-known real-world\nspeech emotion recognition datasets. The results demonstrate that our approach\nis superior on the prediction tasks for multimodal speech utterances, and it\noutperforms a wide range of baselines in terms of prediction accuracy. Further\nmore, we conduct detailed ablation studies to show that our temporal alignment\nmean-max pooling mechanism and cross modality excitement significantly\ncontribute to the promising results. In order to encourage the research\nreproducibility, we make the code publicly available at\n\\url{https://github.com/tal-ai/FG_CME.git}.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:17:58 GMT"},{"version":"v2","created":"Thu, 15 Jul 2021 04:30:01 GMT"}],"update_date":"2021-07-16"}
{"id":"2010.12734","submitter":"Wenshao Zhong","authors":"Wenshao Zhong, Chen Chen, Xingbo Wu, Song Jiang","title":"REMIX: Efficient Range Query for LSM-trees","comments":"19th USENIX Conference on File and Storage Technologies","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  LSM-tree based key-value (KV) stores organize data in a multi-level structure\nfor high-speed writes. Range queries on traditional LSM-trees must seek and\nsort-merge data from multiple table files on the fly, which is expensive and\noften leads to mediocre read performance. To improve range query efficiency on\nLSM-trees, we introduce a space-efficient KV index data structure, named REMIX,\nthat records a globally sorted view of KV data spanning multiple table files. A\nrange query on multiple REMIX-indexed data files can quickly locate the target\nkey using a binary search, and retrieve subsequent keys in sorted order without\nkey comparisons. We build RemixDB, an LSM-tree based KV-store that adopts a\nwrite-efficient compaction strategy and employs REMIXes for fast point and\nrange queries. Experimental results show that REMIXes can substantially improve\nrange query performance in a write-optimized LSM-tree based KV-store.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:21:21 GMT"},{"version":"v2","created":"Mon, 25 Jan 2021 21:34:47 GMT"}],"update_date":"2021-01-27"}
{"id":"2010.12735","submitter":"Vladimir Rabinovich","authors":"Vladimir Rabinovich","title":"Boundary problems for three-dimensional Dirac operators and generalized\n  MIT bag models for unbounded domains","comments":"25 pages","journal-ref":null,"doi":"10.1134/S106192082004010X","report-no":null,"categories":"math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider operators of boundary value problems for 3D- Dirac operators in\nunbounded domains with the uniformly regular boundary. We give effective\nconditions of self-adjointness of operators under consideration and a\ndescription of their essential spectra. We also give applications to operators\nof the MIT bag problems for unbounded domains\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:28:26 GMT"}],"update_date":"2021-02-03"}
{"id":"2010.12736","submitter":"Khanh Nguyen Q","authors":"Khanh Q. Nguyen","title":"Conditional beta and uncertainty factor in the cryptocurrency pricing\n  model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This research is to assess cryptocurrencies with the conditional beta,\ncompared with prior studies based on unconditional beta or fixed beta. It is a\nnew approach to building a pricing model for cryptocurrencies. Therefore, we\nexpect that the use of conditional beta will increase the explanatory ability\nof factors in previous pricing models. Besides, this research is also a pioneer\nin placing the uncertainty factor in the cryptocurrency pricing model. Earlier\nstudies on cryptocurrency pricing have ignored this factor. However, it is a\nsignificant factor in the valuation of cryptocurrencies because uncertainty\nleads to investor sentiment and affects prices.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:31:43 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12737","submitter":"Ji Hyun Nam","authors":"Ji Hyun Nam, Eric Brandt, Sebastian Bauer, Xiaochun Liu, Eftychios\n  Sifakis, Andreas Velten","title":"Real-time Non-line-of-Sight imaging of dynamic scenes","comments":null,"journal-ref":"Nature Communications 12, 6526 (2021)","doi":"10.1038/s41467-021-26721-x","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-Line-of-Sight (NLOS) imaging aims at recovering the 3D geometry of\nobjects that are hidden from the direct line of sight. In the past, this method\nhas suffered from the weak available multibounce signal limiting scene size,\ncapture speed, and reconstruction quality. While algorithms capable of\nreconstructing scenes at several frames per second have been demonstrated,\nreal-time NLOS video has only been demonstrated for retro-reflective objects\nwhere the NLOS signal strength is enhanced by 4 orders of magnitude or more.\nFurthermore, it has also been noted that the signal-to-noise ratio of\nreconstructions in NLOS methods drops quickly with distance and past\nreconstructions, therefore, have been limited to small scenes with depths of\nfew meters. Actual models of noise and resolution in the scene have been\nsimplistic, ignoring many of the complexities of the problem. We show that SPAD\n(Single-Photon Avalanche Diode) array detectors with a total of just 28 pixels\ncombined with a specifically extended Phasor Field reconstruction algorithm can\nreconstruct live real-time videos of non-retro-reflective NLOS scenes. We\nprovide an analysis of the Signal-to-Noise-Ratio (SNR) of our reconstructions\nand show that for our method it is possible to reconstruct the scene such that\nSNR, motion blur, angular resolution, and depth resolution are all independent\nof scene size suggesting that reconstruction of very large scenes may be\npossible. In the future, the light efficiency for NLOS imaging systems can be\nimproved further by adding more pixels to the sensor array.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:40:06 GMT"}],"update_date":"2022-02-01"}
{"id":"2010.12738","submitter":"Xinwei Feng","authors":"Yue Zhou, Xinwei Feng, Jiongmin Yong","title":"Remarks on Viscosity Super-Solutions of Quasi-Variational Inequalities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For Hamilton-Jacobi-Bellman (HJB) equations, with the standard definitions of\nviscosity super-solution and sub-solution, it is known that there is a\ncomparison between any (viscosity) super-solutions and sub-solutions. This\nshould be the same for HJB type quasi-variational inequalities (QVIs) arising\nfrom optimal impulse control problems. However, according to a natural adoption\nof the definition found in Barles 1985, Barles 1985b, the uniqueness of the\nviscosity solution could be guaranteed, but the comparison between viscosity\nsuper- and sub-solutions could not be guaranteed. This paper introduces a\nmodification of the definition for the viscosity super-solution of HJB type\nQVIs so that the desired comparison theorem will hold.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:42:43 GMT"},{"version":"v2","created":"Fri, 5 Feb 2021 08:55:56 GMT"}],"update_date":"2021-02-08"}
{"id":"2010.12739","submitter":"Sumit Dahal","authors":"Sumit Dahal, Michael K. Brewer, John W. Appel, Aamir Ali, Charles L.\n  Bennett, Ricardo Bustos, Manwei Chan, David T. Chuss, Joseph Cleary,\n  Jullianna D. Couto, Rahul Datta, Kevin L. Denis, Joseph Eimer, Francisco\n  Espinoza, Thomas Essinger-Hileman, Dominik Gothe, Kathleen Harrington,\n  Jeffrey Iuliano, John Karakla, Tobias A. Marriage, Sasha Novack, Carolina\n  N\\'u\\~nez, Ivan L. Padilla, Lucas Parker, Matthew A. Petroff, Rodrigo Reeves,\n  Gary Rhoades, Karwan Rostem, Deniz A. N. Valle, Duncan J. Watts, Janet L.\n  Weiland, Edward J. Wollack, Zhilei Xu","title":"Venus Observations at 40 and 90 GHz with CLASS","comments":"7 pages, 3 figures, published in PSJ","journal-ref":"The Planetary Science Journal, 2:71 (6pp), 2021 April 12","doi":"10.3847/PSJ/abedad","report-no":null,"categories":"astro-ph.EP astro-ph.IM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using the Cosmology Large Angular Scale Surveyor, we measure the\ndisk-averaged absolute Venus brightness temperature to be 432.3 $\\pm$ 2.8 K and\n355.6 $\\pm$ 1.3 K in the Q and W frequency bands centered at 38.8 and 93.7 GHz,\nrespectively. At both frequency bands, these are the most precise measurements\nto date. Furthermore, we observe no phase dependence of the measured\ntemperature in either band. Our measurements are consistent with a\nCO$_2$-dominant atmospheric model that includes trace amounts of additional\nabsorbers like SO$_2$ and H$_2$SO$_4$.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:46:46 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 16:58:58 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12740","submitter":"Alejandro V.  Arzola","authors":"Brandon R. Ferrer, Juan Ruben Gomez-Solano, Alejandro V. Arzola","title":"Fluid viscoelasticity triggers fast transitions of a Brownian particle\n  in a double well optical potential","comments":"6 pages and four figures","journal-ref":"Phys. Rev. Lett. 126, 108001 (2021)","doi":"10.1103/PhysRevLett.126.108001","report-no":null,"categories":"cond-mat.soft physics.class-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Thermally activated transitions are ubiquitous in nature, occurring in\ncomplex environments which are typically conceived as ideal viscous fluids. We\nreport the first direct observations of a Brownian bead transiting between the\nwells of a bistable optical potential in a viscoelastic fluid with a single\nlong relaxation time. We precisely characterize both the potential and the\nfluid, thus enabling a neat comparison between our experimental results and a\ntheoretical model based on the generalized Langevin equation. Our findings\nreveal a drastic amplification of the transition rates compared to those in a\nNewtonian fluid, stemming from the relaxation of the fluid during the particle\ncrossing events.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:55:32 GMT"},{"version":"v2","created":"Tue, 16 Mar 2021 02:20:42 GMT"}],"update_date":"2021-03-17"}
{"id":"2010.12741","submitter":"Jo\\~ao Sedoc","authors":"Seolhwa Lee, Heuiseok Lim, Jo\\~ao Sedoc","title":"An Evaluation Protocol for Generative Conversational Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is a multitude of novel generative models for open-domain\nconversational systems; however, there is no systematic evaluation of different\nsystems. Systematic comparisons require consistency in experimental design,\nevaluation sets, conversational systems and their outputs, and statistical\nanalysis. We lay out a protocol for the evaluation of conversational models\nusing head-to-head pairwise comparison. We analyze ten recent models that claim\nstate-of-the-art performance using a paired head-to-head performance\n(win-loss-tie) on five evaluation datasets. Our findings show that DialoGPT and\nBlender are superior systems using Bradley-Terry model and TrueSkill ranking\nmethods. These findings demonstrate the feasibility of our protocol to evaluate\nconversational agents and evaluation sets. Finally, we make all code and\nevaluations publicly available for researchers to compare their model to other\nstate-of-the-art dialog models.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:59:49 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12742","submitter":"Zhiqiang Hu","authors":"Zhiqiang Hu, Roy Ka-Wei Lee, Charu C. Aggarwal, Aston Zhang","title":"Text Style Transfer: A Review and Experimental Evaluation","comments":"We fixed the issue that the references are not associated with any\n  [number] in the bibliography section","journal-ref":"KDD Explorations 24 (2022) 14-45","doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The stylistic properties of text have intrigued computational linguistics\nresearchers in recent years. Specifically, researchers have investigated the\nText Style Transfer (TST) task, which aims to change the stylistic properties\nof the text while retaining its style independent content. Over the last few\nyears, many novel TST algorithms have been developed, while the industry has\nleveraged these algorithms to enable exciting TST applications. The field of\nTST research has burgeoned because of this symbiosis. This article aims to\nprovide a comprehensive review of recent research efforts on text style\ntransfer. More concretely, we create a taxonomy to organize the TST models and\nprovide a comprehensive summary of the state of the art. We review the existing\nevaluation methodologies for TST tasks and conduct a large-scale\nreproducibility study where we experimentally benchmark 19 state-of-the-art TST\nalgorithms on two publicly available datasets. Finally, we expand on current\ntrends and provide new perspectives on the new and exciting developments in the\nTST field.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:02:58 GMT"},{"version":"v2","created":"Sun, 11 Apr 2021 14:48:37 GMT"},{"version":"v3","created":"Tue, 21 Jun 2022 10:57:48 GMT"},{"version":"v4","created":"Sun, 1 Jan 2023 20:24:47 GMT"}],"update_date":"2023-01-03"}
{"id":"2010.12743","submitter":"Conor Nixon","authors":"Conor A. Nixon, Alexander E. Thelen, Martin A. Cordiner, Zbigniew\n  Kisiel, Steven B. Charnley, Edward M. Molter, Joseph Serigano, Patrick G. J.\n  Irwin, Nicholas A. Teanby, Yi-Jehng Kuan","title":"Detection of Cyclopropenylidene on Titan with ALMA","comments":"34 pages, 13 figures. 8 tables","journal-ref":"The Astronomical Journal, 160:205 (17pp), 2020 November","doi":"10.3847/1538-3881/abb679","report-no":null,"categories":"astro-ph.EP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report the first detection on Titan of the small cyclic molecule\ncyclopropenylidene (c-C3H2) from high sensitivity spectroscopic observations\nmade with the Atacama Large Millimeter/sub-millimeter Array (ALMA). Multiple\nlines of cyclopropenylidene were detected in two separate datasets: ~251 GHz in\n2016 (Band 6) and ~352 GHz in 2017 (Band 7). Modeling of these emissions\nindicates abundances of 0.50 +/- 0.14 ppb (2016) and 0.28 +/- 0.08 (2017) for a\n350 km step model, which may either signify a decrease in abundance, or a mean\nvalue of 0.33 +/- 0.07 ppb. Inferred column abundances are (3-5)E12 cm-2 in\n2016 and (1-2)E12 cm-2 in 2017, similar to photochemical model predictions.\nPreviously the C3H3+ ion has been measured in Titan's ionosphere by Cassini's\nIon and Neutral Mass Spectrometer (INMS), but the neutral (unprotonated)\nspecies has not been detected until now, and aromatic versus aliphatic\nstructure could not be determined by the INMS. Our work therefore represents\nthe first unambiguous detection of cyclopropenylidene, the second known cyclic\nmolecule in Titan's atmosphere along with benzene (C6H6) and the first time\nthis molecule has been detected in a planetary atmosphere. We also searched for\nthe N-heterocycle molecules pyridine and pyrimidine finding non-detections in\nboth cases, and determining 2-{\\sigma} upper limits of 1.15 ppb (c-C5H5N) and\n0.85 ppb (c-C4H4N2) for uniform abundances above 300 km. These new results on\ncyclic molecules provide fresh constraints on photochemical pathways in Titan's\natmosphere, and will require new modeling and experimental work to fully\nunderstand the implications for complex molecule formation.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:11:58 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12744","submitter":"Diana Dragomir","authors":"Diana Dragomir, Ian J. M. Crossfield, Bjorn Benneke, Ian Wong, Tansu\n  Daylan, Matias Diaz, Drake Deming, Paul Molliere, Laura Kreidberg, James S.\n  Jenkins, David Berardo, Jessie L. Christiansen, Courtney D. Dressing,\n  Varoujan Gorjian, Stephen R. Kane, Thomas Mikal-Evans, Farisa Y. Morales,\n  Michael Werner, George R. Ricker, Roland Vanderspek, S. Seager, Joshua N.\n  Winn, Jon M. Jenkins, Knicole D. Colon, Willie Fong, Natalia Guerrero,\n  Katharine Hesse, Hugh P. Osborn Mark E. Rose, Jeffrey C. Smith, and Eric B.\n  Ting","title":"Spitzer Reveals Evidence of Molecular Absorption in the Atmosphere of\n  the Hot Neptune LTT 9979b","comments":"12 pages, 5 figures; accepted to ApJ Letters","journal-ref":null,"doi":"10.3847/2041-8213/abbc70","report-no":null,"categories":"astro-ph.EP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-rocky sub-jovian exoplanets in high irradiation environments are rare.\nLTT 9979b, also known as TESS Object of Interest (TOI) 193.01, is one of the\nfew such planets discovered to date, and the first example of an ultra-hot\nNeptune. The planet's bulk density indicates that it has a substantial\natmosphere, so to investigate its atmospheric composition and shed further\nlight on its origin, we obtained {\\it Spitzer} IRAC secondary eclipse\nobservations of LTT 9979b at 3.6 and 4.5 $\\mu$m. We combined the {\\it Spitzer}\nobservations with a measurement of the secondary eclipse in the {\\it TESS}\nbandpass. The resulting secondary eclipse spectrum strongly prefers a model\nthat includes CO absorption over a blackbody spectrum, incidentally making LTT\n9979b the first {\\it TESS} exoplanet (and the first ultra-hot Neptune) with\nevidence of a spectral feature in its atmosphere. We did not find evidence of a\nthermal inversion, at odds with expectations based on the atmospheres of\nsimilarly-irradiated hot Jupiters. We also report a nominal dayside brightness\ntemperature of 2305 $\\pm$ 141 K (based on the 3.6 $\\mu$m secondary eclipse\nmeasurement), and we constrained the planet's orbital eccentricity to $e <\n0.01$ at the 99.7 \\% confidence level. Together with our analysis of LTT\n9979b's thermal phase curves reported in a companion paper, our results set the\nstage for similar investigations of a larger sample of exoplanets discovered in\nthe hot Neptune desert, investigations which are key to uncovering the origin\nof this population.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:12:01 GMT"}],"update_date":"2020-11-11"}
{"id":"2010.12745","submitter":"Ian Crossfield","authors":"Ian J. M. Crossfield, Diana Dragomir, Nicolas B. Cowan, Tansu Daylan,\n  Ian Wong, Tiffany Kataria, Drake Deming, Laura Kreidberg, Thomas Mikal-Evans,\n  Varoujan Gorjian, James S. Jenkins, Bjoern Benneke, Karen A. Collins,\n  Christopher J. Burke, Christopher E. Henze, Scott McDermott, Ismael Mireles,\n  David Watanabe, Bill Wohler, George Ricker, Roland Vanderspek, Sara Seager,\n  Jon M. Jenkins","title":"Phase Curves of Hot Neptune LTT 9779b Suggest a High-Metallicity\n  Atmosphere","comments":"27 pages, 14 pages, 1 data table. ApJL in press. Companion paper to\n  Dragomir et al. 2020","journal-ref":null,"doi":"10.3847/2041-8213/abbc71","report-no":null,"categories":"astro-ph.EP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Phase curve measurements provide a global view of the composition, thermal\nstructure, and dynamics of exoplanet atmospheres. Although most of the dozens\nof phase curve measurements made to date are of large, massive hot Jupiters,\nthere is considerable interest in probing the atmospheres of the smaller\nplanets that are the more typical end product of planet formation. One such\nplanet is the ultra-hot Neptune LTT 9779b, a rare denizen of the Neptune\ndesert. A companion paper presents the planet's secondary eclipses and day-side\nthermal emission spectrum; in this work we describe the planet's optical and\ninfrared phase curves, characterized using Spitzer and TESS photometry. We\ndetect LTT 9779b's thermal phase variations at 4.5um, finding a phase amplitude\nof 358+/-106 ppm and a longitude of peak emission -10 deg +/- 21 deg east of\nthe substellar point. Combined with our secondary eclipse observations, these\nphase curve measurements imply a 4.5um day-side brightness temperature of\n1800+/-120 K, a night-side brightness temperature of 700+/-430 K (<1350 K at 2\nsigma confidence), and a day-night brightness temperature contrast of\n1110+/-460 K. We compare our data to the predictions of 3D GCMs and to similar\nobservations of hot Jupiters experiencing similar levels of stellar\nirradiation. Though not conclusive, our measurement of its small 4.5um phase\noffset, the relatively large amplitude of the phase variation, and the\nqualitative differences between our target's day-side emission spectrum and\nthose of hot Jupiters of similar temperatures all suggest a super-Solar\natmospheric metallicity for LTT 9779b, as might be expected given its size and\nmass. Finally, we provide a refined ephemeris (P=0.79207022+/-0.00000069 d,\nT0=2458783.51636+/-0.00027, BJD_TDB) to enable efficient scheduling of future\nobservations to further characterize the atmosphere of this intriguing planet.\n(abstract abridged)\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:12:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12746","submitter":"Dingwen Tao","authors":"Baodi Shan, Aabid Shamji, Jiannan Tian, Guanpeng Li, Dingwen Tao","title":"LCFI: A Fault Injection Tool for Studying Lossy Compression Error\n  Propagation in HPC Programs","comments":"8 pages, 6 figures, 2 tables, 8 listings, published by IWBDR workshop\n  at IEEE BigData' 20","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Error-bounded lossy compression is becoming more and more important to\ntoday's extreme-scale HPC applications because of the ever-increasing volume of\ndata generated because it has been widely used in in-situ visualization, data\nstream intensity reduction, storage reduction, I/O performance improvement,\ncheckpoint/restart acceleration, memory footprint reduction, etc. Although many\nworks have optimized ratio, quality, and performance for different\nerror-bounded lossy compressors, there is none of the existing works attempting\nto systematically understand the impact of lossy compression errors on HPC\napplication due to error propagation.\n  In this paper, we propose and develop a lossy compression fault injection\ntool, called LCFI. To the best of our knowledge, this is the first fault\ninjection tool that helps both lossy compressor developers and users to\nsystematically and comprehensively understand the impact of lossy compression\nerrors on HPC programs. The contributions of this work are threefold: (1) We\npropose an efficient approach to inject lossy compression errors according to a\nstatistical analysis of compression errors for different state-of-the-art\ncompressors. (2) We build a fault injector which is highly applicable,\ncustomizable, easy-to-use in generating top-down comprehensive results, and\ndemonstrate the use of LCFI. (3) We evaluate LCFI on four representative HPC\nbenchmarks with different abstracted fault models and make several observations\nabout error propagation and their impacts on program outputs.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:14:54 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 03:23:04 GMT"},{"version":"v3","created":"Sun, 1 Nov 2020 01:10:45 GMT"},{"version":"v4","created":"Sun, 22 Nov 2020 23:43:36 GMT"}],"update_date":"2020-11-24"}
{"id":"2010.12747","submitter":"Aydogan Ozcan","authors":"Deniz Mengu, Yair Rivenson, Aydogan Ozcan","title":"Scale-, shift- and rotation-invariant diffractive optical networks","comments":"28 Pages, 6 Figures, 1 Table","journal-ref":"ACS Photonics (2020)","doi":"10.1021/acsphotonics.0c01583","report-no":null,"categories":"physics.optics cs.NE physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research efforts in optical computing have gravitated towards\ndeveloping optical neural networks that aim to benefit from the processing\nspeed and parallelism of optics/photonics in machine learning applications.\nAmong these endeavors, Diffractive Deep Neural Networks (D2NNs) harness\nlight-matter interaction over a series of trainable surfaces, designed using\ndeep learning, to compute a desired statistical inference task as the light\nwaves propagate from the input plane to the output field-of-view. Although,\nearlier studies have demonstrated the generalization capability of diffractive\noptical networks to unseen data, achieving e.g., >98% image classification\naccuracy for handwritten digits, these previous designs are in general\nsensitive to the spatial scaling, translation and rotation of the input\nobjects. Here, we demonstrate a new training strategy for diffractive networks\nthat introduces input object translation, rotation and/or scaling during the\ntraining phase as uniformly distributed random variables to build resilience in\ntheir blind inference performance against such object transformations. This\ntraining strategy successfully guides the evolution of the diffractive optical\nnetwork design towards a solution that is scale-, shift- and\nrotation-invariant, which is especially important and useful for dynamic\nmachine vision applications in e.g., autonomous cars, in-vivo imaging of\nbiomedical specimen, among others.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:18:39 GMT"}],"update_date":"2020-12-25"}
{"id":"2010.12748","submitter":"Pengfei Li","authors":"Pengfei Li, Boris A. Malomed, and Dumitru Mihalache","title":"Metastable soliton necklaces supported by fractional diffraction and\n  competing nonlinearities","comments":"To be published in Optics Express","journal-ref":null,"doi":"10.1364/OE.409908","report-no":null,"categories":"nlin.PS physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate that fractional cubic-quintic nonlinear Schr\\\"odinger\nequation,characterized by its L\\'evy index, maintains ring-shaped soliton\nclusters (\"necklaces\") carrying orbital angular momentum. They can be built, in\nthe respective optical setting, as circular chains of fundamental solitons\nlinked by a vortical phase field. We predict semi-analytically that the\nmetastable necklace-shaped clusters persist, corresponding to a local minimum\nof an effective potential of interaction between adjacent solitons in the\ncluster. Systematic simulations corroborate that the clusters stay robust over\nextremely large propagation distances, even in the presence of strong random\nperturbations.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:38:26 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12749","submitter":"Kai Zhang","authors":"K.Zhang, Z.B.Zhang, Y.F.Huang, L.M.Song, S.J.Zheng, X.J.Li","title":"How are gamma-ray burst radio afterglows populated?","comments":"20 pages, 30 figures, submitted to MNRAS","journal-ref":"2021,MNRAS,503,3262-3278","doi":"10.1093/mnras/stab465","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We systematically analyze three GRB samples named as radio-loud, radio-quiet\nand radio-none afterglows, respectively. It is shown that dichotomy of the\nradio-loud afterglows is not necessary. Interestingly, we find that the\nintrinsic durations ($T_{int}$), isotropic energies of prompt gamma-rays\n($E_{\\gamma, iso}$) and redshifts ($z$) of their host galaxies are log-normally\ndistributed for both the radio-loud and radio-quiet samples except those GRBs\nwithout any radio detections. Based on the distinct distributions of $T_{int}$,\n$E_{\\gamma, iso}$, the circum-burst medium density ($n$) and the isotropic\nequivalent energy of radio afterglows ($L_{\\nu,p}$), we confirm that the GRB\nradio afterglows are really better to be divided into the dim and the bright\ntypes. However, it is noticeable that the distributions of flux densities\n($F_{host}$) from host galaxies of both classes of radio afterglows are\nintrinsically quite similar. Meanwhile, we point out that the radio-none sample\nis also obviously different from the above two samples with radio afterglows\nobserved, according to the cumulative frequency distributions of the $T_{int}$\nand the $E_{\\gamma, iso}$, together with correlations between $T_{int}$ and\n$z$. In addition, a positive correlation between $E_{\\gamma, iso}$ and\n$L_{\\nu,p}$ is found in the radio-loud samples especially for the\nsupernova-associated GRBs. Besides, we also find this positive correlation in\nthe radio-quiet sample. A negative correlation between $T_{int}$ and $z$ is\nconfirmed to hold for the radio-quiet sample too. The dividing line between\nshort and long GRBs in the rest frame is at $T_{int}\\simeq$1 s. Consequently,\nwe propose that the radio-loud, the radio-quiet and the radio-none GRBs could\nbe originated from different progenitors.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:43:37 GMT"}],"update_date":"2021-09-07"}
{"id":"2010.12750","submitter":"Kallol Paul","authors":"Pintu Bhunia and Kallol Paul","title":"Refinements of norm and numerical radius inequalities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Several refinements of norm and numerical radius inequalities of bounded\nlinear operators on a complex Hilbert space are given. In particular, we show\nthat if $A$ is a bounded linear operator on a complex Hilbert space, then $$\n\\frac{1}{4}\\|A^*A+AA^*\\| \\leq \\frac{1}{8}\\bigg( \\|A+A^*\\|^2+\\|A-A^*\\|^2\n+c^2(A+A^*)+c^2(A-A^*)\\bigg) \\leq w^2(A)$$ and \\begin{eqnarray*}\n  \\frac{1}{2}\\|A^*A+AA^*\\| - \\frac{1}{4}\\bigg\\|(A+A^*)^2 (A-A^*)^2\n\\bigg\\|^{1/2} \\leq w^2(A) \\leq \\frac{1}{2}\\|A^*A+AA^*\\|, \\end{eqnarray*} %$$\n\\frac{1}{4}\\|A^*A+AA^*\\| \\leq \\frac{1}{2}w^2(A) + \\frac{1}{8}\\bigg\\|(A+A^*)^2\n(A-A^*)^2 \\bigg\\|^{1/2}\\leq w^2(A),$$ where $\\|.\\|$, $w(.)$ and $c(.)$ are the\noperator norm, the numerical radius and the Crawford number, respectively.\nFurther, we prove that if $A,D$ are bounded linear operators on a complex\nHilbert space, then \\begin{eqnarray*} \\|AD^*\\| \\leq \\left\\| \\int_0^1 \\left(\n(1-t) \\left(\\frac{ |A|^2+|D|^2}{2}\\right) +t\\|AD^*\\|I \\right)^2dt\n\\right\\|^{1/2} \\leq \\frac{1}{2}\\left\\| |A|^2+|D|^2 \\right\\|, \\end{eqnarray*}\nwhere $|A|=(A^*A)^{1/2}$ and $|D|=(D^*D)^{1/2}$. This is a refinement of well\nknown inequality obtained by Bhatia and Kittaneh.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:59:58 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12751","submitter":"Bang Wu","authors":"Bang Wu, Xiangwen Yang, Shirui Pan, Xingliang Yuan","title":"Model Extraction Attacks on Graph Neural Networks: Taxonomy and\n  Realization","comments":"This paper has been published in the 17th ACM ASIA Conference on\n  Computer and Communications Security (ACM ASIACCS 2022)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning models are shown to face a severe threat from Model\nExtraction Attacks, where a well-trained private model owned by a service\nprovider can be stolen by an attacker pretending as a client. Unfortunately,\nprior works focus on the models trained over the Euclidean space, e.g., images\nand texts, while how to extract a GNN model that contains a graph structure and\nnode features is yet to be explored. In this paper, for the first time, we\ncomprehensively investigate and develop model extraction attacks against GNN\nmodels. We first systematically formalise the threat modelling in the context\nof GNN model extraction and classify the adversarial threats into seven\ncategories by considering different background knowledge of the attacker, e.g.,\nattributes and/or neighbour connections of the nodes obtained by the attacker.\nThen we present detailed methods which utilise the accessible knowledge in each\nthreat to implement the attacks. By evaluating over three real-world datasets,\nour attacks are shown to extract duplicated models effectively, i.e., 84% - 89%\nof the inputs in the target domain have the same output predictions as the\nvictim model.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:09:37 GMT"},{"version":"v2","created":"Tue, 30 Nov 2021 20:08:49 GMT"}],"update_date":"2021-12-02"}
{"id":"2010.12752","submitter":"Yanping Liu","authors":"Yanping Liu (1), Yang Jiao (2), Guoqiang Li (1), Gao Wang (1), Jingru\n  Yao (1), Guo Chen (1), Silong Lou (3), Jianwei Shuai (4), Liyu Liu (1) ((1)\n  Chongqing University, (2) Arizona State University, (3) Chongqing Cancer\n  Hospital, (4) Xiamen University)","title":"Deriving Time-varying Cellular Motility Parameters via Wavelet Analysis","comments":"19 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Cell migration is an indispensable physiological and pathological process for\nnormal tissue development and cancer metastasis, which is greatly regulated by\nintracellular signal pathways and extracellular microenvironment (ECM).\nHowever, there is a lack of adequate tools to analyze the time-varying cell\nmigration characteristics because of the effects of some factors, i.e., the ECM\nincluding the time-dependent local stiffness due to microstructural remodeling\nby migrating cells. Here, we develop an approach to derive the time-dependent\nmotility parameters from cellular trajectories, based on the time-varying\npersistent random walk model. In particular, we employ the wavelet denoising\nand wavelet transform to investigate cell migration velocities and obtain the\nwavelet power spectrum. The time-dependent motility parameters are subsequently\nderived via Lorentzian power spectrum. Our analysis shows that the combination\nof wavelet denoising, wavelet transform and Lorentzian power spectrum provides\na powerful tool to derive accurately the time-dependent motility parameters,\nwhich reflects the time-varying microenvironment characteristics to some\nextent.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:10:29 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12753","submitter":"Ben Zhou","authors":"Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish\n  Sabharwal and Dan Roth","title":"Temporal Reasoning on Implicit Events from Distant Supervision","comments":"Accepted at NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose TRACIE, a novel temporal reasoning dataset that evaluates the\ndegree to which systems understand implicit events -- events that are not\nmentioned explicitly in natural language text but can be inferred from it. This\nintroduces a new challenge in temporal reasoning research, where prior work has\nfocused on explicitly mentioned events. Human readers can infer implicit events\nvia commonsense reasoning, resulting in a more comprehensive understanding of\nthe situation and, consequently, better reasoning about time. We find, however,\nthat state-of-the-art models struggle when predicting temporal relationships\nbetween implicit and explicit events. To address this, we propose a\nneuro-symbolic temporal reasoning model, SYMTIME, which exploits distant\nsupervision signals from large-scale text and uses temporal rules to combine\nstart times and durations to infer end times. SYMTIME outperforms strong\nbaseline systems on TRACIE by 5%, and by 11% in a zero prior knowledge training\nsetting. Our approach also generalizes to other temporal reasoning tasks, as\nevidenced by a gain of 1%-9% on MATRES, an explicit event benchmark.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:12:27 GMT"},{"version":"v2","created":"Fri, 7 May 2021 21:07:45 GMT"}],"update_date":"2021-05-11"}
{"id":"2010.12754","submitter":"Justin Bui","authors":"Justin Bui and Robert J Marks II","title":"Autoencoder Watchdog Outlier Detection for Classifiers","comments":"7 pages, 12 figures","journal-ref":"In Proceedings of the 13th International Conference on Agents and\n  Artificial Intelligence - Volume 2: ICAART, ISBN 978-989-758-484-8, pages\n  990-996 (2021)","doi":"10.5220/0010300509900996","report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural networks have often been described as black boxes. A generic neural\nnetwork trained to differentiate between kittens and puppies will classify a\npicture of a kumquat as a kitten or a puppy. An autoencoder watch dog screens\ntrained classifier/regression machine input candidates before processing, e.g.\nto first test whether the neural network input is a puppy or a kitten.\nPreliminary results are presented using convolutional neural networks and\nconvolutional autoencoder watchdogs using MNIST images.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:16:33 GMT"},{"version":"v2","created":"Wed, 10 Feb 2021 16:51:00 GMT"}],"update_date":"2021-08-25"}
{"id":"2010.12755","submitter":"Xinyu Zhao","authors":"Xinyu Zhao, Shih-ting Lin, Greg Durrett","title":"Effective Distant Supervision for Temporal Relation Extraction","comments":null,"journal-ref":null,"doi":null,"report-no":"2021.adaptnlp-1.20","categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A principal barrier to training temporal relation extraction models in new\ndomains is the lack of varied, high quality examples and the challenge of\ncollecting more. We present a method of automatically collecting\ndistantly-supervised examples of temporal relations. We scrape and\nautomatically label event pairs where the temporal relations are made explicit\nin text, then mask out those explicit cues, forcing a model trained on this\ndata to learn other signals. We demonstrate that a pre-trained Transformer\nmodel is able to transfer from the weakly labeled examples to human-annotated\nbenchmarks in both zero-shot and few-shot settings, and that the masking scheme\nis important in improving generalization.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:17:31 GMT"},{"version":"v2","created":"Wed, 7 Apr 2021 00:56:48 GMT"}],"update_date":"2021-09-16"}
{"id":"2010.12756","submitter":"Hamid Reza Moradi","authors":"Hamid Reza Moradi and Mohammad Sababheh","title":"New Estimates for the Numerical Radius","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we present new inequalities for the numerical radius of the\nsum of two Hilbert space operators. These new inequalities will enable us to\nobtain many generalizations and refinements of some well known inequalities,\nincluding multiplicative behavior of the numerical radius and norm bounds.\n  Among many other applications, it is shown that if $T$ is\naccretive-dissipative, then \\[\\frac{1}{\\sqrt{2}}\\left\\| T \\right\\|\\le \\omega\n\\left( T \\right),\\] where $\\omega \\left( \\cdot \\right)$ and $\\left\\| \\cdot\n\\right\\|$ denote the numerical radius and the usual operator norm,\nrespectively. This inequality provides a considerable refinement of the well\nknown inequality $\\frac{1}{2}\\|T\\|\\leq \\omega(T).$\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:17:36 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12757","submitter":"Kai Sun","authors":"Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert,\n  Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, Claire Cardie","title":"Adding Chit-Chat to Enhance Task-Oriented Dialogues","comments":"To appear in NAACL-HLT 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing dialogue corpora and models are typically designed under two\ndisjoint motives: while task-oriented systems focus on achieving functional\ngoals (e.g., booking hotels), open-domain chatbots aim at making socially\nengaging conversations. In this work, we propose to integrate both types of\nsystems by Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR), with\nthe goal of making virtual assistant conversations more engaging and\ninteractive. Specifically, we propose a Human <-> AI collaborative data\ncollection approach for generating diverse chit-chat responses to augment\ntask-oriented dialogues with minimal annotation effort. We then present our new\nchit-chat-based annotations to 23.8K dialogues from two popular task-oriented\ndatasets (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their\nadvantage over the originals via human evaluation. Lastly, we propose three new\nmodels for adding chit-chat to task-oriented dialogues, explicitly trained to\npredict user goals and to generate contextually relevant chit-chat responses.\nAutomatic and human evaluations show that, compared with the state-of-the-art\ntask-oriented baseline, our models can code-switch between task and chit-chat\nto be more engaging, interesting, knowledgeable, and humanlike, while\nmaintaining competitive task performance.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:22:43 GMT"},{"version":"v2","created":"Sat, 1 May 2021 19:12:41 GMT"}],"update_date":"2021-05-04"}
{"id":"2010.12758","submitter":"Zhiyu Chen","authors":"Zhiyu Chen, Honglei Liu, Hu Xu, Seungwhan Moon, Hao Zhou, Bing Liu","title":"NUANCED: Natural Utterance Annotation for Nuanced Conversation with\n  Estimated Distributions","comments":"Findings of EMNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing conversational systems are mostly agent-centric, which assumes the\nuser utterances would closely follow the system ontology (for NLU or dialogue\nstate tracking). However, in real-world scenarios, it is highly desirable that\nthe users can speak freely in their own way. It is extremely hard, if not\nimpossible, for the users to adapt to the unknown system ontology. In this\nwork, we attempt to build a user-centric dialogue system. As there is no clean\nmapping for a user's free form utterance to an ontology, we first model the\nuser preferences as estimated distributions over the system ontology and map\nthe users' utterances to such distributions. Learning such a mapping poses new\nchallenges on reasoning over existing knowledge, ranging from factoid\nknowledge, commonsense knowledge to the users' own situations. To this end, we\nbuild a new dataset named NUANCED that focuses on such realistic settings for\nconversational recommendation. Collected via dialogue simulation and\nparaphrasing, NUANCED contains 5.1k dialogues, 26k turns of high-quality user\nresponses. We conduct experiments, showing both the usefulness and challenges\nof our problem setting. We believe NUANCED can serve as a valuable resource to\npush existing research from the agent-centric system to the user-centric\nsystem. The code and data is publicly available at\n\\url{https://github.com/facebookresearch/nuanced}.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:23:14 GMT"},{"version":"v2","created":"Thu, 9 Sep 2021 17:58:10 GMT"}],"update_date":"2021-09-10"}
{"id":"2010.12759","submitter":"Elham Izadi","authors":"Elham Izadi and Herbert Lange","title":"Symmetric correspondences with decomposable minimal equation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study symmetric correspondences with completely decomposable minimal\nequation on smooth projective curves $C$. The Jacobian of $C$ then decomposes\ncorrespondingly. For all positive integers $g$ and $\\ell$, we give series of\nexamples of smooth curves $C$ of genus $n^\\ell (g-1) +1$ with correspondences\nsatisfying minimal equations of degree $\\ell+1$ such that the Jacobian of $C$\nhas at least $2^\\ell$ isogeny components.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:29:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12760","submitter":"David Alvarez-Melis","authors":"David Alvarez-Melis and Nicol\\`o Fusi","title":"Dataset Dynamics via Gradient Flows in Probability Space","comments":"ICML 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Various machine learning tasks, from generative modeling to domain\nadaptation, revolve around the concept of dataset transformation and\nmanipulation. While various methods exist for transforming unlabeled datasets,\nprincipled methods to do so for labeled (e.g., classification) datasets are\nmissing. In this work, we propose a novel framework for dataset transformation,\nwhich we cast as optimization over data-generating joint probability\ndistributions. We approach this class of problems through Wasserstein gradient\nflows in probability space, and derive practical and efficient particle-based\nmethods for a flexible but well-behaved class of objective functions. Through\nvarious experiments, we show that this framework can be used to impose\nconstraints on classification datasets, adapt them for transfer learning, or to\nre-purpose fixed or black-box models to classify -- with high accuracy --\npreviously unseen datasets.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:29:22 GMT"},{"version":"v2","created":"Wed, 16 Jun 2021 16:33:12 GMT"}],"update_date":"2021-06-17"}
{"id":"2010.12761","submitter":"Deepak Pahwa","authors":"Deepak Pahwa, Umut Dur, Binil Starly","title":"Mechanism Design for Stable Matching with Contracts in a Dynamic\n  Manufacturing-as-a-Service (MaaS) Marketplace","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two-sided manufacturing-as-a-service (MaaS) marketplaces connect clients\nrequesting manufacturing services to suppliers providing those services.\nMatching mechanisms i.e. allocation of clients' orders to suppliers is a key\ndesign parameter of the marketplace platform. The platform might perform an\nallocation to maximize its revenue or optimize for social welfare of all\nparticipants. However, individual participants might not get maximum value from\ntheir match and reject it to form matches (called blocking groups) themselves,\nthereby bypassing the platform. This paper considers the bipartite matching\nproblem in MaaS marketplaces in a dynamic environment and proposes\napproximately stable matching solutions using mechanism design and mathematical\nprogramming approaches to limit the formation of blocking groups. Matching is\nbased on non-strict, incomplete and interdependent preferences of participants\nover contracts enabling negotiations between both sides. Empirical simulations\nare used to test the mechanisms in a simulated 3D printing marketplace and to\nevaluate the impact of stability on its performance. It is found that stable\nmatching results in small degradation in social welfare of the marketplace.\nHowever, it leads to a significantly better outcome in terms of stability of\nallocation. Unstable matchings introduce anarchy into marketplace with\nparticipants rejecting its allocation leading to performance poorer than stable\nmatchings.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:35:11 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12762","submitter":"Sarah Wiegreffe","authors":"Sarah Wiegreffe, Ana Marasovi\\'c, Noah A. Smith","title":"Measuring Association Between Labels and Free-Text Rationales","comments":"Revision to EMNLP 2021 camera-ready; corrects simulatability\n  terminology and clarifies computation of rationale quality metric (no results\n  changed). For a detailed explanation of changes, see\n  https://github.com/allenai/label_rationale_association","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In interpretable NLP, we require faithful rationales that reflect the model's\ndecision-making process for an explained instance. While prior work focuses on\nextractive rationales (a subset of the input words), we investigate their\nless-studied counterpart: free-text natural language rationales. We demonstrate\nthat pipelines, existing models for faithful extractive rationalization on\ninformation-extraction style tasks, do not extend as reliably to \"reasoning\"\ntasks requiring free-text rationales. We turn to models that jointly predict\nand rationalize, a class of widely used high-performance models for free-text\nrationalization whose faithfulness is not yet established. We define\nlabel-rationale association as a necessary property for faithfulness: the\ninternal mechanisms of the model producing the label and the rationale must be\nmeaningfully correlated. We propose two measurements to test this property:\nrobustness equivalence and feature importance agreement. We find that\nstate-of-the-art T5-based joint models exhibit both properties for\nrationalizing commonsense question-answering and natural language inference,\nindicating their potential for producing faithful free-text rationales.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:40:56 GMT"},{"version":"v2","created":"Mon, 15 Mar 2021 03:45:38 GMT"},{"version":"v3","created":"Fri, 10 Sep 2021 00:52:25 GMT"},{"version":"v4","created":"Mon, 29 Aug 2022 20:13:18 GMT"}],"update_date":"2022-08-31"}
{"id":"2010.12763","submitter":"Zhaowei Zhu","authors":"Zhaowei Zhu, Jingxuan Zhu, Ji Liu, Yang Liu","title":"Federated Bandit: A Gossiping Approach","comments":"Accepted by ACM SIGMETRICS 2021","journal-ref":"Proc. ACM Meas. Anal. Comput. Syst., Vol. 5, No. 1, Article 2.\n  Publication date: March 2021","doi":"10.1145/3447380","report-no":null,"categories":"cs.LG cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we study \\emph{Federated Bandit}, a decentralized Multi-Armed\nBandit problem with a set of $N$ agents, who can only communicate their local\ndata with neighbors described by a connected graph $G$. Each agent makes a\nsequence of decisions on selecting an arm from $M$ candidates, yet they only\nhave access to local and potentially biased feedback/evaluation of the true\nreward for each action taken. Learning only locally will lead agents to\nsub-optimal actions while converging to a no-regret strategy requires a\ncollection of distributed data. Motivated by the proposal of federated\nlearning, we aim for a solution with which agents will never share their local\nobservations with a central entity, and will be allowed to only share a private\ncopy of his/her own information with their neighbors. We first propose a\ndecentralized bandit algorithm Gossip_UCB, which is a coupling of variants of\nboth the classical gossiping algorithm and the celebrated Upper Confidence\nBound (UCB) bandit algorithm. We show that Gossip_UCB successfully adapts local\nbandit learning into a global gossiping process for sharing information among\nconnected agents, and achieves guaranteed regret at the order of $O(\\max\\{\n\\texttt{poly}(N,M) \\log T, \\texttt{poly}(N,M)\\log_{\\lambda_2^{-1}} N\\})$ for\nall $N$ agents, where $\\lambda_2\\in(0,1)$ is the second largest eigenvalue of\nthe expected gossip matrix, which is a function of $G$. We then propose\nFed_UCB, a differentially private version of Gossip_UCB, in which the agents\npreserve $\\epsilon$-differential privacy of their local data while achieving\n$O(\\max \\{\\frac{\\texttt{poly}(N,M)}{\\epsilon}\\log^{2.5} T, \\texttt{poly}(N,M)\n(\\log_{\\lambda_2^{-1}} N + \\log T) \\})$ regret.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:44:25 GMT"},{"version":"v2","created":"Wed, 7 Apr 2021 04:59:14 GMT"}],"update_date":"2021-04-08"}
{"id":"2010.12764","submitter":"Rodolfo Corona","authors":"Rodolfo Corona, Daniel Fried, Coline Devin, Dan Klein, Trevor Darrell","title":"Modular Networks for Compositional Instruction Following","comments":"Published in NAACL-2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Standard architectures used in instruction following often struggle on novel\ncompositions of subgoals (e.g. navigating to landmarks or picking up objects)\nobserved during training. We propose a modular architecture for following\nnatural language instructions that describe sequences of diverse subgoals. In\nour approach, subgoal modules each carry out natural language instructions for\na specific subgoal type. A sequence of modules to execute is chosen by learning\nto segment the instructions and predicting a subgoal type for each segment.\nWhen compared to standard, non-modular sequence-to-sequence approaches on\nALFRED, a challenging instruction following benchmark, we find that\nmodularization improves generalization to novel subgoal compositions, as well\nas to environments unseen in training.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:48:45 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 05:34:01 GMT"}],"update_date":"2021-04-14"}
{"id":"2010.12765","submitter":"William Hager","authors":"Jianchao Bai, William W. Hager, and Hongchao Zhang","title":"An Inexact Accelerated Stochastic ADMM for Separable Convex Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An inexact accelerated stochastic Alternating Direction Method of Multipliers\n(AS-ADMM) scheme is developed for solving structured separable convex\noptimization problems with linear constraints. The objective function is the\nsum of a possibly nonsmooth convex function and a smooth function which is an\naverage of many component convex functions. Problems having this structure\noften arise in machine learning and data mining applications. AS-ADMM combines\nthe ideas of both ADMM and the stochastic gradient methods using variance\nreduction techniques. One of the ADMM subproblems employs a linearization\ntechnique while a similar linearization could be introduced for the other\nsubproblem. For a specified choice of the algorithm parameters, it is shown\nthat the objective error and the constraint violation are $\\mathcal{O}(1/k)$\nrelative to the number of outer iterations $k$. Under a strong convexity\nassumption, the expected iterate error converges to zero linearly. A linearized\nvariant of AS-ADMM and incremental sampling strategies are also discussed.\nNumerical experiments with both stochastic and deterministic ADMM algorithms\nshow that AS-ADMM can be particularly effective for structured optimization\narising in big data applications.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:56:07 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12766","submitter":"Zining Zhang","authors":"Zining Zhang, Bingsheng He, Zhenjie Zhang","title":"X-TaSNet: Robust and Accurate Time-Domain Speaker Extraction Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Extracting the speech of a target speaker from mixed audios, based on a\nreference speech from the target speaker, is a challenging yet powerful\ntechnology in speech processing. Recent studies of speaker-independent speech\nseparation, such as TasNet, have shown promising results by applying deep\nneural networks over the time-domain waveform. Such separation neural network\ndoes not directly generate reliable and accurate output when target speakers\nare specified, because of the necessary prior on the number of speakers and the\nlack of robustness when dealing with audios with absent speakers. In this\npaper, we break these limitations by introducing a new speaker-aware speech\nmasking method, called X-TaSNet. Our proposal adopts new strategies, including\na distortion-based loss and corresponding alternating training scheme, to\nbetter address the robustness issue. X-TaSNet significantly enhances the\nextracted speech quality, doubling SDRi and SI-SNRi of the output speech audio\nover state-of-the-art voice filtering approach. X-TaSNet also improves the\nreliability of the results by improving the accuracy of speaker identity in the\noutput audio to 95.4%, such that it returns silent audios in most cases when\nthe target speaker is absent. These results demonstrate X-TaSNet moves one\nsolid step towards more practical applications of speaker extraction\ntechnology.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:57:19 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12767","submitter":"JiaZheng Sun","authors":"Jia-Zheng Sun","title":"Impurity in a Fermi gas under non-Hermitian spin-orbit coupling","comments":"5 pages, 5 figures","journal-ref":null,"doi":"10.1140/epjd/s10053-021-00049-z","report-no":null,"categories":"cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the fate of an impurity in a two-component, non-interacting Fermi\ngas under a non- Hermitian spin-orbit coupling (SOC) which is generated by\ndissipative Raman lasers. While SOC mixes the two spin species in the Fermi gas\nthus modifies the single-particle dispersions, we consider the case where the\nimpurity only interacts with one of the spin species. As a result, spectral\nproperties of the impurity constitute an ideal probe to the dissipative Fermi\ngas in the background. In particular, we show that dissipation destabilizes\npolarons in favor of molecular formation, consistent with previous few-body\nstudies. The dissipative nature of the Fermi gas further leads to broadened\npeaks in the inverse radio-frequency spectra for both the attractive and\nrepulsive polaron branches, which could serve as signals for experimental\nobservation. Our results provides an exemplary scenario where the interplay of\nnon-Hermiticity and interaction can be probed.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:02:42 GMT"}],"update_date":"2021-03-02"}
{"id":"2010.12768","submitter":"Mohamed Ibrahim Nouh","authors":"Yosry A. Azzam, Emad A.-B. Abdel-Salam and Mohamed I. Nouh","title":"Artificial Neural Network Modeling of the Conformable Fractional\n  Isothermal Gas Spheres","comments":"23 pages, 10 figures","journal-ref":null,"doi":"10.22201/ia.01851101p.2021.57.01.14","report-no":null,"categories":"astro-ph.GA astro-ph.IM astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The isothermal gas sphere is a particular type of Lane-Emden equation and is\nused widely to model many problems in astrophysics like stars, star clusters,\nand the formation of galaxies. In this paper, we present a computational scheme\nto simulate the conformable fractional isothermal gas sphere using an\nartificial neural network (ANN) technique and compare the obtained results with\nthe analytical solution deduced using the Taylor series. We performed our\ncalculations, trained the ANN, and tested it using a wide range of the\nfractional parameter. Besides the Emden functions, we calculated the\nmass-radius relations and the density profiles of the fractional isothermal gas\nspheres. The results obtained provided that ANN could perfectly simulate the\nconformable fractional isothermal gas spheres.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:05:23 GMT"}],"update_date":"2021-03-31"}
{"id":"2010.12769","submitter":"Pradyumna Chari","authors":"Pradyumna Chari, Krish Kabra, Doruk Karinca, Soumyarup Lahiri, Diplav\n  Srivastava, Kimaya Kulkarni, Tianyuan Chen, Maxime Cannesson, Laleh Jalilian\n  and Achuta Kadambi","title":"Diverse R-PPG: Camera-Based Heart Rate Estimation for Diverse Subject\n  Skin-Tones and Scenes","comments":"49 pages, 6 figures, 3 tables, Supplement with 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Heart rate (HR) is an essential clinical measure for the assessment of\ncardiorespiratory instability. Since communities of color are\ndisproportionately affected by both COVID-19 and cardiovascular disease, there\nis a pressing need to deploy contactless HR sensing solutions for high-quality\ntelemedicine evaluations. Existing computer vision methods that estimate HR\nfrom facial videos exhibit biased performance against dark skin tones. We\npresent a novel physics-driven algorithm that boosts performance on darker skin\ntones in our reported data. We assess the performance of our method through the\ncreation of the first telemedicine-focused remote vital signs dataset, the\nVITAL dataset. 432 videos (~864 minutes) of 54 subjects with diverse skin tones\nare recorded under realistic scene conditions with corresponding vital sign\ndata. Our method reduces errors due to lighting changes, shadows, and specular\nhighlights and imparts unbiased performance gains across skin tones, setting\nthe stage for making medically inclusive non-contact HR sensing technologies a\nviable reality for patients of all skin tones.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:10:30 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 09:09:27 GMT"},{"version":"v3","created":"Wed, 9 Dec 2020 06:23:32 GMT"}],"update_date":"2020-12-10"}
{"id":"2010.12770","submitter":"Jianpeng Cheng J","authors":"Jianpeng Cheng, Devang Agrawal, Hector Martinez Alonso, Shruti\n  Bhargava, Joris Driesen, Federico Flego, Shaona Ghosh, Dain Kaplan, Dimitri\n  Kartsaklis, Lin Li, Dhivya Piraviperumal, Jason D Williams, Hong Yu, Diarmuid\n  O Seaghdha, Anders Johannsen","title":"Conversational Semantic Parsing for Dialog State Tracking","comments":"Publish as a conference paper at EMNLP 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a new perspective on dialog state tracking (DST), the task of\nestimating a user's goal through the course of a dialog. By formulating DST as\na semantic parsing task over hierarchical representations, we can incorporate\nsemantic compositionality, cross-domain knowledge sharing and co-reference. We\npresent TreeDST, a dataset of 27k conversations annotated with tree-structured\ndialog states and system acts. We describe an encoder-decoder framework for DST\nwith hierarchical representations, which leads to 20% improvement over\nstate-of-the-art DST approaches that operate on a flat meaning space of\nslot-value pairs.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:10:32 GMT"},{"version":"v2","created":"Mon, 5 Apr 2021 04:33:00 GMT"},{"version":"v3","created":"Thu, 13 May 2021 18:02:43 GMT"}],"update_date":"2021-05-17"}
{"id":"2010.12771","submitter":"Yixin Liu","authors":"Yixin Liu, Graham Neubig, John Wieting","title":"On Learning Text Style Transfer with Direct Rewards","comments":"Published as a long paper at NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In most cases, the lack of parallel corpora makes it impossible to directly\ntrain supervised models for the text style transfer task. In this paper, we\nexplore training algorithms that instead optimize reward functions that\nexplicitly consider different aspects of the style-transferred outputs. In\nparticular, we leverage semantic similarity metrics originally used for\nfine-tuning neural machine translation models to explicitly assess the\npreservation of content between system outputs and input texts. We also\ninvestigate the potential weaknesses of the existing automatic metrics and\npropose efficient strategies of using these metrics for training. The\nexperimental results show that our model provides significant gains in both\nautomatic and human evaluation over strong baselines, indicating the\neffectiveness of our proposed methods and training strategies.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:30:02 GMT"},{"version":"v2","created":"Thu, 13 May 2021 15:00:38 GMT"}],"update_date":"2021-05-14"}
{"id":"2010.12772","submitter":"Mehran Rahmani","authors":"Mehran Rahmani, Asif Al Zubayer Swapnil, and Ivan Rulik","title":"New hybrid control of a 2 DoF Robot Arm","comments":"6 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Robot arms have been using in different systems, which the control of\ndesigned in desired trajectory is the main task. Also, it is anticipated that\nwhile in operation the developed 2DoF robot arm will be constantly encountered\nwith noises such as friction forces. A new integral sliding mode control\n(NISMC) is therefore being introduced to suppress noise due to its robustness.\nThen, New hybrid control system (NHISMC) is proposed, which constantly\ncalculates an error value and applies a correction value to the system. This\nwill enhance trajectory and minimize tracking error. In comparison with two\nother controllers, such as traditional sliding mode control (SMC) and NISMC,\nexperimental results confirmed the efficacy of the proposed control method.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:33:55 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12773","submitter":"Xiang Deng","authors":"Xiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr\n  Polozov, Huan Sun, Matthew Richardson","title":"Structure-Grounded Pretraining for Text-to-SQL","comments":"Accepted to NAACL 2021. The Spider-Realistic dataset is available at\n  https://doi.org/10.5281/zenodo.5205322","journal-ref":null,"doi":"10.18653/v1/2021.naacl-main.105","report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning to capture text-table alignment is essential for tasks like\ntext-to-SQL. A model needs to correctly recognize natural language references\nto columns and values and to ground them in the given database schema. In this\npaper, we present a novel weakly supervised Structure-Grounded pretraining\nframework (StruG) for text-to-SQL that can effectively learn to capture\ntext-table alignment based on a parallel text-table corpus. We identify a set\nof novel prediction tasks: column grounding, value grounding and column-value\nmapping, and leverage them to pretrain a text-table encoder. Additionally, to\nevaluate different methods under more realistic text-table alignment settings,\nwe create a new evaluation set Spider-Realistic based on Spider dev set with\nexplicit mentions of column names removed, and adopt eight existing text-to-SQL\ndatasets for cross-database evaluation. STRUG brings significant improvement\nover BERT-LARGE in all settings. Compared with existing pretraining methods\nsuch as GRAPPA, STRUG achieves similar performance on Spider, and outperforms\nall baselines on more realistic sets. The Spider-Realistic dataset is available\nat https://doi.org/10.5281/zenodo.5205322.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:35:35 GMT"},{"version":"v2","created":"Sun, 20 Jun 2021 21:12:39 GMT"},{"version":"v3","created":"Wed, 31 Aug 2022 00:19:41 GMT"}],"update_date":"2022-09-01"}
{"id":"2010.12774","submitter":"Mehran Rahmani","authors":"Mehran Rahmani","title":"New compound fractional sliding mode control and super-twisting control\n  of a MEMS gyroscope","comments":"6 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this research we propose a new compound Fractional Order Sliding Mode\nController (FOSMC) and SuperTwisting Controller (FOSMC+STC) to control of a\nMEMS gyroscope. A new sliding mode surface has been defined to design the\nproposed new sliding mode controller. The main advantages of a FOSMC is its\nhigh tracking performance and robustness against external perturbation, but it\nis susceptible to chattering. By augmenting a STC with a FOSMC, the chattering\nphenomenon is eliminated, singularity problem is solved and systems robustness\nhas significatnetly improved. Simulation results validate the effectiveness of\nthe proposed control approach.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:37:59 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12775","submitter":"Faxian Xiu","authors":"Ce Huang, Enze Zhang, Yong Zhang, Jinglei Zhang, Faxian Xiu, Haiwen\n  Liu, Xiaoyi Xie, Linfeng Ai, Yunkun Yang, Minhao Zhao, Junjie Qi, Lun Li,\n  Shanshan Liu, Zihan Li, Runze Zhan, Ya-Qing Bie, Xufeng Kou, Shaozhi Deng, X.\n  C. Xie","title":"The Discovery of Tunable Universality Class in Superconducting $\\beta$-W\n  Thin Films","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The interplay between quenched disorder and critical behavior in quantum\nphase transitions is conceptually fascinating and of fundamental importance for\nunderstanding phase transitions. However, it is still unclear whether or not\nthe quenched disorder influences the universality class of quantum phase\ntransitions. More crucially, the absence of superconducting-metal transitions\nunder in-plane magnetic fields in 2D superconductors imposes constraints on the\nuniversality of quantum criticality. Here, we discover the tunable universality\nclass of superconductor-metal transition by changing the disorder strength in\n$\\beta$-W films with varying thickness. The finite-size scaling uncovers the\nswitch of universality class: quantum Griffiths singularity to multiple quantum\ncriticality at a critical thickness of $t_{c \\perp 1}\\sim 8 nm$ and then from\nmultiple quantum criticality to single criticality at $t_{c\\perp 2}\\sim 16 nm$.\nMoreover, the superconducting-metal transition is observed for the first time\nunder in-plane magnetic fields and the universality class is changed at $t_{c\n\\parallel }\\sim 8 nm$. The discovery of tunable universality class under both\nout-of-plane and in-plane magnetic fields provides broad information for the\ndisorder effect on superconducting-metal transitions and quantum criticality.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:41:17 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12776","submitter":"Yanda Chen","authors":"Yanda Chen (1), Md Arafat Sultan (2), Vittorio Castelli (2) ((1)\n  Department of Computer Science, Columbia University, (2) IBM Research AI,\n  T.J. Watson Research Center, New York, USA)","title":"Improved Synthetic Training for Reading Comprehension","comments":"11 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Automatically generated synthetic training examples have been shown to\nimprove performance in machine reading comprehension (MRC). Compared to human\nannotated gold standard data, synthetic training data has unique properties,\nsuch as high availability at the possible expense of quality. In view of such\ndifferences, in this paper, we explore novel applications of synthetic examples\nto MRC. Our proposed pre-training and knowledge distillation strategies show\nsignificant improvements over existing methods. In a particularly surprising\ndiscovery, we observe that synthetic distillation often yields students that\ncan outperform the teacher model.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:41:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12777","submitter":"Hyung Won Chung","authors":"Hyung Won Chung, Dan Garrette, Kiat Chuan Tan, Jason Riesa","title":"Improving Multilingual Models with Language-Clustered Vocabularies","comments":"Published in the main conference of EMNLP 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  State-of-the-art multilingual models depend on vocabularies that cover all of\nthe languages the model will expect to see at inference time, but the standard\nmethods for generating those vocabularies are not ideal for massively\nmultilingual applications. In this work, we introduce a novel procedure for\nmultilingual vocabulary generation that combines the separately trained\nvocabularies of several automatically derived language clusters, thus balancing\nthe trade-off between cross-lingual subword sharing and language-specific\nvocabularies. Our experiments show improvements across languages on key\nmultilingual benchmark tasks TyDi QA (+2.9 F1), XNLI (+2.1\\%), and WikiAnn NER\n(+2.8 F1) and factor of 8 reduction in out-of-vocabulary rate, all without\nincreasing the size of the model or data.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:49:15 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12778","submitter":"Mehran Rahmani","authors":"Mehran Rahmani and Asif Al Zubayer Swapnil","title":"New compound control algorithm in sliding mode control to reduce the\n  chattering phenomenon: experimental validation","comments":"17 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, a new SMS is proposed to achieve high tracking and suitable\nrobustness. However, the chattering phenomenon should be regarded as the main\ndrawback of the SMC. Therefore, a new compound control algorithm is used for\nreducing the chattering phenomenon. The applied compound control law constantly\nevaluates the error and send the correct value to the system. This\nsignificantly will reduce the chattering phenomenon. The performance of the\ncontrol methods validated by applying on a robot arm experimentally.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:51:30 GMT"},{"version":"v2","created":"Sat, 12 Dec 2020 03:25:48 GMT"}],"update_date":"2020-12-15"}
{"id":"2010.12779","submitter":"Aida Mostafazadeh Davani","authors":"Aida Mostafazadeh Davani, Ali Omrani, Brendan Kennedy, Mohammad Atari,\n  Xiang Ren, Morteza Dehghani","title":"Fair Hate Speech Detection through Evaluation of Social Group\n  Counterfactuals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Approaches for mitigating bias in supervised models are designed to reduce\nmodels' dependence on specific sensitive features of the input data, e.g.,\nmentioned social groups. However, in the case of hate speech detection, it is\nnot always desirable to equalize the effects of social groups because of their\nessential role in distinguishing outgroup-derogatory hate, such that particular\ntypes of hateful rhetoric carry the intended meaning only when contextualized\naround certain social group tokens. Counterfactual token fairness for a\nmentioned social group evaluates the model's predictions as to whether they are\nthe same for (a) the actual sentence and (b) a counterfactual instance, which\nis generated by changing the mentioned social group in the sentence. Our\napproach assures robust model predictions for counterfactuals that imply\nsimilar meaning as the actual sentence. To quantify the similarity of a\nsentence and its counterfactual, we compare their likelihood score calculated\nby generative language models. By equalizing model behaviors on each sentence\nand its counterfactuals, we mitigate bias in the proposed model while\npreserving the overall classification performance.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:51:47 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12780","submitter":"Yan Zeng","authors":"Yan Zeng and Jian-Yun Nie","title":"Open-Domain Dialogue Generation Based on Pre-trained Language Models","comments":"[v0], 10 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained language models have been successfully used in response\ngeneration for open-domain dialogue. Four main frameworks have been proposed:\n(1) Transformer-ED using Transformer encoder and decoder separately for source\nand target sentences; (2) Transformer-Dec using Transformer decoder for both\nsource and target sentences; (3) Transformer-MLM using Transformer decoder that\napplies bi-directional attention on the source side and left-to-right attention\non the target side with masked language model objective; and (4) Transformer-AR\nthat uses auto-regressive objective instead. In this study, we compare these\nframeworks on 3 datasets, and our comparison reveals that the best framework\nuses bidirectional attention on the source side and does not separate encoder\nand decoder. We also examine model discrepancy, and our experiments confirm\nthat the performance of a model is directly impacted by the underlying\ndiscrepancies. We then propose two correction methods to reduce the\ndiscrepancies, and both improve the model performance. These results show that\ndiscrepancies is an important factor to consider when we use a pre-trained\nmodel, and a reduction in discrepancies can lead to improved performance.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:52:28 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12781","submitter":"Hongping Wang","authors":"Hongping Wang, Zhaobin Li, Xinlei Zhang, Lixing Zhu, Yi Liu, Shizhao\n  Wang","title":"The motion of respiratory droplets produced by coughing","comments":"27 pages, 15 figures, COVID-19, article","journal-ref":null,"doi":"10.1063/5.0033849","report-no":null,"categories":"physics.flu-dyn physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coronavirus disease 2019 (COVID-19) has become a global pandemic infectious\nrespiratory disease with high mortality and infectiousness. This paper\ninvestigates respiratory droplet transmission, which is critical to\nunderstanding, modeling and controlling epidemics. In the present work, we\nimplemented flow visualization, particle image velocimetry (PIV) and particle\nshadow tracking velocimetry (PSTV) to measure the velocity of the airflow and\ndroplets involved in coughing and then constructed a physical model considering\nthe evaporation effect to predict the motion of droplets under different\nweather conditions. The experimental results indicate that the convection\nvelocity of cough airflow presents the relationship $t^{-0.7}$ with time;\nhence, the distance from the cougher increases by $t^{0.3}$ in the range of our\nmeasurement domain. Substituting these experimental results into the physical\nmodel reveals that the small droplets (initial diameter $D \\leq$ 100 $\\mu$m)\nevaporate to droplet nuclei and that the large droplets with $D \\geq$ 500\n$\\mu$m and initial velocity $u_0 \\geq$ 5 m/s travel more than 2 m. Winter\nconditions of low temperature and high relative humidity can cause more\ndroplets to settle to the ground, which may be a possible driver of a second\npandemic wave in the autumn and winter seasons.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:53:32 GMT"}],"update_date":"2021-02-03"}
{"id":"2010.12782","submitter":"Annalisa Conversano","authors":"Annalisa Conversano","title":"Groups definable in o-minimal structures: various properties and a\n  diagram","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a diagram surveying equivalence or strict implication for\nproperties of different nature (algebraic, model theoretic, topological, etc.)\nabout groups definable in o-minimal structures. All results are well-known and\nan extensive bibliography is provided.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:55:13 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 04:59:08 GMT"}],"update_date":"2020-10-29"}
{"id":"2010.12783","submitter":"Xujiang Zhao","authors":"Xujiang Zhao, Feng Chen, Shu Hu, Jin-Hee Cho","title":"Uncertainty Aware Semi-Supervised Learning on Graph Data","comments":"NeurIPS 2020 (Spotlight)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Thanks to graph neural networks (GNNs), semi-supervised node classification\nhas shown the state-of-the-art performance in graph data. However, GNNs have\nnot considered different types of uncertainties associated with class\nprobabilities to minimize risk of increasing misclassification under\nuncertainty in real life. In this work, we propose a multi-source uncertainty\nframework using a GNN that reflects various types of predictive uncertainties\nin both deep learning and belief/evidence theory domains for node\nclassification predictions. By collecting evidence from the given labels of\ntraining nodes, the Graph-based Kernel Dirichlet distribution Estimation (GKDE)\nmethod is designed for accurately predicting node-level Dirichlet distributions\nand detecting out-of-distribution (OOD) nodes. We validated the outperformance\nof our proposed model compared to the state-of-the-art counterparts in terms of\nmisclassification detection and OOD detection based on six real network\ndatasets. We found that dissonance-based detection yielded the best results on\nmisclassification detection while vacuity-based detection was the best for OOD\ndetection. To clarify the reasons behind the results, we provided the\ntheoretical proof that explains the relationships between different types of\nuncertainties considered in this work.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:56:46 GMT"},{"version":"v2","created":"Tue, 24 Nov 2020 23:21:58 GMT"}],"update_date":"2020-11-26"}
{"id":"2010.12784","submitter":"Vikram Gupta","authors":"Vikram Gupta, Haoyue Shi, Kevin Gimpel, Mrinmaya Sachan","title":"Deep Clustering of Text Representations for Supervision-free Probing of\n  Syntax","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We explore deep clustering of text representations for unsupervised model\ninterpretation and induction of syntax. As these representations are\nhigh-dimensional, out-of-the-box methods like KMeans do not work well. Thus,\nour approach jointly transforms the representations into a lower-dimensional\ncluster-friendly space and clusters them. We consider two notions of syntax:\nPart of speech Induction (POSI) and constituency labelling (CoLab) in this\nwork. Interestingly, we find that Multilingual BERT (mBERT) contains surprising\namount of syntactic knowledge of English; possibly even as much as English BERT\n(EBERT). Our model can be used as a supervision-free probe which is arguably a\nless-biased way of probing. We find that unsupervised probes show benefits from\nhigher layers as compared to supervised probes. We further note that our\nunsupervised probe utilizes EBERT and mBERT representations differently,\nespecially for POSI. We validate the efficacy of our probe by demonstrating its\ncapabilities as an unsupervised syntax induction technique. Our probe works\nwell for both syntactic formalisms by simply adapting the input\nrepresentations. We report competitive performance of our probe on 45-tag\nEnglish POSI, state-of-the-art performance on 12-tag POSI across 10 languages,\nand competitive results on CoLab. We also perform zero-shot syntax induction on\nresource impoverished languages and report strong results.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:06:29 GMT"},{"version":"v2","created":"Wed, 1 Dec 2021 23:18:05 GMT"}],"update_date":"2021-12-03"}
{"id":"2010.12785","submitter":"Haoran You","authors":"Haoran You, Xiaohan Chen, Yongan Zhang, Chaojian Li, Sicheng Li, Zihao\n  Liu, Zhangyang Wang, Yingyan Lin","title":"ShiftAddNet: A Hardware-Inspired Deep Network","comments":"Accepted by NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multiplication (e.g., convolution) is arguably a cornerstone of modern deep\nneural networks (DNNs). However, intensive multiplications cause expensive\nresource costs that challenge DNNs' deployment on resource-constrained edge\ndevices, driving several attempts for multiplication-less deep networks. This\npaper presented ShiftAddNet, whose main inspiration is drawn from a common\npractice in energy-efficient hardware implementation, that is, multiplication\ncan be instead performed with additions and logical bit-shifts. We leverage\nthis idea to explicitly parameterize deep networks in this way, yielding a new\ntype of deep network that involves only bit-shift and additive weight layers.\nThis hardware-inspired ShiftAddNet immediately leads to both energy-efficient\ninference and training, without compromising the expressive capacity compared\nto standard DNNs. The two complementary operation types (bit-shift and add)\nadditionally enable finer-grained control of the model's learning capacity,\nleading to more flexible trade-off between accuracy and (training) efficiency,\nas well as improved robustness to quantization and pruning. We conduct\nextensive experiments and ablation studies, all backed up by our FPGA-based\nShiftAddNet implementation and energy measurements. Compared to existing DNNs\nor other multiplication-less models, ShiftAddNet aggressively reduces over 80%\nhardware-quantified energy cost of DNNs training and inference, while offering\ncomparable or better accuracies. Codes and pre-trained models are available at\nhttps://github.com/RICE-EIC/ShiftAddNet.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:09:14 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12786","submitter":"Huda Khayrallah","authors":"Huda Khayrallah, Jo\\~ao Sedoc","title":"Measuring the `I don't know' Problem through the Lens of Gricean\n  Quantity","comments":"to appear at NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the intrinsic evaluation of neural generative dialog models\nthrough the lens of Grice's Maxims of Conversation (1975). Based on the maxim\nof Quantity (be informative), we propose Relative Utterance Quantity (RUQ) to\ndiagnose the `I don't know' problem, in which a dialog system produces generic\nresponses. The linguistically motivated RUQ diagnostic compares the model score\nof a generic response to that of the reference response. We find that for\nreasonable baseline models, `I don't know' is preferred over the reference the\nmajority of the time, but this can be reduced to less than 5% with\nhyperparameter tuning. RUQ allows for the direct analysis of the `I don't know'\nproblem, which has been addressed but not analyzed by prior work.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:16:36 GMT"},{"version":"v2","created":"Wed, 21 Apr 2021 18:55:37 GMT"}],"update_date":"2021-04-23"}
{"id":"2010.12787","submitter":"Kung-Hsiang Huang","authors":"Kung-Hsiang Huang, Nanyun Peng","title":"Document-level Event Extraction with Efficient End-to-end Learning of\n  Cross-event Dependencies","comments":"To appear at NAACL 2021 WNU workshop","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fully understanding narratives often requires identifying events in the\ncontext of whole documents and modeling the event relations. However,\ndocument-level event extraction is a challenging task as it requires the\nextraction of event and entity coreference, and capturing arguments that span\nacross different sentences. Existing works on event extraction usually confine\non extracting events from single sentences, which fail to capture the\nrelationships between the event mentions at the scale of a document, as well as\nthe event arguments that appear in a different sentence than the event trigger.\nIn this paper, we propose an end-to-end model leveraging Deep Value Networks\n(DVN), a structured prediction algorithm, to efficiently capture cross-event\ndependencies for document-level event extraction. Experimental results show\nthat our approach achieves comparable performance to CRF-based models on ACE05,\nwhile enjoys significantly higher computational efficiency.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:28:16 GMT"},{"version":"v2","created":"Fri, 23 Apr 2021 19:58:32 GMT"},{"version":"v3","created":"Fri, 7 May 2021 22:47:09 GMT"}],"update_date":"2021-05-11"}
{"id":"2010.12788","submitter":"Zining Zhang","authors":"Zining Zhang, Bingsheng He, Zhenjie Zhang","title":"GAZEV: GAN-Based Zero-Shot Voice Conversion over Non-parallel Speech\n  Corpus","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-parallel many-to-many voice conversion is recently attract-ing huge\nresearch efforts in the speech processing community. A voice conversion system\ntransforms an utterance of a source speaker to another utterance of a target\nspeaker by keeping the content in the original utterance and replacing by the\nvocal features from the target speaker. Existing solutions, e.g., StarGAN-VC2,\npresent promising results, only when speech corpus of the engaged speakers is\navailable during model training. AUTOVCis able to perform voice conversion on\nunseen speakers, but it needs an external pretrained speaker verification\nmodel. In this paper, we present our new GAN-based zero-shot voice conversion\nsolution, called GAZEV, which targets to support unseen speakers on both source\nand target utterances. Our key technical contribution is the adoption of\nspeaker embedding loss on top of the GAN framework, as well as adaptive\ninstance normalization strategy, in order to address the limitations of speaker\nidentity transfer in existing solutions. Our empirical evaluations demonstrate\nsignificant performance improvement on output speech quality and comparable\nspeaker similarity to AUTOVC.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:31:15 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12789","submitter":"Limin Zhang","authors":"Limin Zhang","title":"New Approaches for Natural Language Understanding based on the Idea that\n  Natural Language encodes both Information and its Processing Procedures","comments":"15 pages, 9 figures, 13 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We must recognize that natural language is a way of information encoding, and\nit encodes not only the information but also the procedures for how information\nis processed. To understand natural language, the same as we conceive and\ndesign computer languages, the first step is to separate information (or data)\nand the processing procedures of information (or data). In natural language,\nsome processing procedures of data are encoded directly as the structure chunk\nand the pointer chunk (this paper has reclassified lexical chunks as the data\nchunk, structure chunk, and the pointer chunk); some processing procedures of\ndata imply in sentences structures; some requests of processing procedures are\nexpressed by information senders and processed by information receivers. For\nthe data parts, the classification encoding system of attribute information and\nthe information organization architecture (including constitutional structures\nof information sets and the hierarchy between the information sets) were\ndiscussed. In section 2, the theoretical part elaborated in section 2 has been\nverified in examples and proofed that the studies in this paper have achieved\nthe goal of enabling machines to understand the information conveyed in the\ndialogue. In section 4, the author summarizes the basic conditions of\n\"Understanding\", rethinks what \"Understanding\" is and how to proceed. The study\nin this paper provides a practical, theoretical basis and research methods for\nNLU. It also can be applied in large-scale and multi-type information\nprocessing in the artificial intelligence (AI) area.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:40:47 GMT"},{"version":"v2","created":"Tue, 3 Nov 2020 16:45:38 GMT"},{"version":"v3","created":"Tue, 12 Jan 2021 16:50:32 GMT"}],"update_date":"2021-01-13"}
{"id":"2010.12790","submitter":"Morgan Blaine Fox","authors":"Morgan B. Fox (1), Andrew S. Voyles (1 and 2), Jonathan T. Morrell\n  (1), Lee A. Bernstein (1 and 2), Amanda M. Lewis (1), Arjan J. Koning (3),\n  Jon C. Batchelder (1), Eva R. Birnbaum (4), Cathy S. Cutler (5), Dmitri G.\n  Medvedev (5), Francois M. Nortier (4), Ellen M. O'Brien (4), Christiaan\n  Vermeulen (4) ((1) Department of Nuclear Engineering, University of\n  California, Berkeley (2) Lawrence Berkeley National Laboratory (3)\n  International Atomic Energy Agency (4) Los Alamos National Laboratory (5)\n  Brookhaven National Laboratory)","title":"Investigating High-Energy Proton-Induced Reactions on Spherical Nuclei:\n  Implications for the Pre-Equilibrium Exciton Model","comments":"37 pages, 62 figures. Revised version, published in Physical Review C","journal-ref":"Phys. Rev. C, vol. 103, no. 3, p. 034601, 2021","doi":"10.1103/PhysRevC.103.034601","report-no":null,"categories":"nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A number of accelerator-based isotope production facilities utilize 100- to\n200-MeV proton beams due to the high production rates enabled by high-intensity\nbeam capabilities and the greater diversity of isotope production brought on by\nthe long range of high-energy protons. However, nuclear reaction modeling at\nthese energies can be challenging because of the interplay between different\nreaction modes and a lack of existing guiding cross section data. A Tri-lab\ncollaboration has been formed among the Lawrence Berkeley, Los Alamos, and\nBrookhaven National Laboratories to address these complexities by\ncharacterizing charged-particle nuclear reactions relevant to the production of\nestablished and novel radioisotopes. In the inaugural collaboration\nexperiments, stacked-targets of niobium foils were irradiated at the Brookhaven\nLinac Isotope Producer (E$_p$=200 MeV) and the Los Alamos Isotope Production\nFacility (E$_p$=100 MeV) to measure $^{93}$Nb(p,x) cross sections between 50\nand 200 MeV. The measured cross-section results were compared with literature\ndata as well as the default calculations of the nuclear model codes TALYS, CoH,\nEMPIRE, and ALICE. We developed a standardized procedure that determines the\nreaction model parameters that best reproduce the most prominent reaction\nchannels in a physically justifiable manner. The primary focus of the procedure\nwas to determine the best parametrization for the pre-equilibrium two-component\nexciton model. This modeling study revealed a trend toward a relative decrease\nfor internal transition rates at intermediate proton energies (E$_p$=20-60 MeV)\nin the current exciton model as compared to the default values. The results of\nthis work are instrumental for the planning, execution, and analysis essential\nto isotope production.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:42:06 GMT"},{"version":"v2","created":"Mon, 5 Apr 2021 09:12:57 GMT"}],"update_date":"2021-04-06"}
{"id":"2010.12791","submitter":"Amirreza Silani","authors":"Amirreza Silani, Michele Cucuzzella, Jacquelien M. A. Scherpen,\n  Mohammad Javad Yazdanpanah","title":"Passivity properties for regulation of DC networks with stochastic load\n  demand","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we present new (stochastic) passivity properties for Direct\nCurrent (DC) power networks, where the unknown and unpredictable load demand is\nmodelled by a stochastic process. More precisely, the considered power network\nconsists of distributed generation units supplying ZIP loads, i.e., nonlinear\nloads comprised of impedance (Z), current (I) and power (P) components.\nDifferently from the majority of the results in the literature, where each of\nthese components is assumed to be constant, we consider time-varying loads\nwhose dynamics are described by a class of stochastic differential equations.\nFinally, we prove that an existing distributed control scheme achieving current\nsharing and (average) voltage regulation ensures the asymptotic stochastic\nstability of the controlled network.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:51:10 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12792","submitter":"Xiaolong Li","authors":"Xiaolong Li and Kui Wang","title":"Lower bounds for the first eigenvalue of the Laplacian on K\\\"ahler\n  manifolds","comments":"Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG math.AP math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We establish lower bound for the first nonzero eigenvalue of the Laplacian on\na closed K\\\"ahler manifold in terms of dimension, diameter, and lower bounds of\nholomorphic sectional curvature and orthogonal Ricci curvature. On compact\nK\\\"ahler manifolds with boundary, we prove lower bounds for the first nonzero\nNeumann or Dirichlet eigenvalue in terms of geometric data. Our results are\nK\\\"ahler analogues of well-known results for Riemannian manifolds.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:59:34 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12793","submitter":"Adam Garnsworthy","authors":"F. H. Garcia, C. Andreoiu, G. C. Ball, A. Bell, A. B. Garnsworthy, F.\n  Nowacki, C. M. Petrache, A. Poves, K. Whitmore, F. A. Ali, N. Bernier, S. S.\n  Bhattacharjee, M. Bowry, R. J. Coleman, I. Dillmann, I. Djianto, A. M.\n  Forney, M. Gascoine, G. Hackman, K. G. Leach, A. N. Murphy, C. R. Natzke, B.\n  Olaizola, K. Ortner, E. E. Peters, M. M. Rajabali, K. Raymond, C. E.\n  Svensson, R. Umashankar, J. Williams, D. Yates","title":"Absence of Low-Energy Shape Coexistence in $^{80}$Ge: The Nonobservation\n  of a Proposed Excited 0$_2^+$ Level at 639 keV","comments":null,"journal-ref":"Phys. Rev. Lett. 125, 172501 (2020)","doi":"10.1103/PhysRevLett.125.172501","report-no":null,"categories":"nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The $^{80}$Ge structure was investigated in a high-statistics $\\beta$-decay\nexperiment of $^{80}$Ga using the GRIFFIN spectrometer at TRIUMF-ISAC through\n$\\gamma$, $\\beta$-$e$, $e$-$\\gamma$ and $\\gamma$-$\\gamma$ spectroscopy. No\nevidence was found for the recently reported 0$_2^{+}$ 639-keV level suggested\nas evidence for low-energy shape coexistence in $^{80}$Ge. Large-scale shell\nmodel calculations performed in $^{78,80,82}$Ge place the $0^{+}_{2}$ level in\n$^{80}$Ge at 2\\,MeV. The new experimental evidence combined with shell model\npredictions indicate that low-energy shape coexistence is not present in\n$^{80}$Ge.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:07:43 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12794","submitter":"Zihan Wang","authors":"Zihan Wang and Dheeraj Mekala and Jingbo Shang","title":"X-Class: Text Classification with Extremely Weak Supervision","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we explore text classification with extremely weak\nsupervision, i.e., only relying on the surface text of class names. This is a\nmore challenging setting than the seed-driven weak supervision, which allows a\nfew seed words per class. We opt to attack this problem from a representation\nlearning perspective -- ideal document representations should lead to nearly\nthe same results between clustering and the desired classification. In\nparticular, one can classify the same corpus differently (e.g., based on topics\nand locations), so document representations should be adaptive to the given\nclass names. We propose a novel framework X-Class to realize the adaptive\nrepresentations. Specifically, we first estimate class representations by\nincrementally adding the most similar word to each class until inconsistency\narises. Following a tailored mixture of class attention mechanisms, we obtain\nthe document representation via a weighted average of contextualized word\nrepresentations. With the prior of each document assigned to its nearest class,\nwe then cluster and align the documents to classes. Finally, we pick the most\nconfident documents from each cluster to train a text classifier. Extensive\nexperiments demonstrate that X-Class can rival and even outperform seed-driven\nweakly supervised methods on 7 benchmark datasets. Our dataset and code are\nreleased at https://github.com/ZihanWangKi/XClass/ .\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:09:51 GMT"},{"version":"v2","created":"Mon, 7 Feb 2022 23:16:14 GMT"}],"update_date":"2022-02-09"}
{"id":"2010.12795","submitter":"Navita Goyal","authors":"Navita Goyal, Roodram Paneri, Ayush Agarwal, Udit Kalani, Abhilasha\n  Sancheti, Niyati Chhaya","title":"CaM-Gen:Causally-aware Metric-guided Text Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Content is created for a well-defined purpose, often described by a metric or\nsignal represented in the form of structured information. The relationship\nbetween the goal (metrics) of target content and the content itself is\nnon-trivial. While large-scale language models show promising text generation\ncapabilities, guiding the generated text with external metrics is challenging.\nThese metrics and content tend to have inherent relationships and not all of\nthem may be of consequence. We introduce CaM-Gen: Causally aware Generative\nNetworks guided by user-defined target metrics incorporating the causal\nrelationships between the metric and content features. We leverage causal\ninference techniques to identify causally significant aspects of a text that\nlead to the target metric and then explicitly guide generative models towards\nthese by a feedback mechanism. We propose this mechanism for variational\nautoencoder and Transformer-based generative models. The proposed models beat\nbaselines in terms of the target metric control while maintaining fluency and\nlanguage quality of the generated text. To the best of our knowledge, this is\none of the early attempts at controlled generation incorporating a metric guide\nusing causal inference.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:17:35 GMT"},{"version":"v2","created":"Fri, 25 Mar 2022 23:06:47 GMT"}],"update_date":"2022-03-29"}
{"id":"2010.12796","submitter":"Xiaqing Ding","authors":"Xiaqing Ding, Yue Wang, Li Tang, Yanmei Jiao and Rong Xiong","title":"Improving the generalization of network based relative pose regression:\n  dimension reduction as a regularizer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Visual localization occupies an important position in many areas such as\nAugmented Reality, robotics and 3D reconstruction. The state-of-the-art visual\nlocalization methods perform pose estimation using geometry based solver within\nthe RANSAC framework. However, these methods require accurate pixel-level\nmatching at high image resolution, which is hard to satisfy under significant\nchanges from appearance, dynamics or perspective of view. End-to-end learning\nbased regression networks provide a solution to circumvent the requirement for\nprecise pixel-level correspondences, but demonstrate poor performance towards\ncross-scene generalization. In this paper, we explicitly add a learnable\nmatching layer within the network to isolate the pose regression solver from\nthe absolute image feature values, and apply dimension regularization on both\nthe correlation feature channel and the image scale to further improve\nperformance towards generalization and large viewpoint change. We implement\nthis dimension regularization strategy within a two-layer pyramid based\nframework to regress the localization results from coarse to fine. In addition,\nthe depth information is fused for absolute translational scale recovery.\nThrough experiments on real world RGBD datasets we validate the effectiveness\nof our design in terms of improving both generalization performance and\nrobustness towards viewpoint change, and also show the potential of regression\nbased visual localization networks towards challenging occasions that are\ndifficult for geometry based visual localization methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:20:46 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12797","submitter":"Bryan Kian Hsiang Low","authors":"Rachael Hwee Ling Sim, Yehong Zhang, Mun Choon Chan, Bryan Kian Hsiang\n  Low","title":"Collaborative Machine Learning with Incentive-Aware Model Rewards","comments":"37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs and additional experimental results, 17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.GT cs.MA stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collaborative machine learning (ML) is an appealing paradigm to build\nhigh-quality ML models by training on the aggregated data from many parties.\nHowever, these parties are only willing to share their data when given enough\nincentives, such as a guaranteed fair reward based on their contributions. This\nmotivates the need for measuring a party's contribution and designing an\nincentive-aware reward scheme accordingly. This paper proposes to value a\nparty's reward based on Shapley value and information gain on model parameters\ngiven its data. Subsequently, we give each party a model as a reward. To\nformally incentivize the collaboration, we define some desirable properties\n(e.g., fairness and stability) which are inspired by cooperative game theory\nbut adapted for our model reward that is uniquely freely replicable. Then, we\npropose a novel model reward scheme to satisfy fairness and trade off between\nthe desirable properties via an adjustable parameter. The value of each party's\nmodel reward determined by our scheme is attained by injecting Gaussian noise\nto the aggregated training data with an optimized noise variance. We\nempirically demonstrate interesting properties of our scheme and evaluate its\nperformance using synthetic and real-world datasets.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:20:55 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12798","submitter":"Xavier Thomas","authors":"Xavier Thomas","title":"Content-Based Personalized Recommender System Using Entity Embeddings","comments":"2 Pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recommender systems are a class of machine learning algorithms that provide\nrelevant recommendations to a user based on the user's interaction with similar\nitems or based on the content of the item. In settings where the content of the\nitem is to be preserved, a content-based approach would be beneficial. This\npaper aims to highlight the advantages of the content-based approach through\nlearned embeddings and leveraging these advantages to provide better and\npersonalised movie recommendations based on user preferences to various movie\nfeatures such as genre and keyword tags.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:25:13 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12799","submitter":"Bryan Kian Hsiang Low","authors":"Dmitrii Kharkovskii, Zhongxiang Dai, Bryan Kian Hsiang Low","title":"Private Outsourced Bayesian Optimization","comments":"37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs, 27 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents the private-outsourced-Gaussian process-upper confidence\nbound (PO-GP-UCB) algorithm, which is the first algorithm for\nprivacy-preserving Bayesian optimization (BO) in the outsourced setting with a\nprovable performance guarantee. We consider the outsourced setting where the\nentity holding the dataset and the entity performing BO are represented by\ndifferent parties, and the dataset cannot be released non-privately. For\nexample, a hospital holds a dataset of sensitive medical records and outsources\nthe BO task on this dataset to an industrial AI company. The key idea of our\napproach is to make the BO performance of our algorithm similar to that of\nnon-private GP-UCB run using the original dataset, which is achieved by using a\nrandom projection-based transformation that preserves both privacy and the\npairwise distances between inputs. Our main theoretical contribution is to show\nthat a regret bound similar to that of the standard GP-UCB algorithm can be\nestablished for our PO-GP-UCB algorithm. We empirically evaluate the\nperformance of our PO-GP-UCB algorithm with synthetic and real-world datasets.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:30:45 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12800","submitter":"Xinliang Frederick Zhang","authors":"Xinliang Frederick Zhang, Heming Sun, Xiang Yue, Simon Lin, Huan Sun","title":"COUGH: A Challenge Dataset and Models for COVID-19 FAQ Retrieval","comments":"EMNLP'21 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a large, challenging dataset, COUGH, for COVID-19 FAQ retrieval.\nSimilar to a standard FAQ dataset, COUGH consists of three parts: FAQ Bank,\nQuery Bank and Relevance Set. The FAQ Bank contains ~16K FAQ items scraped from\n55 credible websites (e.g., CDC and WHO). For evaluation, we introduce Query\nBank and Relevance Set, where the former contains 1,236 human-paraphrased\nqueries while the latter contains ~32 human-annotated FAQ items for each query.\nWe analyze COUGH by testing different FAQ retrieval models built on top of BM25\nand BERT, among which the best model achieves 48.8 under P@5, indicating a\ngreat challenge presented by COUGH and encouraging future research for further\nimprovement. Our COUGH dataset is available at\nhttps://github.com/sunlab-osu/covid-faq.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:30:59 GMT"},{"version":"v2","created":"Fri, 10 Sep 2021 17:30:27 GMT"}],"update_date":"2021-09-13"}
{"id":"2010.12801","submitter":"Pau Clusella Cober\\'o","authors":"Pau Clusella and Antonio Politi","title":"Irregular collective dynamics in a Kuramoto-Daido system","comments":null,"journal-ref":null,"doi":"10.1088/2632-072X/abd3af","report-no":null,"categories":"nlin.CD nlin.AO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyse the collective behavior of a mean-field model of phase-oscillators\nof Kuramoto-Daido type coupled through pairwise interactions which depend on\nphase differences: the coupling function is composed of three harmonics. We\nprovide convincing evidence of a transient but long-lasting chaotic collective\nchaos, which persists in the thermodynamic limit. The regime is analysed with\nthe help of clever direct numerical simulations, by determining the maximum\nLyapunov exponent and assessing the transversal stability to the\nself-consistent mean field. The structure of the invariant measure is finally\ndescribed in terms of a resolution-dependent entropy.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:34:38 GMT"}],"update_date":"2021-01-05"}
{"id":"2010.12802","submitter":"Andres Castellanos-Gomez","authors":"Riccardo Frisenda, Yue Niu, Patricia Gant, Manuel Mu\\~noz and Andres\n  Castellanos-Gomez","title":"Naturally occurring van der Waals materials","comments":"Perspective article. 34 pages, 10 figures, 1 table, more than 170\n  references","journal-ref":"npj 2D Mater Appl 4, 38 (2020)","doi":"10.1038/s41699-020-00172-2","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The exfoliation of two naturally occurring van der Waals minerals, graphite\nand molybdenite, arouse an unprecedented level of interest by the scientific\ncommunity and shaped a whole new field of research: 2D materials research.\nSeveral years later, the family of van der Waals materials that can be\nexfoliated to isolate 2D materials keeps growing, but most of them are\nsynthetic. Interestingly, in nature plenty of naturally occurring van der Waals\nminerals can be found with a wide range of chemical compositions and crystal\nstructures whose properties are mostly unexplored so far. This Perspective aims\nto provide an overview of different families of van der Waals minerals to\nstimulate their exploration in the 2D limit.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:35:39 GMT"}],"update_date":"2021-05-11"}
{"id":"2010.12803","submitter":"Zheda Mai","authors":"Zheda Mai, Ga Wu, Kai Luo, Scott Sanner","title":"Attentive Autoencoders for Multifaceted Preference Learning in One-class\n  Collaborative Filtering","comments":"Accepted at ICDMW 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most existing One-Class Collaborative Filtering (OC-CF) algorithms estimate a\nuser's preference as a latent vector by encoding their historical interactions.\nHowever, users often show diverse interests, which significantly increases the\nlearning difficulty. In order to capture multifaceted user preferences,\nexisting recommender systems either increase the encoding complexity or extend\nthe latent representation dimension. Unfortunately, these changes inevitably\nlead to increased training difficulty and exacerbate scalability issues. In\nthis paper, we propose a novel and efficient CF framework called Attentive\nMulti-modal AutoRec (AMA) that explicitly tracks multiple facets of user\npreferences. Specifically, we extend the Autoencoding-based recommender AutoRec\nto learn user preferences with multi-modal latent representations, where each\nmode captures one facet of a user's preferences. By leveraging the attention\nmechanism, each observed interaction can have different contributions to the\npreference facets. Through extensive experiments on three real-world datasets,\nwe show that AMA is competitive with state-of-the-art models under the OC-CF\nsetting. Also, we demonstrate how the proposed model improves interpretability\nby providing explanations using the attention mechanism.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:35:44 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12804","submitter":"Pedro Jos\\'e Chocano Feito","authors":"Pedro J. Chocano, Manuel A. Mor\\'on, Francisco R. Ruiz del Portal","title":"Coincidence theorems for finite topological spaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We adapt the definition of the Vietoris map to the framework of finite\ntopological spaces and we prove some coincidence theorems. From them, we deduce\na Lefschetz fixed point theorem for multivalued maps that improves recent\nresults in the literature. Finally, it is given an application to the\napproximation of discrete dynamical systems in polyhedra.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:39:08 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12805","submitter":"Andres Castellanos-Gomez","authors":"Martin Lee, Ali Mazaheri, Herre S. J. van der Zant, Riccardo Frisenda,\n  Andres Castellanos-Gomez","title":"Drawing WS2 thermal sensors on paper substrates","comments":"6 main text figures, 1 table, 6 supp. info. figures","journal-ref":null,"doi":"10.1039/D0NR06036D","report-no":null,"categories":"physics.app-ph cond-mat.mtrl-sci physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Paper based thermoresistive sensors are fabricated by rubbing WS2 powder\nagainst a piece of standard copier paper, like the way a pencil is used to\nwrite on paper. The abrasion between the layered material and the rough paper\nsurface erodes the material, breaking the weak van der Waals interlayer bonds,\nyielding a film of interconnected platelets. The resistance of WS2 presents a\nstrong temperature dependence, as expected for a semiconductor material in\nwhich charge transport is due to thermally activated carriers. This strong\ntemperature dependence makes the paper supported WS2 devices extremely\nsensitive to small changes in temperature. This exquisite thermal sensitivity,\nand their fast response times to sudden temperature changes, is exploited\nthereby demonstrating the usability of a WS2-on-paper thermal sensor in a\nrespiration monitoring device.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:40:39 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12806","submitter":"Sabine Klapp","authors":"Timo J. Doerries, Sarah A.M. Loos, and Sabine H.L. Klapp","title":"Correlation functions of non-Markovian systems out of equilibrium:\n  Analytical expressions beyond single-exponential memory","comments":"to appear in J. Stat. Mech. (2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is concerned with correlation functions of stochastic systems with\nmemory, a prominent example being a molecule or colloid moving through a\ncomplex (e.g., viscoelastic) fluid environment. Analytical investigations of\nsuch systems based on non-Markovian stochastic equations are notoriously\ndifficult. A common approximation is that of a single-exponential memory,\ncorresponding to the introduction of one auxiliary variable coupled to the\nMarkovian dynamics of the main variable. As a generalization, we here\ninvestigate a class of \"toy\" models with altogether three degrees of freedom,\ngiving rise to more complex forms of memory. Specifically, we consider, mainly\non an analytical basis, the under- and overdamped motion of a colloidal\nparticle coupled linearly to two auxiliary variables, where the coupling\nbetween variables can be either reciprocal or non-reciprocal. Projecting out\nthe auxiliary variables, we obtain non-Markovian Langevin equations with\nfriction kernels and colored noise, whose structure is similar to that of a\ngeneralized Langevin equation. For the present systems, however, the\nnon-Markovian equations may violate the fluctuation-dissipation relation as\nwell as detailed balance, indicating that the systems are out of equilibrium.\nWe then study systematically the connection between the coupling topology of\nthe underlying Markovian system and various autocorrelation functions.We\ndemonstrate that already two auxiliary variables can generate surprisingly\ncomplex (e.g., non-monotonic or oscillatory) memory and correlation functions.\nFinally, we show that a minimal overdamped model with two auxiliary variables\nand suitable non-reciprocal coupling yields correlation functions resembling\nthose describing hydrodynamic backflow in an optical trap.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:43:18 GMT"},{"version":"v2","created":"Tue, 23 Feb 2021 13:49:08 GMT"}],"update_date":"2021-02-24"}
{"id":"2010.12807","submitter":"Weitong Hua","authors":"Weitong Hua, Zhongxiang Zhou, Jun Wu, Huang Huang, Yue Wang, Rong\n  Xiong","title":"REDE: End-to-end Object 6D Pose Robust Estimation Using Differentiable\n  Outliers Elimination","comments":null,"journal-ref":null,"doi":"10.1109/LRA.2021.3062304","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Object 6D pose estimation is a fundamental task in many applications.\nConventional methods solve the task by detecting and matching the keypoints,\nthen estimating the pose. Recent efforts bringing deep learning into the\nproblem mainly overcome the vulnerability of conventional methods to\nenvironmental variation due to the hand-crafted feature design. However, these\nmethods cannot achieve end-to-end learning and good interpretability at the\nsame time. In this paper, we propose REDE, a novel end-to-end object pose\nestimator using RGB-D data, which utilizes network for keypoint regression, and\na differentiable geometric pose estimator for pose error back-propagation.\nBesides, to achieve better robustness when outlier keypoint prediction occurs,\nwe further propose a differentiable outliers elimination method that regresses\nthe candidate result and the confidence simultaneously. Via confidence weighted\naggregation of multiple candidates, we can reduce the effect from the outliers\nin the final estimation. Finally, following the conventional method, we apply a\nlearnable refinement process to further improve the estimation. The\nexperimental results on three benchmark datasets show that REDE slightly\noutperforms the state-of-the-art approaches and is more robust to object\nocclusion.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:45:39 GMT"},{"version":"v2","created":"Tue, 12 Jan 2021 06:06:50 GMT"},{"version":"v3","created":"Wed, 24 Feb 2021 13:38:26 GMT"}],"update_date":"2021-02-25"}
{"id":"2010.12808","submitter":"Xiaodong Yu","authors":"Xiaodong Yu, Wenpeng Yin, Dan Roth","title":"Pairwise Representation Learning for Event Coreference","comments":"8 pages. *SEM 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Natural Language Processing tasks such as resolving the coreference of events\nrequire understanding the relations between two text snippets. These tasks are\ntypically formulated as (binary) classification problems over independently\ninduced representations of the text snippets. In this work, we develop a\nPairwise Representation Learning (PairwiseRL) scheme for the event mention\npairs, in which we jointly encode a pair of text snippets so that the\nrepresentation of each mention in the pair is induced in the context of the\nother one. Furthermore, our representation supports a finer, structured\nrepresentation of the text snippet to facilitate encoding events and their\narguments. We show that PairwiseRL, despite its simplicity, outperforms the\nprior state-of-the-art event coreference systems on both cross-document and\nwithin-document event coreference benchmarks. We also conduct in-depth analysis\nin terms of the improvement and the limitation of pairwise representation so as\nto provide insights for future work.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:55:52 GMT"},{"version":"v2","created":"Thu, 20 Jan 2022 19:40:58 GMT"},{"version":"v3","created":"Wed, 15 Feb 2023 23:35:09 GMT"}],"update_date":"2023-02-17"}
{"id":"2010.12809","submitter":"Yael Mathov","authors":"Yael Mathov and Tal Ben Senior and Asaf Shabtai and Yuval Elovici","title":"Stop Bugging Me! Evading Modern-Day Wiretapping Using Adversarial\n  Perturbations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CR cs.LG eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mass surveillance systems for voice over IP (VoIP) conversations pose a great\nrisk to privacy. These automated systems use learning models to analyze\nconversations, and calls that involve specific topics are routed to a human\nagent for further examination. In this study, we present an\nadversarial-learning-based framework for privacy protection for VoIP\nconversations. We present a novel method that finds a universal adversarial\nperturbation (UAP), which, when added to the audio stream, prevents an\neavesdropper from automatically detecting the conversation's topic. As shown in\nour experiments, the UAP is agnostic to the speaker or audio length, and its\nvolume can be changed in real time, as needed. Our real-world solution uses a\nTeensy microcontroller that acts as an external microphone and adds the UAP to\nthe audio in real time. We examine different speakers, VoIP applications\n(Skype, Zoom, Slack, and Google Meet), and audio lengths. Our results in the\nreal world suggest that our approach is a feasible solution for privacy\nprotection.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 06:56:35 GMT"},{"version":"v2","created":"Thu, 2 Sep 2021 07:54:52 GMT"}],"update_date":"2021-09-03"}
{"id":"2010.12810","submitter":"Chenlin Meng","authors":"Chenlin Meng, Lantao Yu, Yang Song, Jiaming Song and Stefano Ermon","title":"Autoregressive Score Matching","comments":"NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Autoregressive models use chain rule to define a joint probability\ndistribution as a product of conditionals. These conditionals need to be\nnormalized, imposing constraints on the functional families that can be used.\nTo increase flexibility, we propose autoregressive conditional score models\n(AR-CSM) where we parameterize the joint distribution in terms of the\nderivatives of univariate log-conditionals (scores), which need not be\nnormalized. To train AR-CSM, we introduce a new divergence between\ndistributions named Composite Score Matching (CSM). For AR-CSM models, this\ndivergence between data and model distributions can be computed and optimized\nefficiently, requiring no expensive sampling or adversarial training. Compared\nto previous score matching algorithms, our method is more scalable to high\ndimensional data and more stable to optimize. We show with extensive\nexperimental results that it can be applied to density estimation on synthetic\ndata, image generation, image denoising, and training latent variable models\nwith implicit encoders.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:01:24 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12811","submitter":"Tailin Wu","authors":"Tailin Wu, Hongyu Ren, Pan Li, Jure Leskovec","title":"Graph Information Bottleneck","comments":"20 pages, 3 figures, NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Representation learning of graph-structured data is challenging because both\ngraph structure and node features carry important information. Graph Neural\nNetworks (GNNs) provide an expressive way to fuse information from network\nstructure and node features. However, GNNs are prone to adversarial attacks.\nHere we introduce Graph Information Bottleneck (GIB), an information-theoretic\nprinciple that optimally balances expressiveness and robustness of the learned\nrepresentation of graph-structured data. Inheriting from the general\nInformation Bottleneck (IB), GIB aims to learn the minimal sufficient\nrepresentation for a given task by maximizing the mutual information between\nthe representation and the target, and simultaneously constraining the mutual\ninformation between the representation and the input data. Different from the\ngeneral IB, GIB regularizes the structural as well as the feature information.\nWe design two sampling algorithms for structural regularization and instantiate\nthe GIB principle with two new models: GIB-Cat and GIB-Bern, and demonstrate\nthe benefits by evaluating the resilience to adversarial attacks. We show that\nour proposed models are more robust than state-of-the-art graph defense models.\nGIB-based models empirically achieve up to 31% improvement with adversarial\nperturbation of the graph structure as well as node features.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:13:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12812","submitter":"Zexuan Zhong","authors":"Zexuan Zhong and Danqi Chen","title":"A Frustratingly Easy Approach for Entity and Relation Extraction","comments":"NAACL 2021. Our code and models are available at\n  https://github.com/princeton-nlp/PURE","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  End-to-end relation extraction aims to identify named entities and extract\nrelations between them. Most recent work models these two subtasks jointly,\neither by casting them in one structured prediction framework, or performing\nmulti-task learning through shared representations. In this work, we present a\nsimple pipelined approach for entity and relation extraction, and establish the\nnew state-of-the-art on standard benchmarks (ACE04, ACE05 and SciERC),\nobtaining a 1.7%-2.8% absolute improvement in relation F1 over previous joint\nmodels with the same pre-trained encoders. Our approach essentially builds on\ntwo independent encoders and merely uses the entity model to construct the\ninput for the relation model. Through a series of careful examinations, we\nvalidate the importance of learning distinct contextual representations for\nentities and relations, fusing entity information early in the relation model,\nand incorporating global context. Finally, we also present an efficient\napproximation to our approach which requires only one pass of both entity and\nrelation encoders at inference time, achieving an 8-16$\\times$ speedup with a\nslight reduction in accuracy.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:14:01 GMT"},{"version":"v2","created":"Tue, 23 Mar 2021 17:48:35 GMT"}],"update_date":"2021-03-24"}
{"id":"2010.12813","submitter":"Kevin Lin","authors":"Catherine Chen, Kevin Lin, Dan Klein","title":"Constructing Taxonomies from Pretrained Language Models","comments":"NAACL 2021","journal-ref":null,"doi":"10.18653/v1/2021.naacl-main.373","report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a method for constructing taxonomic trees (e.g., WordNet) using\npretrained language models. Our approach is composed of two modules, one that\npredicts parenthood relations and another that reconciles those predictions\ninto trees. The parenthood prediction module produces likelihood scores for\neach potential parent-child pair, creating a graph of parent-child relation\nscores. The tree reconciliation module treats the task as a graph optimization\nproblem and outputs the maximum spanning tree of this graph. We train our model\non subtrees sampled from WordNet, and test on non-overlapping WordNet subtrees.\nWe show that incorporating web-retrieved glosses can further improve\nperformance. On the task of constructing subtrees of English WordNet, the model\nachieves 66.7 ancestor F1, a 20.0% relative increase over the previous best\npublished result on this task. In addition, we convert the original English\ndataset into nine other languages using Open Multilingual WordNet and extend\nour results across these languages.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:16:21 GMT"},{"version":"v2","created":"Sun, 18 Apr 2021 02:37:29 GMT"}],"update_date":"2021-11-03"}
{"id":"2010.12814","submitter":"Manil T Mohan","authors":"Manil T. Mohan","title":"Asymptotic analysis of the 2D convective Brinkman-Forchheimer equations\n  in unbounded domains: Global attractors and upper semicontinuity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we carry out the asymptotic analysis of the two dimensional\nconvective Brinkman-Forchheimer (CBF) equations, which characterize the motion\nof incompressible fluid flows in a saturated porous medium. We establish the\nexistence of a global attractor in both bounded (using compact embedding) and\nPoincar\\'e domains (using asymptotic compactness property). In Poincar\\'e\ndomains, for $r=1,2$ and $3$, the estimates for Hausdorff as well as fractal\ndimensions of the global attractors are also obtained. We then show an upper\nsemicontinuity of global attractors for the 2D CBF equations. We consider an\nexpanding sequence of simply connected, bounded and smooth subdomains\n$\\Omega_m$ of the Poincar\\'e domain $\\Omega$ such that $\\Omega_m\\to\\Omega$ as\n$m\\to\\infty$. If $\\mathscr{A}_m$ and $\\mathscr{A}$ are the global attractors of\nthe 2D CBF equations corresponding to $\\Omega$ and $\\Omega_m$, respectively,\nthen we show that for large enough $m$, the global attractor $\\mathscr{A}_m$\nenters into any neighborhood $\\mathcal{U}(\\mathscr{A})$ of $\\mathscr{A}$. The\npresence of Darcy term in the CBF equations helps us to obtain the above\nmentioned results in general unbounded domains also. Finally, we discuss about\nthe quasi-stability property of the semigroup associated with the 2D CBF\nequations in bounded domains and establish the existence of finite fractal\ndimensional global as well as exponential attractors for $r\\in[1,\\infty)$.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:18:03 GMT"},{"version":"v2","created":"Thu, 12 Nov 2020 14:00:19 GMT"},{"version":"v3","created":"Sat, 28 Nov 2020 06:58:19 GMT"}],"update_date":"2020-12-01"}
{"id":"2010.12815","submitter":"Harekrushna Behera Dr.","authors":"Mohamin B M Khan and Harekrushna Behera","title":"Impact of sloping porous seabed on the efficiency of an OWC against\n  oblique waves","comments":null,"journal-ref":null,"doi":"10.1016/j.renene.2021.04.046","report-no":null,"categories":"physics.flu-dyn physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The study examines the influence of a sloping porous bed on the efficiency of\nan oscillating water column (OWC) device facing oblique water waves. A\nvertical, surface piercing, thin plate near a rigid wall approximates the OWC.\nThe system is simulated using a multi-domain boundary element method assuming\nthe linear potential theory. The impact of varying sloping bed structural\nparameters and influence of the incident wave angle on the performance of the\nOWC is evaluated and discussed. The significance of this model to act as a\nbreakwater protecting near-shore marine facilities is also highlighted. The OWC\nefficiency is found to be highly sensitive to the slope of the porous seabed,\nand seabed porosity is found to stabilize the resonant frequency against\nchanges in water levels. OWCs are found to be more efficient over porous\nseabeds with higher frictional coefficients. The results indicate optimum\nvalues for the parameters governing such a wave energy conversion system that\ncan be used for the design and implementation of the model.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:23:01 GMT"}],"update_date":"2021-06-30"}
{"id":"2010.12816","submitter":"Sebastian Perez-Salazar","authors":"Sebastian Perez-Salazar, Rachel Cummings","title":"Differentially Private Online Submodular Maximization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we consider the problem of online submodular maximization under\na cardinality constraint with differential privacy (DP). A stream of $T$\nsubmodular functions over a common finite ground set $U$ arrives online, and at\neach time-step the decision maker must choose at most $k$ elements of $U$\nbefore observing the function. The decision maker obtains a payoff equal to the\nfunction evaluated on the chosen set, and aims to learn a sequence of sets that\nachieves low expected regret. In the full-information setting, we develop an\n$(\\varepsilon,\\delta)$-DP algorithm with expected $(1-1/e)$-regret bound of\n$\\mathcal{O}\\left( \\frac{k^2\\log |U|\\sqrt{T \\log k/\\delta}}{\\varepsilon}\n\\right)$. This algorithm contains $k$ ordered experts that learn the best\nmarginal increments for each item over the whole time horizon while maintaining\nprivacy of the functions. In the bandit setting, we provide an\n$(\\varepsilon,\\delta+ O(e^{-T^{1/3}}))$-DP algorithm with expected\n$(1-1/e)$-regret bound of $\\mathcal{O}\\left( \\frac{\\sqrt{\\log\nk/\\delta}}{\\varepsilon} (k (|U| \\log |U|)^{1/3})^2 T^{2/3} \\right)$. Our\nalgorithms contains $k$ ordered experts that learn the best marginal item to\nselect given the items chosen her predecessors, while maintaining privacy of\nthe functions. One challenge for privacy in this setting is that the payoff and\nfeedback of expert $i$ depends on the actions taken by her $i-1$ predecessors.\nThis particular type of information leakage is not covered by post-processing,\nand new analysis is required. Our techniques for maintaining privacy with\nfeedforward may be of independent interest.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:23:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12817","submitter":"Maria Gorelik","authors":"Maria Gorelik","title":"Bipartite extension graphs and the Duflo--Serganova functor","comments":"Corollary 2.3.3 added; other minor changes made","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RT math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider several examples when the extension graph admits a bipartition\ncompatible with the action of Duflo--Serganova functors.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:33:02 GMT"},{"version":"v2","created":"Sun, 8 May 2022 15:53:20 GMT"},{"version":"v3","created":"Tue, 22 Nov 2022 07:14:34 GMT"}],"update_date":"2022-11-23"}
{"id":"2010.12818","submitter":"Enrico Pajer","authors":"Enrico Pajer","title":"Building a Boostless Bootstrap for the Bispectrum","comments":"34+10 pages, 1 figure","journal-ref":null,"doi":"10.1088/1475-7516/2021/01/023","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The observation of primordial correlators by cosmological surveys is a very\npromising avenue to probe high energies and the perturbative regime of quantum\ngravity. Hence, it is imperative that we understand how these observables are\nshaped by the pillars of fundamental physics, namely unitarity, locality and\nsymmetries. To this end, we study the three-point correlators of gravitons and\nscalar curvature perturbations around a quasi de Sitter spacetime. We identify\na set of Bootstrap Rules that fully fix the form of these correlators in the\nasymptotic future, i.e. at the boundary, and make no reference to bulk time\nevolution. Importantly, our Boostless Bootstrap accounts for the ubiquitous\n(spontaneous) breaking of de Sitter boosts caused by any inflationary\nbackground. We show how all bispectra involving gravitons in single-clock,\ncanonical inflation can be easily derived in this approach. We also derive for\nthe first time the scalar bispectrum in the Effective Field Theory of inflation\nto any order in derivatives. In many cases, our derivation is computationally\nsimpler than the corresponding explicit calculation, and makes particularly\ntransparent the implications of locality, the choice of vacuum, and the\nunderlying symmetries.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:33:22 GMT"}],"update_date":"2021-01-20"}
{"id":"2010.12819","submitter":"Linnea Grans-Samuelsson","authors":"Linnea Grans-Samuelsson, Jesper Lykke Jacobsen, Hubert Saleur","title":"The action of the Virasoro algebra in quantum spin chains. I. The\n  non-rational case","comments":"61 pages, 13 figures, 12 tables v2: Minor edits. Corrected typo in eq\n  (188)","journal-ref":null,"doi":"10.1007/JHEP02(2021)130","report-no":null,"categories":"hep-th cond-mat.stat-mech math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the action of discretized Virasoro generators, built out of\ngenerators of the lattice Temperley-Lieb algebra (\"Koo-Saleur\ngenerators\"[arXiv:hep-th/9312156]), in the critical XXZ quantum spin chain. We\nexplore the structure of the continuum-limit Virasoro modules at generic\ncentral charge for the XXZ vertex model, paralleling [arXiv:2007.11539] for the\nloop model. We find again indecomposable modules, but this time not logarithmic\nones. The limit of the Temperley-Lieb modules $\\mathcal{W}_{j,1}$ for $j\\neq 0$\ncontains pairs of \"conjugate states\" with conformal weights\n$(h_{r,s},h_{r,-s})$ and $(h_{r,-s},h_{r,s})$ that give rise to dual\nstructures: Verma or co-Verma modules. The limit of\n$\\mathcal{W}_{0,\\mathfrak{q}^{\\pm2}}$ contains diagonal fields\n$(h_{r,1},h_{r,1})$ and gives rise to either only Verma or only co-Verma\nmodules, depending on the sign of the exponent in $\\mathfrak{q}^{\\pm 2}$. In\norder to obtain matrix elements of Koo-Saleur generators at large system size\n$N$ we use Bethe ansatz and Quantum Inverse Scattering methods, computing the\nform factors for relevant combinations of three neighbouring spin operators.\nRelations between form factors ensure that the above duality exists already at\nthe lattice level. We also study in which sense Koo-Saleur generators converge\nto Virasoro generators. We consider convergence in the weak sense,\ninvestigating whether the commutator of limits is the same as the limit of the\ncommutator? We find that it coincides only up to the central term. As a side\nresult we compute the ground-state expectation value of two neighbouring\nTemperley-Lieb generators in the XXZ spin chain.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:34:16 GMT"},{"version":"v2","created":"Mon, 22 Feb 2021 14:04:51 GMT"}],"update_date":"2021-02-23"}
{"id":"2010.12820","submitter":"Emily Sheng","authors":"Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, Nanyun Peng","title":"\"Nice Try, Kiddo\": Investigating Ad Hominems in Dialogue Responses","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ad hominem attacks are those that target some feature of a person's character\ninstead of the position the person is maintaining. These attacks are harmful\nbecause they propagate implicit biases and diminish a person's credibility.\nSince dialogue systems respond directly to user input, it is important to study\nad hominems in dialogue responses. To this end, we propose categories of ad\nhominems, compose an annotated dataset, and build a classifier to analyze human\nand dialogue system responses to English Twitter posts. We specifically compare\nresponses to Twitter topics about marginalized communities (#BlackLivesMatter,\n#MeToo) versus other topics (#Vegan, #WFH), because the abusive language of ad\nhominems could further amplify the skew of power away from marginalized\npopulations. Furthermore, we propose a constrained decoding technique that uses\nsalient $n$-gram similarity as a soft constraint for top-$k$ sampling to reduce\nthe amount of ad hominems generated. Our results indicate that 1) responses\nfrom both humans and DialoGPT contain more ad hominems for discussions around\nmarginalized communities, 2) different quantities of ad hominems in the\ntraining data can influence the likelihood of generating ad hominems, and 3) we\ncan use constrained decoding techniques to reduce ad hominems in generated\ndialogue responses.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:37:49 GMT"},{"version":"v2","created":"Mon, 12 Apr 2021 17:22:39 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12821","submitter":"Hyung Won Chung","authors":"Hyung Won Chung, Thibault F\\'evry, Henry Tsai, Melvin Johnson,\n  Sebastian Ruder","title":"Rethinking embedding coupling in pre-trained language models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We re-evaluate the standard practice of sharing weights between input and\noutput embeddings in state-of-the-art pre-trained language models. We show that\ndecoupled embeddings provide increased modeling flexibility, allowing us to\nsignificantly improve the efficiency of parameter allocation in the input\nembedding of multilingual models. By reallocating the input embedding\nparameters in the Transformer layers, we achieve dramatically better\nperformance on standard natural language understanding tasks with the same\nnumber of parameters during fine-tuning. We also show that allocating\nadditional capacity to the output embedding provides benefits to the model that\npersist through the fine-tuning stage even though the output embedding is\ndiscarded after pre-training. Our analysis shows that larger output embeddings\nprevent the model's last layers from overspecializing to the pre-training task\nand encourage Transformer representations to be more general and more\ntransferable to other tasks and languages. Harnessing these findings, we are\nable to train models that achieve strong performance on the XTREME benchmark\nwithout increasing the number of parameters at the fine-tuning stage.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:43:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12822","submitter":"Ian Marquette","authors":"Danilo Latini, Ian Marquette and Yao-Zhong Zhang","title":"Embedding of the Racah Algebra R($\\boldsymbol{n}$) and\n  Superintegrability","comments":null,"journal-ref":"Annals of Physics 426, 168397 (2021)","doi":"10.1016/j.aop.2021.168397","report-no":null,"categories":"math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The rank-$1$ Racah algebra $R(3)$ plays a pivotal role in the theory of\nsuperintegrable systems. It appears as the symmetry algebra of the\n$3$-parameter system on the $2$-sphere from which all second-order conformally\nflat superintegrable models in $2$D can be obtained by means of suitable limits\nand contractions. A higher rank generalization of $R(3)$, the so-called rank\n$n-2$ Racah algebra $R(n)$, has been considered recently and showed to be the\nsymmetry algebra of the general superintegrable model on the $(n-1)$-sphere. In\nthe present work, we show that such an algebraic structure naturally arises as\nembedded inside a larger quadratic algebra characterizing $n$D superintegrable\nmodels with non-central terms. This is shown both in classical and quantum\nmechanics through suitable (symplectic or differential) realisations of the\nRacah and additional generators. Among the main results, we present an explicit\nconstruction of the complete symmetry algebras for two families of\n$n$-dimensional maximally superintegrable models, the Smorodinsky-Winternitz\nsystem and the generalized Kepler-Coulomb system. For both families, the\nunderlying symmetry algebras are higher-rank quadratic algebras containing the\nRacah algebra $R(n)$ as subalgebra. High-order algebraic relations among the\ngenerators of the full quadratic algebras are also obtained both in the\nclassical and quantum frameworks. These results should shed new light to the\nfurther understanding of the structures of quadratic algebras in the context of\nsuperintegrable systems.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:43:02 GMT"}],"update_date":"2021-10-01"}
{"id":"2010.12823","submitter":"Huan Wang","authors":"Huan Wang, Jing Wang","title":"Topological bands in two-dimensional orbital-active bipartite lattices","comments":"7 pages, 5 figures, 1 table","journal-ref":"Phys. Rev. B 103, L081109 (2021)","doi":"10.1103/PhysRevB.103.L081109","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The search for large gap quantum spin Hall (QSH) and quantum anomalous Hall\n(QAH) insulators is important both for fundamental and practical interests. The\ndegenerate multi-orbitals $p_x,p_y$ in honeycomb lattice provides a paradigm\nfor QSH state with a boosted topological gap of the first order in atomic\nspin-orbit coupling. By using elementary band representation, we explore the\nfeasibility of this mechanism for QSH in general two-dimensional lattices, and\nfind that the biparticle lattices with $C_{3v}$ or $C_{4v}$ symmetry and\ndegenerate multi-orbitals could work. We further provide concrete tight-binding\nmodels on honeycomb, kagome and square lattices to demonstrate the desired\ntopological physics. By introducing ferromagnetism into QSH state, we extend\nthe mechanism to QAH state with a boosted gap. The QSH and QAH states can be\nachieved when Fermi level is at integer filling only for honeycomb lattice, but\nat certain fractional filling for other lattices. We conclude with a brief\ndiscussion on the possible material venues for such mechanism.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:48:55 GMT"}],"update_date":"2021-06-04"}
{"id":"2010.12824","submitter":"Yao Yao","authors":"Jiaqing Huang, Yijie Mo, and Yao Yao","title":"Unified dynamic approach for simulating quantum tunneling and thermionic\n  emission at metal/organic interface","comments":"21 pages, 6 figures","journal-ref":"Phys. Rev. Applied 15, 014021 (2021)","doi":"10.1103/PhysRevApplied.15.014021","report-no":null,"categories":"physics.app-ph physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Injection from metallic electrodes serves as a main channel of charge\ngeneration in organic semiconducting devices and the quantum effect is normally\nregarded to be essential. We develop a dynamic approach based upon the surface\nhopping (SH) algorithm and classical device modeling, by which both quantum\ntunneling and thermionic emission of charge carrier injection at metal/organic\ninterfaces are concurrently investigated. The injected charges from metallic\nelectrode are observed to quickly spread onto the organic molecules following\nby an accumulation close to the interface induced by the built-in electric\nfield, exhibiting a transition from delocalization to localization. We compare\nthe Ehrenfest dynamics on mean-field level and the SH algorithm by simulating\nthe temperature dependence of charge injection dynamics, and it is found that\nthe former one leads to an improper result that the injection efficiency\ndecreases with increasing temperature at room-temperature regime while SH\nresults are credible. The relationship between injected charges and the applied\nbias voltage suggests it is the quantum tunneling that dominates the\nlow-threshold injection characteristics in molecular crystals, which is further\nsupported by the calculation results of small entropy change during the\ninjection processes. An optimum interfacial width for charge injection\nefficiency at the interface is also quantified and can be utilized to\nunderstand the role of interfacial buffer layer in practical devices.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:50:01 GMT"}],"update_date":"2021-01-20"}
{"id":"2010.12825","submitter":"Rochelle Choenni","authors":"Rochelle Choenni, Ekaterina Shutova","title":"Cross-neutralising: Probing for joint encoding of linguistic information\n  in multilingual models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multilingual sentence encoders are widely used to transfer NLP models across\nlanguages. The success of this transfer is, however, dependent on the model's\nability to encode the patterns of cross-lingual similarity and variation. Yet,\nlittle is known as to how these models are able to do this. We propose a simple\nmethod to study how relationships between languages are encoded in two\nstate-of-the-art multilingual models (i.e. M-BERT and XLM-R). The results\nprovide insight into their information sharing mechanisms and suggest that\nlinguistic properties are encoded jointly across typologically-similar\nlanguages in these models.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:55:32 GMT"},{"version":"v2","created":"Sat, 13 Mar 2021 16:21:09 GMT"}],"update_date":"2021-03-16"}
{"id":"2010.12826","submitter":"Felix Faltings","authors":"Felix Faltings and Michel Galley and Gerold Hintz and Chris Brockett\n  and Chris Quirk and Jianfeng Gao and Bill Dolan","title":"Text Editing by Command","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A prevailing paradigm in neural text generation is one-shot generation, where\ntext is produced in a single step. The one-shot setting is inadequate, however,\nwhen the constraints the user wishes to impose on the generated text are\ndynamic, especially when authoring longer documents. We address this limitation\nwith an interactive text generation setting in which the user interacts with\nthe system by issuing commands to edit existing text. To this end, we propose a\nnovel text editing task, and introduce WikiDocEdits, a dataset of\nsingle-sentence edits crawled from Wikipedia. We show that our Interactive\nEditor, a transformer-based model trained on this dataset, outperforms\nbaselines and obtains positive results in both automatic and human evaluations.\nWe present empirical and qualitative analyses of this model's performance.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:00:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12827","submitter":"Amane Sugiyama","authors":"Amane Sugiyama and Naoki Yoshinaga","title":"Context-aware Decoder for Neural Machine Translation using a Target-side\n  Document-Level Language Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although many context-aware neural machine translation models have been\nproposed to incorporate contexts in translation, most of those models are\ntrained end-to-end on parallel documents aligned in sentence-level. Because\nonly a few domains (and language pairs) have such document-level parallel data,\nwe cannot perform accurate context-aware translation in most domains. We\ntherefore present a simple method to turn a sentence-level translation model\ninto a context-aware model by incorporating a document-level language model\ninto the decoder. Our context-aware decoder is built upon only a sentence-level\nparallel corpora and monolingual corpora; thus no document-level parallel data\nis needed. In a theoretical viewpoint, the core part of this work is the novel\nrepresentation of contextual information using point-wise mutual information\nbetween context and the current sentence. We show the effectiveness of our\napproach in three language pairs, English to French, English to Russian, and\nJapanese to English, by evaluation in \\textsc{bleu} and contrastive tests for\ncontext-aware translation.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:06:18 GMT"},{"version":"v2","created":"Mon, 15 Nov 2021 11:00:35 GMT"}],"update_date":"2021-11-16"}
{"id":"2010.12828","submitter":"Haoyu Zhang","authors":"Haoyu Zhang, Dingkun Long, Guangwei Xu, Pengjun Xie, Fei Huang, Ji\n  Wang","title":"Keyphrase Extraction with Dynamic Graph Convolutional Networks and\n  Diversified Inference","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Keyphrase extraction (KE) aims to summarize a set of phrases that accurately\nexpress a concept or a topic covered in a given document. Recently,\nSequence-to-Sequence (Seq2Seq) based generative framework is widely used in KE\ntask, and it has obtained competitive performance on various benchmarks. The\nmain challenges of Seq2Seq methods lie in acquiring informative latent document\nrepresentation and better modeling the compositionality of the target\nkeyphrases set, which will directly affect the quality of generated keyphrases.\nIn this paper, we propose to adopt the Dynamic Graph Convolutional Networks\n(DGCN) to solve the above two problems simultaneously. Concretely, we explore\nto integrate dependency trees with GCN for latent representation learning.\nMoreover, the graph structure in our model is dynamically modified during the\nlearning process according to the generated keyphrases. To this end, our\napproach is able to explicitly learn the relations within the keyphrases\ncollection and guarantee the information interchange between encoder and\ndecoder in both directions. Extensive experiments on various KE benchmark\ndatasets demonstrate the effectiveness of our approach.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:11:23 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12829","submitter":"Xian Li","authors":"Xian Li, Changhan Wang, Yun Tang, Chau Tran, Yuqing Tang, Juan Pino,\n  Alexei Baevski, Alexis Conneau, Michael Auli","title":"Multilingual Speech Translation with Efficient Finetuning of Pretrained\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a simple yet effective approach to build multilingual\nspeech-to-text (ST) translation by efficient transfer learning from pretrained\nspeech encoder and text decoder. Our key finding is that a minimalistic LNA\n(LayerNorm and Attention) finetuning can achieve zero-shot crosslingual and\ncross-modality transfer ability by only finetuning less than 10% of the\npretrained parameters. This enables effectively leveraging large pretrained\nmodels with low training cost. Using wav2vec 2.0 for acoustic modeling, and\nmBART for multilingual text generation, our approach advanced the new\nstate-of-the-art for 34 translation directions (and surpassing cascaded ST for\n23 of them) on large-scale multilingual ST benchmark CoVoST 2 (+6.4 BLEU on\naverage across 15 En-X directions and +5.1 BLEU on average across 19 X-En\ndirections). Our approach demonstrates strong zero-shot performance in a\nmany-to-many multilingual model (+5.7 BLEU on average across 18 non-English\ndirections), making it an appealing approach for attaining high-quality speech\ntranslation with improved parameter and data efficiency.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:15:08 GMT"},{"version":"v2","created":"Tue, 8 Dec 2020 07:25:28 GMT"},{"version":"v3","created":"Thu, 31 Dec 2020 05:48:49 GMT"},{"version":"v4","created":"Sat, 2 Jan 2021 08:16:21 GMT"}],"update_date":"2021-01-05"}
{"id":"2010.12830","submitter":"Timoth\\'ee B\\'enard","authors":"Timoth\\'ee B\\'enard","title":"Drift of random walks on abelian covers of finite volume homogeneous\n  spaces","comments":"28 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $G$ be a connected simple real Lie group, $\\Lambda_{0}\\subseteq G$ a\nlattice and $\\Lambda \\unlhd \\Lambda_{0}$ a normal subgroup such that\n$\\Lambda_{0}/\\Lambda\\simeq \\mathbb{Z}^d$. We study the drift of a random walk\non the $\\mathbb{Z}^d$-cover $\\Lambda\\backslash G$ of the finite volume\nhomogeneous space $\\Lambda_{0}\\backslash G$. This walk is defined by a\nZariski-dense compactly supported probability measure $\\mu$ on $G$. We first\nassume the covering map $\\Lambda\\backslash G\\rightarrow \\Lambda_{0}\\backslash\nG$ does not unfold any cusp of $\\Lambda_{0}\\backslash G$ and compute the drift\nat \\emph{every} starting point. Then we remove this assumption and describe the\ndrift almost everywhere. The case of hyperbolic manifolds of dimension 2 stands\nout with non-converging type behaviors. The recurrence of the trajectories is\nalso characterized in this context.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:16:05 GMT"},{"version":"v2","created":"Tue, 22 Dec 2020 21:50:13 GMT"},{"version":"v3","created":"Sat, 18 Dec 2021 09:52:18 GMT"}],"update_date":"2021-12-21"}
{"id":"2010.12831","submitter":"Liunian Harold Li","authors":"Liunian Harold Li, Haoxuan You, Zhecan Wang, Alireza Zareian, Shih-Fu\n  Chang, Kai-Wei Chang","title":"Unsupervised Vision-and-Language Pre-training Without Parallel Images\n  and Captions","comments":"NAACL 2021 Camera Ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained contextual vision-and-language (V&L) models have achieved\nimpressive performance on various benchmarks. However, existing models require\na large amount of parallel image-caption data for pre-training. Such data are\ncostly to collect and require cumbersome curation. Inspired by unsupervised\nmachine translation, we investigate if a strong V&L representation model can be\nlearned through unsupervised pre-training without image-caption corpora. In\nparticular, we propose to conduct ``mask-and-predict'' pre-training on\ntext-only and image-only corpora and introduce the object tags detected by an\nobject recognition model as anchor points to bridge two modalities. We find\nthat such a simple approach achieves performance close to a model pre-trained\nwith aligned data, on four English V&L benchmarks. Our work challenges the\nwidely held notion that aligned data is necessary for V&L pre-training, while\nsignificantly reducing the amount of supervision needed for V&L models.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:17:54 GMT"},{"version":"v2","created":"Sun, 11 Apr 2021 23:54:25 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12832","submitter":"Yujie Wang","authors":"Yi Xing, Jie Zheng, Jindong Li, Yixin Cao, Wei Pan, Jie Zhang and\n  Yujie Wang","title":"X-ray tomography investigation of cyclically sheared granular materials","comments":"26 pages, 4 figures","journal-ref":"Phys. Rev. Lett. 126, 048002 (2021)","doi":"10.1103/PhysRevLett.126.048002","report-no":null,"categories":"cond-mat.soft cond-mat.dis-nn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We perform combined X-ray tomography and shear force measurements on a\ncyclically sheared granular system with highly transient behaviors, and obtain\nthe evolution of microscopic structures and the macroscopic shear force during\nthe shear cycle. We explain the macroscopic behaviors of the system based on\nmicroscopic processes, including the particle level structural rearrangement\nand frictional contact variation. Specifically, we show how contact friction\ncan induce large structural fluctuations and cause significant shear dilatancy\neffect for granular materials, and we also construct an empirical constitutive\nrelationship for the macroscopic shear force.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:22:04 GMT"}],"update_date":"2021-02-03"}
{"id":"2010.12833","submitter":"Georgia Papacharalampous","authors":"Georgia Papacharalampous, Hristos Tyralis, Simon Michael Papalexiou,\n  Andreas Langousis, Sina Khatami, Elena Volpi, Salvatore Grimaldi","title":"Global-scale massive feature extraction from monthly hydroclimatic time\n  series: Statistical characterizations, spatial patterns and hydrological\n  similarity","comments":null,"journal-ref":"Science of the Total Environment 767 (2021) 144612","doi":"10.1016/j.scitotenv.2020.144612","report-no":null,"categories":"stat.AP stat.CO stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Hydroclimatic time series analysis focuses on a few feature types (e.g.,\nautocorrelations, trends, extremes), which describe a small portion of the\nentire information content of the observations. Aiming to exploit a larger part\nof the available information and, thus, to deliver more reliable results (e.g.,\nin hydroclimatic time series clustering contexts), here we approach\nhydroclimatic time series analysis differently, i.e., by performing massive\nfeature extraction. In this respect, we develop a big data framework for\nhydroclimatic variable behaviour characterization. This framework relies on\napproximately 60 diverse features and is completely automatic (in the sense\nthat it does not depend on the hydroclimatic process at hand). We apply the new\nframework to characterize mean monthly temperature, total monthly precipitation\nand mean monthly river flow. The applications are conducted at the global scale\nby exploiting 40-year-long time series originating from over 13 000 stations.\nWe extract interpretable knowledge on seasonality, trends, autocorrelation,\nlong-range dependence and entropy, and on feature types that are met less\nfrequently. We further compare the examined hydroclimatic variable types in\nterms of this knowledge and, identify patterns related to the spatial\nvariability of the features. For this latter purpose, we also propose and\nexploit a hydroclimatic time series clustering methodology. This new\nmethodology is based on Breiman's random forests. The descriptive and\nexploratory insights gained by the global-scale applications prove the\nusefulness of the adopted feature compilation in hydroclimatic contexts.\nMoreover, the spatially coherent patterns characterizing the clusters delivered\nby the new methodology build confidence in its future exploitation...\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:27:17 GMT"},{"version":"v2","created":"Fri, 15 Jan 2021 23:31:22 GMT"}],"update_date":"2021-01-19"}
{"id":"2010.12834","submitter":"Saadia Gabriel","authors":"Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, Jianfeng Gao","title":"GO FIGURE: A Meta Evaluation of Factuality in Summarization","comments":"ACL 2021 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While neural language models can generate text with remarkable fluency and\ncoherence, controlling for factual correctness in generation remains an open\nresearch question. This major discrepancy between the surface-level fluency and\nthe content-level correctness of neural generation has motivated a new line of\nresearch that seeks automatic metrics for evaluating the factuality of machine\ntext. In this paper, we introduce GO FIGURE, a meta-evaluation framework for\nevaluating factuality evaluation metrics. We propose five necessary and\nintuitive conditions to evaluate factuality metrics on diagnostic factuality\ndata across three different summarization tasks. Our benchmark analysis on ten\nfactuality metrics reveals that our meta-evaluation framework provides a robust\nand efficient evaluation that is extensible to multiple types of factual\nconsistency and standard generation metrics, including QA metrics. It also\nreveals that while QA metrics generally improve over standard metrics that\nmeasure factuality across domains, performance is highly dependent on the way\nin which questions are generated.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:30:20 GMT"},{"version":"v2","created":"Sat, 5 Jun 2021 18:21:36 GMT"}],"update_date":"2021-06-08"}
{"id":"2010.12835","submitter":"Imran Akhtar","authors":"Muhammad Sufyan, Hamayun Farooq, Imran Akhtar and Zafar Bangash","title":"Pressure Mode Decomposition Analysis of the Flow past a Cross-flow\n  Oscillating Circular Cylinder","comments":"7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CE cs.NA math.NA physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Proper orthogonal decomposition (POD) is often employed in developing\nreduced-order models (ROM) in fluid flows for design, control, and\noptimization. Contrary to the usual practice where velocity field is the focus,\nwe apply the POD analysis on the pressure field data obtained from numerical\nsimulations of the flow past stationary and oscillating cylinders. Since\npressure mainly contributes to the hydrodynamic forces acting on the structure,\nwe compute the pressure POD modes on the cylinder surface oscillating in\nlock-in and lock-out regions. These modes are then dissected into sine and\ncosine magnitudes to estimate their contribution in the development of pressure\nlift and drag decomposition coefficients, respectively. The key finding of this\nstudy is that more POD modes are required to capture the flow physics in\nnonsynchronous regimes as compared to synchronization case. Engineering\napplication of this study is the development of reduced-order models for\neffective control techniques.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:33:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12836","submitter":"Alexander Fabbri","authors":"Alexander R. Fabbri, Simeng Han, Haoyuan Li, Haoran Li, Marjan\n  Ghazvininejad, Shafiq Joty, Dragomir Radev, Yashar Mehdad","title":"Improving Zero and Few-Shot Abstractive Summarization with Intermediate\n  Fine-tuning and Data Augmentation","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Models pretrained with self-supervised objectives on large text corpora\nachieve state-of-the-art performance on English text summarization tasks.\nHowever, these models are typically fine-tuned on hundreds of thousands of data\npoints, an infeasible requirement when applying summarization to new, niche\ndomains. In this work, we introduce a novel and generalizable method, called\nWikiTransfer, for fine-tuning pretrained models for summarization in an\nunsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained\nmodels on pseudo-summaries, produced from generic Wikipedia data, which contain\ncharacteristics of the target dataset, such as the length and level of\nabstraction of the desired summaries. WikiTransfer models achieve\nstate-of-the-art, zero-shot abstractive summarization performance on the\nCNN-DailyMail dataset and demonstrate the effectiveness of our approach on\nthree additional diverse datasets. These models are more robust to noisy data\nand also achieve better or comparable few-shot performance using 10 and 100\ntraining examples when compared to few-shot transfer from other summarization\ndatasets. To further boost performance, we employ data augmentation via\nround-trip translation as well as introduce a regularization term for improved\nfew-shot transfer. To understand the role of dataset aspects in transfer\nperformance and the quality of the resulting output summaries, we further study\nthe effect of the components of our unsupervised fine-tuning data and analyze\nfew-shot performance using both automatic and human evaluation.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:36:49 GMT"},{"version":"v2","created":"Sun, 11 Apr 2021 13:04:46 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12837","submitter":"Fuyu Lv","authors":"Fuyu Lv, Mengxue Li, Tonglei Guo, Changlong Yu, Fei Sun, Taiwei Jin,\n  Wilfred Ng","title":"XDM: Improving Sequential Deep Matching with Unclicked User Behaviors\n  for Recommender System","comments":"12 pages, accepted by DASFAA2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep learning-based sequential recommender systems have recently attracted\nincreasing attention from both academia and industry. Most of industrial\nEmbedding-Based Retrieval (EBR) system for recommendation share the similar\nideas with sequential recommenders. Among them, how to comprehensively capture\nsequential user interest is a fundamental problem. However, most existing\nsequential recommendation models take as input clicked or purchased behavior\nsequences from user-item interactions. This leads to incomprehensive user\nrepresentation and sub-optimal model performance, since they ignore the\ncomplete user behavior exposure data, i.e., items impressed yet unclicked by\nusers. In this work, we attempt to incorporate and model those unclicked item\nsequences using a new learning approach in order to explore better sequential\nrecommendation technique. An efficient triplet metric learning algorithm is\nproposed to appropriately learn the representation of unclicked items. Our\nmethod can be simply integrated with existing sequential recommendation models\nby a confidence fusion network and further gain better user representation. The\noffline experimental results based on real-world E-commerce data demonstrate\nthe effectiveness and verify the importance of unclicked items in sequential\nrecommendation. Moreover we deploy our new model (named XDM) into EBR of\nrecommender system at Taobao, outperforming the deployed previous generation\nSDM.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:37:04 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 02:50:06 GMT"},{"version":"v3","created":"Thu, 17 Jun 2021 08:03:30 GMT"},{"version":"v4","created":"Thu, 31 Mar 2022 02:46:32 GMT"}],"update_date":"2022-04-01"}
{"id":"2010.12838","submitter":"Junyong Zhang","authors":"Junyong Zhang","title":"Resolvent and spectral measure for Schr\\\"odinger operators on flat\n  Euclidean cones","comments":"13 pages; Comments are welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct the Schwartz kernel of resolvent and spectral measure for\nSchr\\\"odinger operators on the flat Euclidean cone $(X,g)$, where\n$X=C(\\mathbb{S}_\\sigma^1)=(0,\\infty)\\times \\mathbb{S}_\\sigma^1$ is a product\ncone over the circle, $\\mathbb{S}_\\sigma^1=\\R/2\\pi \\sigma\\Z$, with radius\n$\\sigma>0$ and the metric $g=dr^2+r^2 d\\theta^2$. As products, we prove the\ndispersive estimates for the Schr\\\"odinger and half-wave propagators in this\nsetting.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:41:52 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12839","submitter":"Sina Sajjadi","authors":"Sina Sajjadi, Alireza Hashemi, Fakhteh Ghanbarnejad","title":"Social distancing in pedestrian dynamics and its effect on disease\n  spreading","comments":null,"journal-ref":"Phys. Rev. E 104, 014313 (2021)","doi":"10.1103/PhysRevE.104.014313","report-no":null,"categories":"physics.soc-ph q-bio.PE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-pharmaceutical measures such as social distancing, can play an important\nrole to control an epidemic in the absence of vaccinations. In this paper, we\nstudy the impact of social distancing on epidemics for which it is executable.\nWe use a mathematical model combining human mobility and disease spreading. For\nthe mobility dynamics, we design an agent based model consisting of pedestrian\ndynamics with a novel type of force to resemble social distancing in crowded\nsites. For the spreading dynamics, we consider the compartmental SIE dynamics\nplus an indirect transmission with the footprints of the infectious pedestrians\nbeing the contagion factor. We show that the increase in the intensity of\nsocial distancing has a significant effect on the exposure risk. By classifying\nthe population into social distancing abiders and non-abiders, we conclude that\nthe practice of social distancing, even by a minority of potentially infectious\nagents, results in a drastic change on the population exposure risk, but\nreduces the effectiveness of the protocols when practiced by the rest of the\npopulation. Furthermore, we observe that for contagions which the indirect\ntransmission is more significant, the effectiveness of social distancing would\nbe reduced. This study can provide a quantitative guideline for policy-making\non exposure risk reduction.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:47:02 GMT"}],"update_date":"2021-08-04"}
{"id":"2010.12840","submitter":"Amirreza Silani","authors":"Amirreza Silani, Michele Cucuzzella, Jacquelien M. A. Scherpen,\n  Mohammad Javad Yazdanpanah","title":"Output Regulation for Load Frequency Control","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivated by the inadequacy of the existing control strategies for power\nsystems affected by time-varying uncontrolled power injections such as loads\nand the increasingly widespread renewable energy sources, this paper proposes\ntwo control schemes based on the well-known output regulation control\nmethodology. The first one is designed based on the classical output regulation\ntheory and addresses the so-called Load Frequency Control (LFC) problem in\npresence of time-varying uncontrolled power injections. Then, in order to also\nminimize the generation costs, we use an approximate output regulation method\nthat solves numerically only the partial differential equation of the regulator\nequation and propose a controller based on this solution, minimizing an\nappropriate penalty function. An extensive case study shows excellent\nperformance of the proposed control schemes in different and critical\nscenarios.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:49:25 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12841","submitter":"Amit Anand","authors":"Amit Anand, Bikash K. Behera and Prasanta K. Panigrahi","title":"Solving diner's dilemma game, circuit implementation, and verification\n  on IBMQ simulator","comments":null,"journal-ref":"Quantum Information Processing 19, 186 (2020)","doi":"10.1007/s11128-020-02687-5","report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Diners dilemma is one of the most interesting problems in both economic and\ngame theories. Here, we solve this problem for n (number of players) =4 with\nquantum rules and we are able to remove the dilemma of diners between the\nPareto optimal and Nash equilibrium points of the game. We find the quantum\nstrategy that gives maximum payoff for each diner without affecting the payoff\nand strategy of others. We use the quantum principles of superposition and\nentanglement that gives supremacy over any classical strategies. We present the\ncircuit implementation for the game, design it on the IBM quantum simulator and\nverify the strategies in the quantum model.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:49:28 GMT"},{"version":"v2","created":"Mon, 16 Nov 2020 13:32:20 GMT"}],"update_date":"2020-11-17"}
{"id":"2010.12842","submitter":"Nicole M\\\"ucke","authors":"Nicole M\\\"ucke","title":"Stochastic Gradient Descent Meets Distribution Regression","comments":null,"journal-ref":"Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130","doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stochastic gradient descent (SGD) provides a simple and efficient way to\nsolve a broad range of machine learning problems. Here, we focus on\ndistribution regression (DR), involving two stages of sampling: Firstly, we\nregress from probability measures to real-valued responses. Secondly, we sample\nbags from these distributions for utilizing them to solve the overall\nregression problem. Recently, DR has been tackled by applying kernel ridge\nregression and the learning properties of this approach are well understood.\nHowever, nothing is known about the learning properties of SGD for two stage\nsampling problems. We fill this gap and provide theoretical guarantees for the\nperformance of SGD for DR. Our bounds are optimal in a mini-max sense under\nstandard assumptions.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:03:00 GMT"},{"version":"v2","created":"Fri, 5 Mar 2021 16:33:42 GMT"}],"update_date":"2021-03-08"}
{"id":"2010.12843","submitter":"Jakub Slav\\'ik","authors":"Jakub Slav\\'ik","title":"Large and moderate deviations principles and central limit theorem for\n  the stochastic 3D primitive equations with gradient dependent noise","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We establish the large deviations principle (LDP) and the moderate deviations\nprinciple (MDP) and an almost sure version of the central limit theorem (CLT)\nfor the stochastic 3D viscous primitive equations driven by a multiplicative\nwhite noise allowing dependence on spatial gradient of solutions with initial\ndata in $H^2$. The LDP is established using the weak convergence approach of\nBudjihara and Dupuis and uniform version of the stochastic Gronwall lemma. The\nresult corrects a minor technical issue in Z. Dong, J. Zhai, and R. Zhang:\nLarge deviations principles for 3D stochastic primitive equations, J.\nDifferential Equations, 263(5):3110-3146, 2017, and establishes the result for\na more general noise. The MDP is established using a similar argument.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:04:11 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12844","submitter":"Sahisnu Mazumder","authors":"Sahisnu Mazumder, Oriana Riva","title":"FLIN: A Flexible Natural Language Interface for Web Navigation","comments":"Accepted to NAACL-HLT 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  AI assistants can now carry out tasks for users by directly interacting with\nwebsite UIs. Current semantic parsing and slot-filling techniques cannot\nflexibly adapt to many different websites without being constantly re-trained.\nWe propose FLIN, a natural language interface for web navigation that maps user\ncommands to concept-level actions (rather than low-level UI actions), thus\nbeing able to flexibly adapt to different websites and handle their transient\nnature. We frame this as a ranking problem: given a user command and a webpage,\nFLIN learns to score the most relevant navigation instruction (involving action\nand parameter values). To train and evaluate FLIN, we collect a dataset using\nnine popular websites from three domains. Our results show that FLIN was able\nto adapt to new websites in a given domain.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:11:26 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 23:39:18 GMT"}],"update_date":"2021-04-15"}
{"id":"2010.12845","submitter":"S\\'everin Philip","authors":"S\\'everin Philip","title":"Fields of definition of abelian subvarieties","comments":"Comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we study the field of definition of abelian subvarieties\n$B\\subset A_{\\overline{K}}$ for an abelian variety $A$ over a field $K$ of\ncharacteristic $0$. We show that, provided that no isotypic component of\n$A_{\\overline{K}}$ is simple, there are infinitely many abelian subvarieties of\n$A_{\\overline{K}}$ with field of definition $K_A$, the field of definition of\nthe endomorphisms of $A_{\\overline{K}}$. This result combined with earlier work\nof R\\'emond gives an explicit maximum for the minimal degree of a field\nextension over which an abelian subvariety of $A_{\\overline{K}}$ is defined\nwith varying $A$ of fixed dimension and $K$ of characteristic $0$.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:15:32 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12846","submitter":"Fabian Mussnig","authors":"Ben Li, Fabian Mussnig","title":"Metrics and Isometries for Convex Functions","comments":null,"journal-ref":"Int. Math. Res. Not. IMRN 2022, no. 18, 14496-14563","doi":"10.1093/imrn/rnab139","report-no":null,"categories":"math.FA math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a class of functional analogs of the symmetric difference metric\non the space of coercive convex functions on $\\mathbb{R}^n$ with\nfull-dimensional domain. We show that convergence with respect to these metrics\nis equivalent to epi-convergence. Furthermore, we give a full classification of\nall isometries with respect to some of the new metrics. Moreover, we introduce\ntwo new functional analogs of the Hausdorff metric on the spaces of coercive\nconvex functions and super-coercive convex functions, respectively, and prove\nequivalence to epi-convergence.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:19:14 GMT"}],"update_date":"2022-10-04"}
{"id":"2010.12847","submitter":"Abdelhakim Hannousse","authors":"Abdelhakim Hannousse and Salima Yahiouche","title":"Towards Benchmark Datasets for Machine Learning Based Website Phishing\n  Detection: An experimental study","comments":null,"journal-ref":"Engineering Applications of Artificial Intelligence 104C (2021)\n  104347","doi":"10.1016/j.engappai.2021.104347","report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we present a general scheme for building reproducible and\nextensible datasets for website phishing detection. The aim is to (1) enable\ncomparison of systems using different features, (2) overtake the short-lived\nnature of phishing websites, and (3) keep track of the evolution of phishing\ntactics. For experimenting the proposed scheme, we start by adopting a refined\nclassification of website phishing features and we systematically select a\ntotal of 87 commonly recognized ones, we classify them, and we made them\nsubjects for relevance and runtime analysis. We use the collected set of\nfeatures to build a dataset in light of the proposed scheme. Thereafter, we use\na conceptual replication approach to check the genericity of former findings\nfor the built dataset. Specifically, we evaluate the performance of classifiers\non individual classes and on combinations of classes, we investigate different\ncombinations of models, and we explore the effects of filter and wrapper\nmethods on the selection of discriminative features. The results show that\nRandom Forest is the most predictive classifier. Features gathered from\nexternal services are found the most discriminative where features extracted\nfrom web page contents are found less distinguishing. Besides external service\nbased features, some web page content features are found time consuming and not\nsuitable for runtime detection. The use of hybrid features provided the best\naccuracy score of 96.61%. By investigating different feature selection methods,\nfilter-based ranking together with incremental removal of less important\nfeatures improved the performance up to 96.83% better than wrapper methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:21:33 GMT"}],"update_date":"2021-06-22"}
{"id":"2010.12848","submitter":"Neil Walton","authors":"Neil Walton","title":"An Adiabatic Theorem for Policy Tracking with TD-learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We evaluate the ability of temporal difference learning to track the reward\nfunction of a policy as it changes over time. Our results apply a new adiabatic\ntheorem that bounds the mixing time of time-inhomogeneous Markov chains. We\nderive finite-time bounds for tabular temporal difference learning and\n$Q$-learning when the policy used for training changes in time. To achieve\nthis, we develop bounds for stochastic approximation under asynchronous\nadiabatic updates.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:34:53 GMT"},{"version":"v2","created":"Fri, 30 Oct 2020 20:03:20 GMT"}],"update_date":"2020-11-03"}
{"id":"2010.12849","submitter":"Meshkat Rajaee","authors":"Pouya Bakhti, Meshkat Rajaee","title":"Sensitivities of future reactor and long-baseline neutrino experiments\n  to NSI","comments":"14 pages, 8 figures","journal-ref":"Phys. Rev. D 103, 075003 (2021)","doi":"10.1103/PhysRevD.103.075003","report-no":null,"categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the potential of the next generation long-baseline neutrino\nexperiments DUNE and T2HK as well as the upcoming reactor experiment JUNO to\nconstrain Non-Standard Interaction (NSI) parameters. JUNO is going to provide\nthe most precise measurements of solar neutrino oscillation parameters as well\nas determining the neutrino mass ordering. We study how the results of JUNO\ncombined with those of long-baseline neutrino experiments such as DUNE and T2HK\ncan help to determine oscillation parameters and to constrain NSI parameters.\nWe present excluded regions in NSI parameter space, $\\epsilon_{\\alpha \\beta}$\nassuming Standard Model (SM) as the null hypothesis. We further explore the\ncorrelations between the NSI parameters and CP-violation phase.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:37:04 GMT"}],"update_date":"2021-04-14"}
{"id":"2010.12850","submitter":"Semih Yavuz","authors":"Shiyang Li, Semih Yavuz, Kazuma Hashimoto, Jia Li, Tong Niu, Nazneen\n  Rajani, Xifeng Yan, Yingbo Zhou and Caiming Xiong","title":"CoCo: Controllable Counterfactuals for Evaluating Dialogue State\n  Trackers","comments":"ICLR 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dialogue state trackers have made significant progress on benchmark datasets,\nbut their generalization capability to novel and realistic scenarios beyond the\nheld-out conversations is less understood. We propose controllable\ncounterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking\n(DST) models on novel scenarios, i.e., would the system successfully tackle the\nrequest if the user responded differently but still consistently with the\ndialogue flow? CoCo leverages turn-level belief states as counterfactual\nconditionals to produce novel conversation scenarios in two steps: (i)\ncounterfactual goal generation at turn-level by dropping and adding slots\nfollowed by replacing slot values, (ii) counterfactual conversation generation\nthat is conditioned on (i) and consistent with the dialogue flow. Evaluating\nstate-of-the-art DST models on MultiWOZ dataset with CoCo-generated\ncounterfactuals results in a significant performance drop of up to 30.8% (from\n49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used\ntechniques like paraphrasing only affect the accuracy by at most 2%. Human\nevaluations show that COCO-generated conversations perfectly reflect the\nunderlying user goal with more than 95% accuracy and are as human-like as the\noriginal conversations, further strengthening its reliability and promise to be\nadopted as part of the robustness evaluation of DST models.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:39:35 GMT"},{"version":"v2","created":"Fri, 1 Jan 2021 08:22:41 GMT"},{"version":"v3","created":"Fri, 26 Mar 2021 06:35:21 GMT"}],"update_date":"2021-03-29"}
{"id":"2010.12851","submitter":"Daniel Flamm","authors":"Daniel Flamm and Daniel G\\\"unther Grossmann and Michael Jenne and\n  Felix Zimmermann and Jonas Kleiner and Myriam Kaiser and Julian Hellstern and\n  Christoph Tillkorn and Malte Kumkar","title":"Beam shaping for ultrafast materials processing","comments":"Conference Presentation (Photonics West 2019), Review article, 17\n  pages, 16 figures","journal-ref":"Laser Resonators, Microresonators, and Beam Control XXI. Vol.\n  10904. International Society for Optics and Photonics, 2019","doi":"10.1117/12.2511516","report-no":null,"categories":"physics.optics physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The remarkable temporal properties of ultra-short pulsed lasers in\ncombination with novel beam shaping concepts enable the development of\ncompletely new material processing strategies. We demonstrate the benefit of\nemploying focus distributions being tailored in all three spatial dimensions.\nAs example advanced Bessel-like beam profiles, 3D-beam splitting concepts and\nflat-top focus distributions are used to achieve high-quality and efficient\nresults for cutting, welding and drilling applications. Spatial and temporal in\nsitu diagnostics is employed to analyze light-matter interaction and, in\ncombination with flexible digital-holographic beam shaping techniques, to find\nthe optimal beam shape for the respective laser application.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:40:10 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12852","submitter":"Radhika Dua","authors":"Radhika Dua, Sai Srinivas Kancheti and Vineeth N Balasubramanian","title":"Beyond VQA: Generating Multi-word Answer and Rationale to Visual\n  Questions","comments":"MULA Workshop, CVPR 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Visual Question Answering is a multi-modal task that aims to measure\nhigh-level visual understanding. Contemporary VQA models are restrictive in the\nsense that answers are obtained via classification over a limited vocabulary\n(in the case of open-ended VQA), or via classification over a set of\nmultiple-choice-type answers. In this work, we present a completely generative\nformulation where a multi-word answer is generated for a visual query. To take\nthis a step forward, we introduce a new task: ViQAR (Visual Question Answering\nand Reasoning), wherein a model must generate the complete answer and a\nrationale that seeks to justify the generated answer. We propose an end-to-end\narchitecture to solve this task and describe how to evaluate it. We show that\nour model generates strong answers and rationales through qualitative and\nquantitative evaluation, as well as through a human Turing Test.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:44:50 GMT"},{"version":"v2","created":"Thu, 17 Jun 2021 09:44:12 GMT"}],"update_date":"2021-06-18"}
{"id":"2010.12853","submitter":"Rodolfo Ostilla-M\\'onico","authors":"V. Jeganathan, K. Alba and R. Ostilla-M\\'onico","title":"Controlling secondary flows in Taylor-Couette flow using stress-free\n  boundary conditions","comments":"JFM in press","journal-ref":null,"doi":"10.1017/jfm.2021.534","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Taylor-Couette (TC) flow, the flow between two independently rotating and\nco-axial cylinders is commonly used as a canonical model for shear flows.\nUnlike plane Couette, pinned secondary flows can be found in TC flow. These are\nknown as Taylor rolls and drastically affect the flow behaviour. We study the\npossibility of modifying these secondary structures using patterns of\nstress-free and no-slip boundary conditions on the inner cylinder. For this, we\nperform direct numerical simulations of narrow-gap TC flow with pure inner\ncylinder rotation at four different shear Reynolds numbers up to $Re_s=3\\times\n10^4$. We find that one-dimensional azimuthal patterns do not have a\nsignificant effect on the flow topology, and that the resulting torque is a\nlarge fraction ($\\sim80-90\\%$) of torque in the fully no-slip case.\nOne-dimensional axial patterns decrease the torque more, and for certain\npattern frequency disrupt the rolls by interfering with the existing Reynolds\nstresses that generate secondary structures. For $Re\\geq 10^4$, this disruption\nleads to a smaller torque than what would be expected from simple boundary\nlayer effects and the resulting effective slip length and slip velocity. We\nfind that two-dimensional checkerboard patterns have similar behaviour to\nazimuthal patterns and do not affect the flow or the torque substantially, but\ntwo-dimensional spiral inhomogeneities can move around the pinned secondary\nflows as they induce persistent axial velocities. We quantify the roll's\nmovement for various angles and the widths of the spiral pattern, and find a\nnon-monotonic behaviour as a function of pattern angle and pattern frequency.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:52:58 GMT"},{"version":"v2","created":"Wed, 9 Jun 2021 21:18:48 GMT"},{"version":"v3","created":"Thu, 17 Jun 2021 20:12:07 GMT"}],"update_date":"2021-07-28"}
{"id":"2010.12854","submitter":"Tushar Khot","authors":"Shih-Ting Lin and Ashish Sabharwal and Tushar Khot","title":"ReadOnce Transformers: Reusable Representations of Text for Transformers","comments":"Accepted to ACL 2021(Camera Ready)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present ReadOnce Transformers, an approach to convert a transformer-based\nmodel into one that can build an information-capturing, task-independent, and\ncompressed representation of text. The resulting representation is reusable\nacross different examples and tasks, thereby requiring a document shared across\nmany examples or tasks to only be \\emph{read once}. This leads to faster\ntraining and evaluation of models. Additionally, we extend standard\ntext-to-text transformer models to Representation+Text-to-text models, and\nevaluate on multiple downstream tasks: multi-hop QA, abstractive QA, and\nlong-document summarization. Our one-time computed representation results in a\n2x-5x speedup compared to standard text-to-text models, while the compression\nalso allows existing language models to handle longer documents without the\nneed for designing new pre-trained models.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:53:16 GMT"},{"version":"v2","created":"Tue, 3 Aug 2021 18:33:45 GMT"}],"update_date":"2021-08-05"}
{"id":"2010.12855","submitter":"Benjamin Seeger","authors":"Pierre Cardaliaguet and Benjamin Seeger","title":"H\\\"older regularity of Hamilton-Jacobi equations with stochastic forcing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We obtain space-time H\\\"older regularity estimates for solutions of first-\nand second-order Hamilton-Jacobi equations perturbed with an additive\nstochastic forcing term. The bounds depend only on the growth of the\nHamiltonian in the gradient and on the regularity of the stochastic\ncoefficients, in a way that is invariant with respect to a hyperbolic scaling.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:00:56 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 05:23:12 GMT"},{"version":"v3","created":"Mon, 1 Mar 2021 16:50:12 GMT"}],"update_date":"2021-03-02"}
{"id":"2010.12856","submitter":"Mohsen Kian","authors":"Mohsen Kian and Yuki Seo","title":"Jointly convex mappings related to the Lieb's functional and Minkowski\n  type operator inequalities","comments":null,"journal-ref":"Analysis and Mathematical Physics-2021","doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Employing the notion of operator log-convexity, we study joint concavity$/$\nconvexity of multivariable operator functions: $(A,B)\\mapsto F(A,B)=h\\left[\n\\Phi(f(A))\\ \\sigma\\ \\Psi(g(B))\\right]$, where $\\Phi$ and $\\Psi$ are positive\nlinear maps and $\\sigma$ is an operator mean. As applications, we prove jointly\nconcavity$/$convexity of matrix trace functions $\\Tr\\left\\{ F(A,B)\\right\\}$.\nMoreover, considering positive multi-linear mappings in $F(A,B)$, our study of\nthe joint concavity$/$ convexity of $(A_1,\\cdots,A_k)\\mapsto h\\left[\n\\Phi(f(A_1),\\cdots,f(A_k))\\right]$ provides some generalizations and complement\nto results of Ando and Lieb concerning the concavity$/$ convexity of maps\ninvolving tensor product. In addition, we present Minkowski type operator\ninequalities for a unial positive linear map, which is an operator version of\nMinkowski type matrix trace inequalities under a more general setting than\nCarlen and Lieb, Bekjan, and Ando and Hiai.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:02:29 GMT"}],"update_date":"2021-03-05"}
{"id":"2010.12857","submitter":"William McCorkindale Mr.","authors":"William McCorkindale, Carl Poelking, Alpha A. Lee","title":"Investigating 3D Atomic Environments for Enhanced QSAR","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM cs.LG physics.comp-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Predicting bioactivity and physical properties of molecules is a longstanding\nchallenge in drug design. Most approaches use molecular descriptors based on a\n2D representation of molecules as a graph of atoms and bonds, abstracting away\nthe molecular shape. A difficulty in accounting for 3D shape is in designing\nmolecular descriptors can precisely capture molecular shape while remaining\ninvariant to rotations/translations. We describe a novel alignment-free 3D QSAR\nmethod using Smooth Overlap of Atomic Positions (SOAP), a well-established\nformalism developed for interpolating potential energy surfaces. We show that\nthis approach rigorously describes local 3D atomic environments to compare\nmolecular shapes in a principled manner. This method performs competitively\nwith traditional fingerprint-based approaches as well as state-of-the-art graph\nneural networks on pIC$_{50}$ ligand-binding prediction in both random and\nscaffold split scenarios. We illustrate the utility of SOAP descriptors by\nshowing that its inclusion in ensembling diverse representations statistically\nimproves performance, demonstrating that incorporating 3D atomic environments\ncould lead to enhanced QSAR for cheminformatics.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:04:48 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12858","submitter":"Benjamin Muller","authors":"Benjamin Muller and Antonis Anastasopoulos and Beno\\^it Sagot and\n  Djam\\'e Seddah","title":"When Being Unseen from mBERT is just the Beginning: Handling New\n  Languages With Multilingual Language Models","comments":"Accepted at NAACL-HLT 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Transfer learning based on pretraining language models on a large amount of\nraw data has become a new norm to reach state-of-the-art performance in NLP.\nStill, it remains unclear how this approach should be applied for unseen\nlanguages that are not covered by any available large-scale multilingual\nlanguage model and for which only a small amount of raw data is generally\navailable. In this work, by comparing multilingual and monolingual models, we\nshow that such models behave in multiple ways on unseen languages. Some\nlanguages greatly benefit from transfer learning and behave similarly to\nclosely related high resource languages whereas others apparently do not.\nFocusing on the latter, we show that this failure to transfer is largely\nrelated to the impact of the script used to write such languages.\nTransliterating those languages improves very significantly the ability of\nlarge-scale multilingual language models on downstream tasks.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:15:03 GMT"},{"version":"v2","created":"Sat, 17 Apr 2021 09:56:40 GMT"}],"update_date":"2021-04-20"}
{"id":"2010.12859","submitter":"Soufiane Hayou","authors":"Soufiane Hayou, Eugenio Clerico, Bobby He, George Deligiannidis,\n  Arnaud Doucet, Judith Rousseau","title":"Stable ResNet","comments":"43 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep ResNet architectures have achieved state of the art performance on many\ntasks. While they solve the problem of gradient vanishing, they might suffer\nfrom gradient exploding as the depth becomes large (Yang et al. 2017).\nMoreover, recent results have shown that ResNet might lose expressivity as the\ndepth goes to infinity (Yang et al. 2017, Hayou et al. 2019). To resolve these\nissues, we introduce a new class of ResNet architectures, called Stable ResNet,\nthat have the property of stabilizing the gradient while ensuring expressivity\nin the infinite depth limit.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:27:24 GMT"},{"version":"v2","created":"Thu, 18 Mar 2021 17:27:53 GMT"}],"update_date":"2021-03-19"}
{"id":"2010.12860","submitter":"Giovanni Lapenta","authors":"Giovanni Lapenta and Jean Berchem and Mostafa El Alaoui and Raymond\n  Walker","title":"Turbulent energization of electron power law tails during magnetic\n  reconnection","comments":"6 figures. Ti appear on Physical Review Letters","journal-ref":null,"doi":"10.1103/PhysRevLett.125.225101","report-no":null,"categories":"physics.plasm-ph astro-ph.HE physics.space-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Earth's magnetotail is an excellent laboratory to study the interplay of\nreconnection and turbulence in determining electron energization. The process\nof formation of a power law tail during turbulent reconnection is a documented\nfact still in need of a comprehensive explanation. We conduct a massively\nparallel particle in cell 3D simulation and use enhanced statistical resolution\nof the high energy range of the particle velocities to study how reconnection\ncreates the conditions for the tail to be formed. The process is not direct\nacceleration by the coherent, laminar, reconnection-generated electric field.\nRather, reconnection causes turbulent outflows where energy exchange is\ndominated by a highly non-gaussian distribution of fluctuations. Electron\nenergization is diffuse throughout the entire reconnection outflow but it is\nheightened by regions of intensified magnetic field such as dipolarization\nfronts traveling towards Earth.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:30:23 GMT"}],"update_date":"2020-12-30"}
{"id":"2010.12861","submitter":"Jye Luen Lee","authors":"Syuan-Hao Sie, Jye-Luen Lee, Yi-Ren Chen, Chih-Cheng Lu, Chih-Cheng\n  Hsieh, Meng-Fan Chang, Kea-Tiong Tang","title":"MARS: Multi-macro Architecture SRAM CIM-Based Accelerator with\n  Co-designed Compressed Neural Networks","comments":"IEEE Transactions on Computer-Aided Design of Integrated Circuits and\n  Systems 2021","journal-ref":null,"doi":"10.1109/TCAD.2021.3082107","report-no":null,"categories":"cs.AR cs.ET cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Convolutional neural networks (CNNs) play a key role in deep learning\napplications. However, the large storage overheads and the substantial\ncomputation cost of CNNs are problematic in hardware accelerators.\nComputing-in-memory (CIM) architecture has demonstrated great potential to\neffectively compute large-scale matrix-vector multiplication. However, the\nintensive multiply and accumulation (MAC) operations executed at the crossbar\narray and the limited capacity of CIM macros remain bottlenecks for further\nimprovement of energy efficiency and throughput. To reduce computation costs,\nnetwork pruning and quantization are two widely studied compression methods to\nshrink the model size. However, most of the model compression algorithms can\nonly be implemented in digital-based CNN accelerators. For implementation in a\nstatic random access memory (SRAM) CIM-based accelerator, the model compression\nalgorithm must consider the hardware limitations of CIM macros, such as the\nnumber of word lines and bit lines that can be turned on at the same time, as\nwell as how to map the weight to the SRAM CIM macro. In this study, a software\nand hardware co-design approach is proposed to design an SRAM CIM-based CNN\naccelerator and an SRAM CIM-aware model compression algorithm. To lessen the\nhigh-precision MAC required by batch normalization (BN), a quantization\nalgorithm that can fuse BN into the weights is proposed. Furthermore, to reduce\nthe number of network parameters, a sparsity algorithm that considers a CIM\narchitecture is proposed. Last, MARS, a CIM-based CNN accelerator that can\nutilize multiple SRAM CIM macros as processing units and support a sparsity\nneural network, is proposed.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:31:49 GMT"},{"version":"v2","created":"Tue, 25 May 2021 05:38:22 GMT"}],"update_date":"2021-05-26"}
{"id":"2010.12862","submitter":"Mustafa Kishk","authors":"Ainur Zhaikhan, Mustafa A. Kishk, Hesham ElSawy, and Mohamed-Slim\n  Alouini","title":"Safeguarding the IoT from Malware Epidemics: A Percolation Theory\n  Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The upcoming Internet of things (IoT) is foreseen to encompass massive\nnumbers of connected devices, smart objects, and cyber-physical systems. Due to\nthe large-scale and massive deployment of devices, it is deemed infeasible to\nsafeguard 100% of the devices with state-of-the-art security countermeasures.\nHence, large-scale IoT has inevitable loopholes for network intrusion and\nmalware infiltration. Even worse, exploiting the high density of devices and\ndirect wireless connectivity, malware infection can stealthily propagate\nthrough susceptible (i.e., unsecured) devices and form an epidemic outbreak\nwithout being noticed to security administration. A malware outbreak enables\nadversaries to compromise large population of devices, which can be exploited\nto launch versatile cyber and physical malicious attacks. In this context, we\nutilize spatial firewalls, to safeguard the IoT from malware outbreak. In\nparticular, spatial firewalls are computationally capable devices equipped with\nstate-of-the-art security and anti-malware programs that are spatially deployed\nacross the network to filter the wireless traffic in order to detect and thwart\nmalware propagation. Using tools from percolation theory, we prove that there\nexists a critical density of spatial firewalls beyond which malware outbreak is\nimpossible. This, in turns, safeguards the IoT from malware epidemics\nregardless of the infection/treatment rates. To this end, a tractable upper\nbound for the critical density of spatial firewalls is obtained. Furthermore,\nwe characterize the relative communications ranges of the spatial firewalls and\nIoT devices to ensure secure network connectivity. The percentage of devices\nsecured by the firewalls is also characterized.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:33:25 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12863","submitter":"Javlon Rayimbaev Javlon","authors":"Javlon Rayimbaev, Pulat Tadjimuratov, Ahmadjon Abdujabbarov, Bobomurat\n  Ahmedov, Malika Khudoyberdieva","title":"Dynamics of test particles around regular black holes in modified\n  gravity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the work, we have presented detailed analyses of the event horizon and\ncurvature properties of spacetime around a regular black hole in modified\ngravity so-called regular MOG black hole. The motion of neutral, electrically\ncharged and magnetized particles with magnetic dipole moment, in the close\nenvironment of the regular MOG black hole immersed in an external\nasymptotically uniform magnetic field has been also explored. Through the study\non the motion of the neutral test particle, we have obtained that the positive\n(negative) values of the MOG parameter mimic the spin of a rotating Kerr black\nhole giving the same values for innermost stable pro-grade (retrograde) orbits\nof the particles in the range of the spin parameter $a/M \\in(-0.4125, \\\n0.6946)$. The efficiency of energy release from the accretion disk by the\nNovikov-Thorne model has been calculated and shown that the efficiency is\nlinearly proportional to the increase of the MOG parameter $\\alpha$, and\nexceeds up to 15 \\% at the critical limiting value of the MOG parameter\n$\\alpha_{\\rm cr}$. The study of the charged particles dynamics has shown that\ninnermost stable circular orbits (ISCOs) of the particle increases with the\nincrease of the MOG parameter, while the increase of cyclotron frequency being\nresponsible to the magnetic interaction causes the decrease of the latter.\nMoreover, the dynamics of magnetic dipoles has shown that the increase of the\nMOG and the magnetic coupling parameters lead to an increase of the inner\nradius and the width of the accretion disk consisting of magnetized particles.\nFinally, we have focused on showing the range of values of the magnetic\ncoupling parameter causing the orbits to be stable.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:34:49 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12864","submitter":"Xisen Jin","authors":"Xisen Jin, Francesco Barbieri, Brendan Kennedy, Aida Mostafazadeh\n  Davani, Leonardo Neves, Xiang Ren","title":"On Transferability of Bias Mitigation Effects in Language Model\n  Fine-Tuning","comments":"14 pages; Accepted at NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fine-tuned language models have been shown to exhibit biases against\nprotected groups in a host of modeling tasks such as text classification and\ncoreference resolution. Previous works focus on detecting these biases,\nreducing bias in data representations, and using auxiliary training objectives\nto mitigate bias during fine-tuning. Although these techniques achieve bias\nreduction for the task and domain at hand, the effects of bias mitigation may\nnot directly transfer to new tasks, requiring additional data collection and\ncustomized annotation of sensitive attributes, and re-evaluation of appropriate\nfairness metrics. We explore the feasibility and benefits of upstream bias\nmitigation (UBM) for reducing bias on downstream tasks, by first applying bias\nmitigation to an upstream model through fine-tuning and subsequently using it\nfor downstream fine-tuning. We find, in extensive experiments across hate\nspeech detection, toxicity detection, occupation prediction, and coreference\nresolution tasks over various bias factors, that the effects of UBM are indeed\ntransferable to new downstream tasks or domains via fine-tuning, creating less\nbiased downstream models than directly fine-tuning on the downstream task or\ntransferring from a vanilla upstream model. Though challenges remain, we show\nthat UBM promises more efficient and accessible bias mitigation in LM\nfine-tuning.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:36:11 GMT"},{"version":"v2","created":"Sun, 11 Apr 2021 23:34:33 GMT"}],"update_date":"2021-04-13"}
{"id":"2010.12865","submitter":"Jiajin Li","authors":"Jiajin Li, Caihua Chen, Anthony Man-Cho So","title":"Fast Epigraphical Projection-based Incremental Algorithms for\n  Wasserstein Distributionally Robust Support Vector Machine","comments":"Accepted by NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Wasserstein \\textbf{D}istributionally \\textbf{R}obust \\textbf{O}ptimization\n(DRO) is concerned with finding decisions that perform well on data that are\ndrawn from the worst-case probability distribution within a Wasserstein ball\ncentered at a certain nominal distribution. In recent years, it has been shown\nthat various DRO formulations of learning models admit tractable convex\nreformulations. However, most existing works propose to solve these convex\nreformulations by general-purpose solvers, which are not well-suited for\ntackling large-scale problems. In this paper, we focus on a family of\nWasserstein distributionally robust support vector machine (DRSVM) problems and\npropose two novel epigraphical projection-based incremental algorithms to solve\nthem. The updates in each iteration of these algorithms can be computed in a\nhighly efficient manner. Moreover, we show that the DRSVM problems considered\nin this paper satisfy a H\\\"olderian growth condition with explicitly determined\ngrowth exponents. Consequently, we are able to establish the convergence rates\nof the proposed incremental algorithms. Our numerical results indicate that the\nproposed methods are orders of magnitude faster than the state-of-the-art, and\nthe performance gap grows considerably as the problem size increases.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:42:27 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12866","submitter":"Sungbin Lim","authors":"Kyungjae Lee and Hongjun Yang and Sungbin Lim and Songhwai Oh","title":"Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed\n  Rewards","comments":"38 pages, 4 figures. Accepted for NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider stochastic multi-armed bandits (MABs) with\nheavy-tailed rewards, whose $p$-th moment is bounded by a constant $\\nu_{p}$\nfor $1<p\\leq2$. First, we propose a novel robust estimator which does not\nrequire $\\nu_{p}$ as prior information, while other existing robust estimators\ndemand prior knowledge about $\\nu_{p}$. We show that an error probability of\nthe proposed estimator decays exponentially fast. Using this estimator, we\npropose a perturbation-based exploration strategy and develop a generalized\nregret analysis scheme that provides upper and lower regret bounds by revealing\nthe relationship between the regret and the cumulative density function of the\nperturbation. From the proposed analysis scheme, we obtain gap-dependent and\ngap-independent upper and lower regret bounds of various perturbations. We also\nfind the optimal hyperparameters for each perturbation, which can achieve the\nminimax optimal regret bound with respect to total rounds. In simulation, the\nproposed estimator shows favorable performance compared to existing robust\nestimators for various $p$ values and, for MAB problems, the proposed\nperturbation strategy outperforms existing exploration methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:44:02 GMT"},{"version":"v2","created":"Wed, 27 Oct 2021 07:10:55 GMT"}],"update_date":"2021-10-28"}
{"id":"2010.12867","submitter":"Junaid ur Rehman","authors":"Syed Muhammad Kazim and Ahmad Farooq and Junaid ur Rehman and Hyundong\n  Shin","title":"Adaptive quantum state tomography with iterative particle filtering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Several Bayesian estimation based heuristics have been developed to perform\nquantum state tomography (QST). Their ability to quantify uncertainties using\nregion estimators and include a priori knowledge of the experimentalists makes\nthis family of methods an attractive choice for QST. However, specialized\ntechniques for pure states do not work well for mixed states and vice versa. In\nthis paper, we present an adaptive particle filter (PF) based QST protocol\nwhich improves the scaling of fidelity compared to nonadaptive Bayesian schemes\nfor arbitrary multi-qubit states. This is due to the protocol's unabating\nperseverance to find the states's diagonal bases and more systematic handling\nof enduring problems in popular PF methods relating to the subjectivity of\ninformative priors and the invalidity of particles produced by resamplers.\nNumerical examples and implementation on IBM quantum devices demonstrate\nimproved performance for arbitrary quantum states and the application readiness\nof our proposed scheme.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:00:33 GMT"},{"version":"v2","created":"Wed, 15 Sep 2021 07:17:00 GMT"}],"update_date":"2021-09-16"}
{"id":"2010.12868","submitter":"Yongchang Hao","authors":"Yongchang Hao, Shilin He, Wenxiang Jiao, Zhaopeng Tu, Michael Lyu and\n  Xing Wang","title":"Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine\n  Translation","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Non-Autoregressive machine Translation (NAT) models have demonstrated\nsignificant inference speedup but suffer from inferior translation accuracy.\nThe common practice to tackle the problem is transferring the Autoregressive\nmachine Translation (AT) knowledge to NAT models, e.g., with knowledge\ndistillation. In this work, we hypothesize and empirically verify that AT and\nNAT encoders capture different linguistic properties of source sentences.\nTherefore, we propose to adopt Multi-Task learning to transfer the AT knowledge\nto NAT models through encoder sharing. Specifically, we take the AT model as an\nauxiliary task to enhance NAT model performance. Experimental results on WMT14\nEnglish-German and WMT16 English-Romanian datasets show that the proposed\nMulti-Task NAT achieves significant improvements over the baseline NAT models.\nFurthermore, the performance on large-scale WMT19 and WMT20 English-German\ndatasets confirm the consistency of our proposed method. In addition,\nexperimental results demonstrate that our Multi-Task NAT is complementary to\nknowledge distillation, the standard knowledge transfer method for NAT.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:00:58 GMT"},{"version":"v2","created":"Mon, 17 May 2021 07:24:55 GMT"}],"update_date":"2021-05-18"}
{"id":"2010.12869","submitter":"Farhad Merchant","authors":"Suresh Nambi, Salim Ullah, Aditya Lohana, Siva Satyendra Sahoo, Farhad\n  Merchant, Akash Kumar","title":"ExPAN(N)D: Exploring Posits for Efficient Artificial Neural Network\n  Design in FPGA-based Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR cs.AI cs.ET cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent advances in machine learning, in general, and Artificial Neural\nNetworks (ANN), in particular, has made smart embedded systems an attractive\noption for a larger number of application areas. However, the high\ncomputational complexity, memory footprints, and energy requirements of machine\nlearning models hinder their deployment on resource-constrained embedded\nsystems. Most state-of-the-art works have considered this problem by proposing\nvarious low bit-width data representation schemes, optimized arithmetic\noperators' implementations, and different complexity reduction techniques such\nas network pruning. To further elevate the implementation gains offered by\nthese individual techniques, there is a need to cross-examine and combine these\ntechniques' unique features. This paper presents ExPAN(N)D, a framework to\nanalyze and ingather the efficacy of the Posit number representation scheme and\nthe efficiency of fixed-point arithmetic implementations for ANNs. The Posit\nscheme offers a better dynamic range and higher precision for various\napplications than IEEE $754$ single-precision floating-point format. However,\ndue to the dynamic nature of the various fields of the Posit scheme, the\ncorresponding arithmetic circuits have higher critical path delay and resource\nrequirements than the single-precision-based arithmetic units. Towards this\nend, we propose a novel Posit to fixed-point converter for enabling\nhigh-performance and energy-efficient hardware implementations for ANNs with\nminimal drop in the output accuracy. We also propose a modified Posit-based\nrepresentation to store the trained parameters of a network. Compared to an\n$8$-bit fixed-point-based inference accelerator, our proposed implementation\noffers $\\approx46\\%$ and $\\approx18\\%$ reductions in the storage requirements\nof the parameters and energy consumption of the MAC units, respectively.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:02:25 GMT"},{"version":"v2","created":"Tue, 27 Oct 2020 05:28:28 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.12870","submitter":"Ahmed Touati","authors":"Ahmed Touati and Pascal Vincent","title":"Efficient Learning in Non-Stationary Linear Markov Decision Processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study episodic reinforcement learning in non-stationary linear (a.k.a.\nlow-rank) Markov Decision Processes (MDPs), i.e, both the reward and transition\nkernel are linear with respect to a given feature map and are allowed to evolve\neither slowly or abruptly over time. For this problem setting, we propose\nOPT-WLSVI an optimistic model-free algorithm based on weighted least squares\nvalue iteration which uses exponential weights to smoothly forget data that are\nfar in the past. We show that our algorithm, when competing against the best\npolicy at each time, achieves a regret that is upper bounded by\n$\\widetilde{\\mathcal{O}}(d^{5/4}H^2 \\Delta^{1/4} K^{3/4})$ where $d$ is the\ndimension of the feature space, $H$ is the planning horizon, $K$ is the number\nof episodes and $\\Delta$ is a suitable measure of non-stationarity of the MDP.\nMoreover, we point out technical gaps in the study of forgetting strategies in\nnon-stationary linear bandits setting made by previous works and we propose a\nfix to their regret analysis.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:02:45 GMT"},{"version":"v2","created":"Fri, 5 Mar 2021 14:05:08 GMT"},{"version":"v3","created":"Mon, 27 Dec 2021 14:22:39 GMT"}],"update_date":"2021-12-28"}
{"id":"2010.12871","submitter":"Zein Shaheen","authors":"Zein Shaheen, Gerhard Wohlgenannt, Erwin Filtz","title":"Large Scale Legal Text Classification Using Transformer Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large multi-label text classification is a challenging Natural Language\nProcessing (NLP) problem that is concerned with text classification for\ndatasets with thousands of labels. We tackle this problem in the legal domain,\nwhere datasets, such as JRC-Acquis and EURLEX57K labeled with the EuroVoc\nvocabulary were created within the legal information systems of the European\nUnion. The EuroVoc taxonomy includes around 7000 concepts. In this work, we\nstudy the performance of various recent transformer-based models in combination\nwith strategies such as generative pretraining, gradual unfreezing and\ndiscriminative learning rates in order to reach competitive classification\nperformance, and present new state-of-the-art results of 0.661 (F1) for\nJRC-Acquis and 0.754 for EURLEX57K. Furthermore, we quantify the impact of\nindividual steps, such as language model fine-tuning or gradual unfreezing in\nan ablation study, and provide reference dataset splits created with an\niterative stratification algorithm.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:03:01 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12872","submitter":"Aaron Chan","authors":"Mrigank Raman, Aaron Chan, Siddhant Agarwal, Peifeng Wang, Hansen\n  Wang, Sungchul Kim, Ryan Rossi, Handong Zhao, Nedim Lipka, Xiang Ren","title":"Learning to Deceive Knowledge Graph Augmented Models via Targeted\n  Perturbation","comments":"13 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge graphs (KGs) have helped neural models improve performance on\nvarious knowledge-intensive tasks, like question answering and item\nrecommendation. By using attention over the KG, such KG-augmented models can\nalso \"explain\" which KG information was most relevant for making a given\nprediction. In this paper, we question whether these models are really behaving\nas we expect. We show that, through a reinforcement learning policy (or even\nsimple heuristics), one can produce deceptively perturbed KGs, which maintain\nthe downstream performance of the original KG while significantly deviating\nfrom the original KG's semantics and structure. Our findings raise doubts about\nKG-augmented models' ability to reason about KG information and give sensible\nexplanations.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:04:45 GMT"},{"version":"v2","created":"Sun, 29 Nov 2020 21:56:00 GMT"},{"version":"v3","created":"Sat, 2 Jan 2021 10:43:59 GMT"},{"version":"v4","created":"Thu, 21 Jan 2021 07:40:13 GMT"},{"version":"v5","created":"Thu, 18 Mar 2021 05:50:57 GMT"},{"version":"v6","created":"Mon, 3 May 2021 18:38:15 GMT"}],"update_date":"2021-05-05"}
{"id":"2010.12873","submitter":"Jun Yan","authors":"Jun Yan, Mrigank Raman, Aaron Chan, Tianyu Zhang, Ryan Rossi, Handong\n  Zhao, Sungchul Kim, Nedim Lipka, Xiang Ren","title":"Learning Contextualized Knowledge Structures for Commonsense Reasoning","comments":"Accepted to Findings of ACL-IJCNLP 2021. Code and data:\n  https://github.com/INK-USC/HGN","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, knowledge graph (KG) augmented models have achieved noteworthy\nsuccess on various commonsense reasoning tasks. However, KG edge (fact)\nsparsity and noisy edge extraction/generation often hinder models from\nobtaining useful knowledge to reason over. To address these issues, we propose\na new KG-augmented model: Hybrid Graph Network (HGN). Unlike prior methods, HGN\nlearns to jointly contextualize extracted and generated knowledge by reasoning\nover both within a unified graph structure. Given the task input context and an\nextracted KG subgraph, HGN is trained to generate embeddings for the subgraph's\nmissing edges to form a \"hybrid\" graph, then reason over the hybrid graph while\nfiltering out context-irrelevant edges. We demonstrate HGN's effectiveness\nthrough considerable performance gains across four commonsense reasoning\nbenchmarks, plus a user study on edge validness and helpfulness.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:09:16 GMT"},{"version":"v2","created":"Sat, 2 Jan 2021 11:59:06 GMT"},{"version":"v3","created":"Fri, 4 Jun 2021 08:16:35 GMT"}],"update_date":"2021-06-07"}
{"id":"2010.12874","submitter":"Arijit Saha","authors":"Ganesh C. Paul, SK Firoz Islam, Paramita Dutta, Arijit Saha","title":"Signatures of interfacial topological chiral modes via RKKY exchange\n  interaction in Dirac and Weyl systems","comments":"This is the published version","journal-ref":"Phys. Rev. B 103, 115306 (2021)","doi":"10.1103/PhysRevB.103.115306","report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We theoretically investigate the features of Ruderman-Kittel-Kasuya-Yosida\n(RKKY) exchange interaction between two magnetic impurities, mediated by the\ninterfacial bound states inside a domain wall (DW). The latter separates the\ntwo regions with oppositely signed inversion symmetry broken terms in graphene\nand Weyl semimetal. The DW is modelled by a smooth quantum well which hosts a\nnumber of discrete bound states including a pair of gapless, metallic\nzero-energy modes with opposite chiralities. We find clear signatures of these\ninterfacial chiral bound states in spin response (RKKY exchange interaction)\nwhich is robust to the deformation of the quantum well.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:10:44 GMT"},{"version":"v2","created":"Sat, 13 Mar 2021 09:25:31 GMT"}],"update_date":"2021-03-17"}
{"id":"2010.12875","submitter":"Yu Tian","authors":"Yu Tian, Gaofeng Pan, and Mohamed-Slim Alouini","title":"Stochastic Analysis of Cooperative Satellite-UAV Communications","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  In this paper, a dual-hop cooperative satellite-unmanned aerial vehicle (UAV)\ncommunication system including a satellite (S), a group of cluster headers\n(CHs), which are respectively with a group of uniformly distributed UAVs, is\nconsidered. Specifically, these CHs serve as aerial decode-and-forward relays\nto forward the information transmitted by S to UAVs. Moreover, free-space\noptical (FSO) and radio frequency (RF) technologies are respectively adopted\nover S-CH and CH-UAV links to exploit FSO's high directivity over long-distance\ntransmission and RF's omnidirectional coverage ability. The positions of the\nCHs in the 3-dimensional space follow the Mat\\'ern hard-core point processes\ntype-II in which each CH can not be closer to any other ones than a predefined\ndistance. Three different cases over CH-UAV links are considered during the\nperformance modeling: interference-free, interference-dominated, and\ninterference-and-noise cases. Then, the coverage performance of S-CH link and\nthe CH-UAV links under three cases is studied and the closed-form analytical\nexpressions of the coverage probability (CP) over both links are derived. Also,\nthe asymptotic expressions for the CP over S-CH link and CH-UAV link in\ninterference-free case are derived. Finally, numerical results are provided to\nvalidate our proposed analytical models and thus some meaningful conclusions\nare achieved.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:12:03 GMT"},{"version":"v2","created":"Thu, 18 Mar 2021 04:44:11 GMT"}],"update_date":"2021-03-19"}
{"id":"2010.12876","submitter":"Gexin Huang","authors":"Gexin Huang, Jiawen Liang, Ke Liu, Chang Cai, ZhengHui Gu, Feifei Qi,\n  Yuan Qing Li, Zhu Liang Yu and Wei Wu","title":"Electromagnetic Source Imaging via a Data-Synthesis-Based Convolutional\n  Encoder-Decoder Network","comments":"15 pages, 14 figures, and journal","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Electromagnetic source imaging (ESI) requires solving a highly ill-posed\ninverse problem. To seek a unique solution, traditional ESI methods impose\nvarious forms of priors that may not accurately reflect the actual source\nproperties, which may hinder their broad applications. To overcome this\nlimitation, in this paper a novel data-synthesized spatio-temporally\nconvolutional encoder-decoder network method termed DST-CedNet is proposed for\nESI. DST-CedNet recasts ESI as a machine learning problem, where discriminative\nlearning and latent-space representations are integrated in a convolutional\nencoder-decoder network (CedNet) to learn a robust mapping from the measured\nelectroencephalography/magnetoencephalography (E/MEG) signals to the brain\nactivity. In particular, by incorporating prior knowledge regarding dynamical\nbrain activities, a novel data synthesis strategy is devised to generate\nlarge-scale samples for effectively training CedNet. This stands in contrast to\ntraditional ESI methods where the prior information is often enforced via\nconstraints primarily aimed for mathematical convenience. Extensive numerical\nexperiments as well as analysis of a real MEG and Epilepsy EEG dataset\ndemonstrate that DST-CedNet outperforms several state-of-the-art ESI methods in\nrobustly estimating source signals under a variety of source configurations.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:16:11 GMT"},{"version":"v2","created":"Sat, 31 Oct 2020 02:23:42 GMT"},{"version":"v3","created":"Fri, 8 Jan 2021 07:35:58 GMT"},{"version":"v4","created":"Sun, 11 Jul 2021 08:53:24 GMT"},{"version":"v5","created":"Wed, 14 Jul 2021 02:47:17 GMT"},{"version":"v6","created":"Wed, 13 Jul 2022 16:21:58 GMT"}],"update_date":"2022-07-14"}
{"id":"2010.12877","submitter":"Fardin Ghorbani","authors":"Fardin Ghorbani, Javad Shabanpour, Sepideh Monjezi, Hossein Soleimani,\n  Soheil Hashemi, Ali Abdolali","title":"EEGsig: an open-source machine learning-based toolbox for EEG signal\n  processing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the quest to realize a comprehensive EEG signal processing framework, in\nthis paper, we demonstrate a toolbox and graphic user interface, EEGsig, for\nthe full process of EEG signals. Our goal is to provide a comprehensive suite,\nfree and open-source framework for EEG signal processing where the users\nespecially physicians who do not have programming experience can focus on their\npractical requirements to speed up the medical projects. Developed on MATLAB\nsoftware, we have aggregated all the three EEG signal processing steps,\nincluding preprocessing, feature extraction, and classification into EEGsig. In\naddition to a varied list of useful features, in EEGsig, we have implemented\nthree popular classification algorithms (K-NN, SVM, and ANN) to assess the\nperformance of the features. Our experimental results demonstrate that our\nnovel framework for EEG signal processing attained excellent classification\nresults and feature extraction robustness under different machine learning\nclassifier algorithms. Besides, in EEGsig, for selecting the best feature\nextracted, all EEG signal channels can be visible simultaneously; thus, the\neffect of each task on the signal can be visible. We believe that our\nuser-centered MATLAB package is an encouraging platform for novice users as\nwell as offering the highest level of control to expert users\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:18:33 GMT"},{"version":"v2","created":"Thu, 26 Aug 2021 09:41:49 GMT"}],"update_date":"2021-08-27"}
{"id":"2010.12878","submitter":"Benedek Rozemberczki","authors":"Benedek Rozemberczki, Peter Englert, Amol Kapoor, Martin Blais, Bryan\n  Perozzi","title":"Pathfinder Discovery Networks for Neural Message Passing","comments":"Code is available here: https://github.com/benedekrozemberczki/PDN/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work we propose Pathfinder Discovery Networks (PDNs), a method for\njointly learning a message passing graph over a multiplex network with a\ndownstream semi-supervised model. PDNs inductively learn an aggregated weight\nfor each edge, optimized to produce the best outcome for the downstream\nlearning task. PDNs are a generalization of attention mechanisms on graphs\nwhich allow flexible construction of similarity functions between nodes, edge\nconvolutions, and cheap multiscale mixing layers. We show that PDNs overcome\nweaknesses of existing methods for graph attention (e.g. Graph Attention\nNetworks), such as the diminishing weight problem. Our experimental results\ndemonstrate competitive predictive performance on academic node classification\ntasks. Additional results from a challenging suite of node classification\nexperiments show how PDNs can learn a wider class of functions than existing\nbaselines. We analyze the relative computational complexity of PDNs, and show\nthat PDN runtime is not considerably higher than static-graph models. Finally,\nwe discuss how PDNs can be used to construct an easily interpretable attention\nmechanism that allows users to understand information propagation in the graph.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:28:57 GMT"},{"version":"v2","created":"Tue, 16 Feb 2021 22:45:42 GMT"}],"update_date":"2021-02-18"}
{"id":"2010.12879","submitter":"Norman Haussmann","authors":"Norman Haussmann, Martin Zang, Robin Mease, Markus Clemens, Benedikt\n  Schmuelling and Matthias Bolten","title":"Towards Real-Time Magnetic Dosimetry Simulations for Inductive Charging\n  Systems","comments":null,"journal-ref":null,"doi":"10.1108/COMPEL-03-2021-0084","report-no":null,"categories":"cs.CE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The exposure of a human by magneto-quasistatic fields from wireless charging\nsystems is to be determined from magnetic field measurements in near real-time.\nThis requires a fast linear equations solver for the discrete Poisson system of\nthe Co-Simulation Scalar Potential Finite Difference (Co-Sim. SPFD) scheme.\nHere, the use of the AmgX library on NVIDIA GPUs is presented for this task. It\nenables solving the equation system resulting from an ICNIRP recommended human\nvoxel model resolution of 2 mm in less than 0.5 seconds on a single NVIDIA\nTesla V100 GPU.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:32:30 GMT"}],"update_date":"2022-02-17"}
{"id":"2010.12880","submitter":"Simindokht Jahangard","authors":"Mehdi Bonyani, Simindokht Jahangard, Morteza Daneshmand","title":"Persian Handwritten Digit, Character and Word Recognition Using Deep\n  Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Digit, letter and word recognition for a particular script has various\napplications in todays commercial contexts. Nevertheless, only a limited number\nof relevant studies have dealt with Persian scripts. In this paper, deep neural\nnetworks are utilized through various DensNet architectures, as well as the\nXception, are adopted, modified and further boosted through data augmentation\nand test time augmentation, in order to come up with an optical character\nrecognition accounting for the particularities of the Persian language and the\ncorresponding handwritings. Taking advantage of dividing the databases to\ntraining, validation and test sets, as well as k-fold cross validation, the\ncomparison of the proposed method with various state-of-the-art alternatives is\nperformed on the basis of the HODA and Sadri databases, which offer the most\ncomprehensive collection of samples in terms of the various handwriting styles\npossessed by different human beings, as well as different forms each letter may\ntake, which depend on its position within a word. On the HODA database, we\nachieve recognition rates of 99.72% and 89.99% for digits and characters, being\n99.72%, 98.32% and 98.82% for digits, characters and words from the Sadri\ndatabase, respectively.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:42:28 GMT"},{"version":"v2","created":"Sat, 14 Nov 2020 06:20:53 GMT"}],"update_date":"2020-11-17"}
{"id":"2010.12881","submitter":"Arturo Oncevay","authors":"Arturo Oncevay and Kervy Rivas Rojas","title":"Revisiting Neural Language Modelling with Syllables","comments":"5 pages (main paper), 4 pages of Appendix","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Language modelling is regularly analysed at word, subword or character units,\nbut syllables are seldom used. Syllables provide shorter sequences than\ncharacters, they can be extracted with rules, and their segmentation typically\nrequires less specialised effort than identifying morphemes. We reconsider\nsyllables for an open-vocabulary generation task in 20 languages. We use\nrule-based syllabification methods for five languages and address the rest with\na hyphenation tool, which behaviour as syllable proxy is validated. With a\ncomparable perplexity, we show that syllables outperform characters, annotated\nmorphemes and unsupervised subwords. Finally, we also study the overlapping of\nsyllables concerning other subword pieces and discuss some limitations and\nopportunities.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:44:41 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12882","submitter":"Mingyang Chen","authors":"Mingyang Chen, Wen Zhang, Zonggang Yuan, Yantao Jia, Huajun Chen","title":"FedE: Embedding Knowledge Graphs in Federated Setting","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge graphs (KGs) consisting of triples are always incomplete, so it's\nimportant to do Knowledge Graph Completion (KGC) by predicting missing triples.\nMulti-Source KG is a common situation in real KG applications which can be\nviewed as a set of related individual KGs where different KGs contains\nrelations of different aspects of entities. It's intuitive that, for each\nindividual KG, its completion could be greatly contributed by the triples\ndefined and labeled in other ones. However, because of the data privacy and\nsensitivity, a set of relevant knowledge graphs cannot complement each other's\nKGC by just collecting data from different knowledge graphs together.\nTherefore, in this paper, we introduce federated setting to keep their privacy\nwithout triple transferring between KGs and apply it in embedding knowledge\ngraph, a typical method which have proven effective for KGC in the past decade.\nWe propose a Federated Knowledge Graph Embedding framework FedE, focusing on\nlearning knowledge graph embeddings by aggregating locally-computed updates.\nFinally, we conduct extensive experiments on datasets derived from KGE\nbenchmark datasets and results show the effectiveness of our proposed FedE.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:52:05 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12883","submitter":"Bryan Kian Hsiang Low","authors":"Quoc Phong Nguyen, Bryan Kian Hsiang Low, Patrick Jaillet","title":"Variational Bayesian Unlearning","comments":"34th Annual Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Extended version with proofs, 22 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the problem of approximately unlearning a Bayesian model\nfrom a small subset of the training data to be erased. We frame this problem as\none of minimizing the Kullback-Leibler divergence between the approximate\nposterior belief of model parameters after directly unlearning from erased data\nvs. the exact posterior belief from retraining with remaining data. Using the\nvariational inference (VI) framework, we show that it is equivalent to\nminimizing an evidence upper bound which trades off between fully unlearning\nfrom erased data vs. not entirely forgetting the posterior belief given the\nfull data (i.e., including the remaining data); the latter prevents\ncatastrophic unlearning that can render the model useless. In model training\nwith VI, only an approximate (instead of exact) posterior belief given the full\ndata can be obtained, which makes unlearning even more challenging. We propose\ntwo novel tricks to tackle this challenge. We empirically demonstrate our\nunlearning methods on Bayesian models such as sparse Gaussian process and\nlogistic regression using synthetic and real-world datasets.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:53:00 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12884","submitter":"Ximing Lu","authors":"Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra\n  Bhagavatula, Yejin Choi","title":"NeuroLogic Decoding: (Un)supervised Neural Text Generation with\n  Predicate Logic Constraints","comments":"NAACL 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conditional text generation often requires lexical constraints, i.e., which\nwords should or shouldn't be included in the output text. While the dominant\nrecipe for conditional text generation has been large-scale pretrained language\nmodels that are finetuned on the task-specific training data, such models do\nnot learn to follow the underlying constraints reliably, even when supervised\nwith large amounts of task-specific examples.\n  We propose NeuroLogic Decoding, a simple yet effective algorithm that enables\nneural language models -- supervised or not -- to generate fluent text while\nsatisfying complex lexical constraints. Our approach is powerful yet efficient.\nIt handles any set of lexical constraints that is expressible under predicate\nlogic, while its asymptotic runtime is equivalent to conventional beam search.\n  Empirical results on four benchmarks show that NeuroLogic Decoding\noutperforms previous approaches, including algorithms that handle a subset of\nour constraints. Moreover, we find that unsupervised models with NeuroLogic\nDecoding often outperform supervised models with conventional decoding, even\nwhen the latter is based on considerably larger networks. Our results suggest\nthe limit of large-scale neural networks for fine-grained controllable\ngeneration and the promise of inference-time algorithms.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:55:22 GMT"},{"version":"v2","created":"Tue, 20 Apr 2021 18:59:28 GMT"}],"update_date":"2021-04-22"}
{"id":"2010.12885","submitter":"Tong Niu","authors":"Tong Niu, Semih Yavuz, Yingbo Zhou, Nitish Shirish Keskar, Huan Wang,\n  Caiming Xiong","title":"Unsupervised Paraphrasing with Pretrained Language Models","comments":"Accepted at EMNLP 2021 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Paraphrase generation has benefited extensively from recent progress in the\ndesigning of training objectives and model architectures. However, previous\nexplorations have largely focused on supervised methods, which require a large\namount of labeled data that is costly to collect. To address this drawback, we\nadopt a transfer learning approach and propose a training pipeline that enables\npre-trained language models to generate high-quality paraphrases in an\nunsupervised setting. Our recipe consists of task-adaptation, self-supervision,\nand a novel decoding algorithm named Dynamic Blocking (DB). To enforce a\nsurface form dissimilar from the input, whenever the language model emits a\ntoken contained in the source sequence, DB prevents the model from outputting\nthe subsequent source token for the next generation step. We show with\nautomatic and human evaluations that our approach achieves state-of-the-art\nperformance on both the Quora Question Pair (QQP) and the ParaNMT datasets and\nis robust to domain shift between the two datasets of distinct distributions.\nWe also demonstrate that our model transfers to paraphrasing in other languages\nwithout any additional finetuning.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:55:28 GMT"},{"version":"v2","created":"Fri, 10 Sep 2021 20:50:19 GMT"}],"update_date":"2021-09-14"}
{"id":"2010.12886","submitter":"Zhuolin Ye","authors":"Zhuolin Ye, Viktor Holubec","title":"Maximum efficiency of absorption refrigerators at arbitrary cooling\n  power","comments":null,"journal-ref":"Phys. Rev. E 103, 052125 (2021)","doi":"10.1103/PhysRevE.103.052125","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider absorption refrigerators consisting of simultaneously operating\nCarnot-type heat engine and refrigerator. Their maximum efficiency at given\npower (MEGP) is given by the product of MEGPs for the internal engine and\nrefrigerator. The only subtlety of the derivation lies in the fact that the\nmaximum cooling power of the absorption refrigerator is not limited just by the\nmaximum power of the internal refrigerator but, due to the first law, also by\nthat of the internal engine. As a specific example, we consider the\nsimultaneous absorption refrigerators composed of low-dissipation (LD) heat\nengines and refrigerators, for which the expressions for MEGPs are known. The\nderived expression for maximum efficiency implies bounds on the MEGP of LD\nabsorption refrigerators. It also implies that a slight decrease in power of\nthe absorption refrigerator from its maximum value results in a large nonlinear\nincrease in efficiency observed in heat engines whenever the ratio of maximum\npowers of the internal engine and the refrigerator does not diverge. Otherwise,\nthe increase in efficiency is linear as observed in LD refrigerators. Thus, in\nall practical situations, the efficiency of LD absorption refrigerators\nsignificantly increases when their cooling power is slightly decreased from its\nmaximum.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:56:27 GMT"},{"version":"v2","created":"Mon, 1 Feb 2021 21:38:21 GMT"},{"version":"v3","created":"Thu, 11 Mar 2021 15:25:56 GMT"},{"version":"v4","created":"Mon, 19 Apr 2021 14:48:54 GMT"}],"update_date":"2021-05-20"}
{"id":"2010.12887","submitter":"Jincheng Bai","authors":"Jincheng Bai, Qifan Song, Guang Cheng","title":"Nearly Optimal Variational Inference for High Dimensional Regression\n  with Shrinkage Priors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a variational Bayesian (VB) procedure for high-dimensional linear\nmodel inferences with heavy tail shrinkage priors, such as student-t prior.\nTheoretically, we establish the consistency of the proposed VB method and prove\nthat under the proper choice of prior specifications, the contraction rate of\nthe VB posterior is nearly optimal. It justifies the validity of VB inference\nas an alternative of Markov Chain Monte Carlo (MCMC) sampling. Meanwhile,\ncomparing to conventional MCMC methods, the VB procedure achieves much higher\ncomputational efficiency, which greatly alleviates the computing burden for\nmodern machine learning applications such as massive data analysis. Through\nnumerical studies, we demonstrate that the proposed VB method leads to shorter\ncomputing time, higher estimation accuracy, and lower variable selection error\nthan competitive sparse Bayesian methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:10:27 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12888","submitter":"Sungho Suh","authors":"Sungho Suh and Paul Lukowicz and Yong Oh Lee","title":"Discriminative feature generation for classification of imbalanced data","comments":"Submitted to Pattern Recognition, Elsevier","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The data imbalance problem is a frequent bottleneck in the classification\nperformance of neural networks. In this paper, we propose a novel supervised\ndiscriminative feature generation (DFG) method for a minority class dataset.\nDFG is based on the modified structure of a generative adversarial network\nconsisting of four independent networks: generator, discriminator, feature\nextractor, and classifier. To augment the selected discriminative features of\nthe minority class data by adopting an attention mechanism, the generator for\nthe class-imbalanced target task is trained, and the feature extractor and\nclassifier are regularized using the pre-trained features from a large source\ndata. The experimental results show that the DFG generator enhances the\naugmentation of the label-preserved and diverse features, and the\nclassification results are significantly improved on the target task. The\nfeature generation model can contribute greatly to the development of data\naugmentation methods through discriminative feature generation and supervised\nattention methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:19:05 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12889","submitter":"Alejandro Donaire","authors":"Alejandro Donaire, Luigi Villani, Fanny Ficuciello, Juan Tomassini and\n  Bruno Siciliano","title":"Force and state-feedback control for robots with non-collocated\n  environmental and actuator forces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.SY eess.SY math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present an impedance control design for multi-variable\nlinear and nonlinear robotic systems. The control design considers force and\nstate feedback to improve the performance of the closed loop. Simultaneous\nfeedback of forces and states allows the controller for an extra degree of\nfreedom to approximate the desired impedance port behaviour. A numerical\nanalysis is used to demonstrate the desired impedance closed-loop behaviour.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:22:06 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12890","submitter":"Liangyi Huang","authors":"Liangyi Huang and Hui Rao","title":"A dimension drop phenomenon of fractal cubes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let E be a metric space. We introduce a notion of connectedness index of E,\nwhich is the Hausdor? dimension of the union of non-trivial connected\ncomponents of E. We show that the connectedness index of a fractal cube E is\nstrictly less than the Hausdor? dimension of E provided that E possesses a\ntrivial connected component. Hence the connectedness index is a new Lipschitz\ninvariant. Moreover, we investigate the relation between the connectedness\nindex and topological Hausdor? dimension.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:30:48 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12891","submitter":"Maciej Molas Dr.","authors":"M. Osiekowicz, D. Staszczuk, K. Olkowska-Pucko, {\\L}. Kipczak, M.\n  Grzeszczyk, M. Zinkiewicz, K. Nogajewski, Z. R. Kudrynskyi, Z. D. Kovalyuk,\n  A. Patan\\'e, A. Babi\\'nski, M. R. Molas","title":"Resonance and antiresonance in Raman scattering in GaSe and InSe\n  crystals","comments":"7 pages, 6 figures","journal-ref":"Scientific Reports 11, 924 (2021)","doi":"10.1038/s41598-020-79411-x","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The temperature effect on the Raman scattering efficiency is investigated in\n$\\varepsilon$-GaSe and $\\gamma$-InSe crystals. We found that varying the\ntemperature over a broad range from 5 K to 350 K permits to achieve both the\nresonant conditions and the antiresonance behaviour in Raman scattering of the\nstudied materials. The resonant conditions of Raman scattering are observed at\nabout 270 K under the 1.96 eV excitation for GaSe due to the energy proximity\nof the optical band gap. In the case of InSe, the resonant Raman spectra are\napparent at about 50 K and 270 K under correspondingly the 2.41 eV and 2.54 eV\nexcitations as a result of the energy proximity of the \\mbox{so-called} B\ntransition. Interestingly, the observed resonances for both materials are\nfollowed by an antiresonance behaviour noticeable at higher temperatures than\nthe detected resonances. The significant variations of phonon-modes intensities\ncan be explained in terms of electron-phonon coupling and quantum interference\nof contributions from different points of the Brillouin zone\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:35:07 GMT"}],"update_date":"2021-03-31"}
{"id":"2010.12892","submitter":"Christoph Haase","authors":"Christoph Haase and Jakub R\\'o\\.zycki","title":"On the Expressiveness of B\\\"uchi Arithmetic","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.FL math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show that the existential fragment of B\\\"uchi arithmetic is strictly less\nexpressive than full B\\\"uchi arithmetic of any base, and moreover establish\nthat its $\\Sigma_2$-fragment is already expressively complete. Furthermore, we\nshow that regular languages of polynomial growth are definable in the\nexistential fragment of B\\\"uchi arithmetic.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:39:27 GMT"},{"version":"v2","created":"Fri, 8 Jan 2021 15:02:07 GMT"},{"version":"v3","created":"Tue, 2 Mar 2021 23:49:48 GMT"}],"update_date":"2021-03-04"}
{"id":"2010.12893","submitter":"Luis Hern\\'andez-Corbato","authors":"Armengol Gasull, Luis Hern\\'andez-Corbato, Francisco R. Ruiz del\n  Portal","title":"Parrondo's paradox for homeomorphisms","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct two planar homeomorphisms $f$ and $g$ for which the origin is a\nglobally asymptotically stable fixed point whereas for $f \\circ g$ and $g \\circ\nf$ the origin is a global repeller. Furthermore, the origin remains a global\nrepeller for the iterated function system generated by $f$ and $g$ where each\nof the maps appears with a certain probability. This planar construction is\nalso extended to any dimension greater than 2 and proves for first time the\nappearance of the Parrondo's dynamical paradox in odd dimensions.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:49:51 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12894","submitter":"Sujunjie Sun","authors":"Sujunjie Sun, Guopeng Zhang, Haibo Mei, Kezhi Wang, and Kun Yang","title":"Optimizing Multi-UAV Deployment in 3D Space to Minimize Task Completion\n  Time in UAV-Enabled Mobile Edge Computing Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In Unmanned Aerial Vehicle (UAV)-enabled mobile edge computing (MEC) systems,\nUAVs can carry edge servers to help ground user equipment (UEs) offloading\ntheir computing tasks to the UAVs for execution. This paper aims to minimize\nthe total time required for the UAVs to complete the offloaded tasks, while\noptimizing the three-dimensional (3D) deployment of UAVs, including their\nflying height and horizontal positions. Although the formulated optimization is\na mixed integer nonlinear programmming, we convert it to a convex problem and\ndevelop a successive convex approximation (SCA) based algorithm to effectively\nsolve it. The simulation results show that the joint optimization of the\nhorizontal and the vertical position of a group of UAVs can achieve better\nperformance than the traditional algorithms.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:51:05 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12895","submitter":"Tao Li","authors":"Jiyanglin Li and Tao Li","title":"Some Theoretical Results Concerning Time-varying Nonparametric\n  Regression with Local Stationary Regressors and Error","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.ME stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With regard to a three-step estimation procedure, proposed without\ntheoretical discussion by Li and You in Journal of Applied Statistics and\nManagement, for a nonparametric regression model with time-varying regression\nfunction, local stationary regressors and time-varying AR(p) (tvAR(p)) error\nprocess , we established all necessary asymptotic properties for each of\nestimator. We derive the convergence rate and asymptotic normality of the\npreliminary estimation of nonparametric regression function, establish the\nasymptotic distribution of time-varying coefficient functions in the error\nterm, and present the asymptotic property of the refined estimation of\nnonparametric regression function. In addition, with regard to the ULASSO\nmethod for variable selection and constant coefficient detection for error term\nstructure, we show that the ULASSO estimator can identify the true error term\nstructure consistently. We conduct two simulation studies to illustrate the\nfinite sample performance of the estimators and validate our theoretical\ndiscussion on the properties of the estimators.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:17:30 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12896","submitter":"Loizos Michael","authors":"Antonis Kakas, Loizos Michael","title":"Abduction and Argumentation for Explainable Machine Learning: A Position\n  Survey","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents Abduction and Argumentation as two principled forms for\nreasoning, and fleshes out the fundamental role that they can play within\nMachine Learning. It reviews the state-of-the-art work over the past few\ndecades on the link of these two reasoning forms with machine learning work,\nand from this it elaborates on how the explanation-generating role of Abduction\nand Argumentation makes them naturally-fitting mechanisms for the development\nof Explainable Machine Learning and AI systems. Abduction contributes towards\nthis goal by facilitating learning through the transformation, preparation, and\nhomogenization of data. Argumentation, as a conservative extension of classical\ndeductive reasoning, offers a flexible prediction and coverage mechanism for\nlearning -- an associated target language for learned knowledge -- that\nexplicitly acknowledges the need to deal, in the context of learning, with\nuncertain, incomplete and inconsistent data that are incompatible with any\nclassically-represented logical theory.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:23:44 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12897","submitter":"Ginger Egberts","authors":"Ginger Egberts and Fred Vermolen and Paul van Zuijlen","title":"A one-dimensional morphoelastic model for burn injuries: stability\n  analysis, numerical validation and biological interpretation","comments":"38 pages, 5 figures","journal-ref":null,"doi":"10.1007/s00285-021-01648-5","report-no":null,"categories":"math.NA cs.NA physics.bio-ph q-bio.TO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To deal with permanent deformations and residual stresses, we consider a\nmorphoelastic model for the scar formation as the result of wound healing after\na skin trauma. Next to the mechanical components such as strain and\ndisplacements, the model accounts for biological constituents such as the\nconcentration of signaling molecules, the cellular densities of fibroblasts and\nmyofibroblasts, and the density of collagen. Here we present stability\nconstraints for the one-dimensional counterpart of this morphoelastic model,\nfor both the continuous and (semi-) discrete problem. We show that the\ntruncation error between these eigenvalues associated with the continuous and\nsemi-discrete problem is of order $\\mathcal{O}(h^2)$. Next, we perform\nnumerical validation to these constraints and provide a biological\ninterpretation of the (in)stability. For the mechanical part of the model, the\nresults show the components reach equilibria in a (non) monotonic way,\ndepending on the value of the viscosity. The results show that the parameters\nof the chemical part of the model need to meet the stability constraint,\ndepending on the decay rate of the signaling molecules, to avoid unrealistic\nresults.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:27:43 GMT"},{"version":"v2","created":"Sun, 28 Feb 2021 13:58:14 GMT"}],"update_date":"2022-03-17"}
{"id":"2010.12898","submitter":"Anindita Banerjee","authors":"Anindita Banerjee, Deepika Aggarwal, Ankush Sharma, Ganesh Yadav","title":"Unpredictable and Uniform RNG based on time of arrival using InGaAs\n  Detectors","comments":"8 pages, 4 figures, 3 Tables, RevTex","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Quantum random number generators are becoming mandatory in a demanding\ntechnology world of high performing learning algorithms and security\nguidelines. Our implementation based on principles of quantum mechanics enable\nus to achieve the required randomness. We have generated high-quality quantum\nrandom numbers from a weak coherent source at telecommunication wavelength. The\nentropy is based on time of arrival of quantum states within a predefined time\ninterval. The detection of photons by the InGaAs single-photon detectors and\nhigh precision time measurement of 5 ps enables us to generate 16 random bits\nper arrival time which is the highest reported to date. We have presented the\ntheoretical analysis and experimental verification of the random number\ngeneration methodology. The method eliminates the requirement of any randomness\nextractor to be applied thereby, leveraging the principles of quantum physics\nto generate random numbers. The output data rate is on an average of 2.4 Mbps.\nThe raw quantum random numbers are compared with NIST prescribed Blum-Blum-Shub\npseudo random number generator and an in-house built hardware random number\ngenerator from FPGA, on the ENT and NIST Platform.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:31:00 GMT"},{"version":"v2","created":"Fri, 16 Jul 2021 07:23:48 GMT"}],"update_date":"2021-07-19"}
{"id":"2010.12899","submitter":"Danye Wu","authors":"Yana Qin, Danye Wu, Zhiwei Xu, Jie Tian, Yujun Zhang","title":"Adaptive In-network Collaborative Caching for Enhanced Ensemble Deep\n  Learning at Edge","comments":"Submitted to IEEE Access","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To enhance the quality and speed of data processing and protect the privacy\nand security of the data, edge computing has been extensively applied to\nsupport data-intensive intelligent processing services at edge. Among these\ndata-intensive services, ensemble learning-based services can in natural\nleverage the distributed computation and storage resources at edge devices to\nachieve efficient data collection, processing, analysis.\n  Collaborative caching has been applied in edge computing to support services\nclose to the data source, in order to take the limited resources at edge\ndevices to support high-performance ensemble learning solutions. To achieve\nthis goal, we propose an adaptive in-network collaborative caching scheme for\nensemble learning at edge. First, an efficient data representation structure is\nproposed to record cached data among different nodes. In addition, we design a\ncollaboration scheme to facilitate edge nodes to cache valuable data for local\nensemble learning, by scheduling local caching according to a summarization of\ndata representations from different edge nodes. Our extensive simulations\ndemonstrate the high performance of the proposed collaborative caching scheme,\nwhich significantly reduces the learning latency and the transmission overhead.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:32:58 GMT"},{"version":"v2","created":"Wed, 28 Oct 2020 00:51:01 GMT"},{"version":"v3","created":"Thu, 29 Oct 2020 07:21:41 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.12900","submitter":"Takashi Hikihara","authors":"Shota Inagaki, Shiu Mochiyama, and Takashi Hikihara","title":"Electric Power Processing Using Logic Operation and Error Correction","comments":"This paper is submitted to The Royal Society, Proceedings A","journal-ref":null,"doi":"10.1098/rsos.202344","report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, electric power is processed using the logic operation method\nand the error correction algorithms to meet load demand. Electric power was\ntreated as physically flow through the distribution network, which was governed\nby circuit configuration and efficiency. The hardware required to digitize or\npacketize electric power, which is called power packet router, was developed in\nthis research work. It provides the opportunity for functional electric power\ndispatching disregarding the power flow in the circuit. This study proposes a\nnew design for the network, which makes the logic operation of electric power\npossible and provides an algorithm to correct the inaccuracies caused by\ndissipation and noise. Phase shift of the power supply network is resulted by\nimplementing the introduced design.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:37:53 GMT"}],"update_date":"2021-08-25"}
{"id":"2010.12901","submitter":"Victor Ma\\~nosa","authors":"Anna Cima, Armengol Gasull, V\\'ictor Ma\\~nosa, Francesc Ma\\~nosas","title":"Pointwise periodic maps with quantized first integrals","comments":"46 pages, 20 figures","journal-ref":"Commun Nonlinear Sci Numer Simulat 108 (2022) 106150 (26 pages)","doi":"10.1016/j.cnsns.2021.106150","report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe the global dynamics of some pointwise periodic piecewise linear\nmaps in the plane that exhibit interesting dynamic features. For each of these\nmaps we find a first integral. For these integrals the set of values are\ndiscrete, thus quantized. Furthermore, the level sets are bounded sets whose\ninterior is formed by a finite number of open tiles of certain regular or\nuniform tessellations. The action of the maps on each invariant set of tiles is\ndescribed geometrically.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:48:42 GMT"},{"version":"v2","created":"Sat, 5 Dec 2020 07:27:52 GMT"},{"version":"v3","created":"Tue, 14 Sep 2021 10:31:00 GMT"},{"version":"v4","created":"Thu, 2 Dec 2021 22:24:41 GMT"}],"update_date":"2022-01-24"}
{"id":"2010.12902","submitter":"Ginger Egberts","authors":"Ginger Egberts and Fred Vermolen and Paul van Zuijlen","title":"A one-dimensional morphoelastic model for burn injuries: sensitivity\n  analysis and a feasibility study","comments":null,"journal-ref":null,"doi":"10.1007/s10237-021-01499-5","report-no":null,"categories":"math.NA cs.NA physics.bio-ph q-bio.TO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a one-dimensional morphoelastic model describing post-burn scar\ncontraction. This model describes the displacement of the dermal layer of the\nskin and the development of the effective Eulerian strain in the tissue.\nBesides these components, the model also contains components that play a major\nrole in skin repair after trauma. These components are signaling molecules,\nfibroblasts, myofibroblasts, and collagen. We perform a sensitivity analysis\nfor many parameters of the model and use the results for a feasibility study.\nIn this study, we test whether the model is suitable for predicting the extent\nof contraction in different age groups. To this end, we conduct an extensive\nliterature review to find parameter values. From the sensitivity analysis, we\nconclude that the most sensitive parameters are the equilibrium collagen\nconcentration in the dermal layer, the apoptosis rate of fibroblasts and\nmyofibroblasts, and the secretion rate of signaling molecules. Further,\nalthough we can use the model to simulate distinct contraction densities in\ndifferent age groups, our results differ from what is seen in the clinic.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:55:50 GMT"},{"version":"v2","created":"Thu, 27 May 2021 10:00:42 GMT"},{"version":"v3","created":"Fri, 28 May 2021 07:45:36 GMT"}],"update_date":"2022-03-17"}
{"id":"2010.12903","submitter":"Alexander Brudnyi","authors":"A. Brudnyi","title":"On Exponential Factorizations of Matrices over Banach Algebras","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study exponential factorization of invertible matrices over unital complex\nBanach algebras. In particular, we prove that every invertible matrix with\nentries in the algebra of holomorphic functions on a closed bordered Riemann\nsurface can be written as a product of two exponents of matrices over this\nalgebra. Our result extends similar results proved earlier in [KS] and [L] for\n$2\\times 2$ matrices.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 13:57:47 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12904","submitter":"Francesco Pannarale","authors":"Raul Ciancarella and Francesco Pannarale and Andrea Addazi and\n  Antonino Marciano","title":"Constraining Mirror Dark Matter Inside Neutron Stars","comments":"21 pages, 5 figures, 2 tables","journal-ref":null,"doi":null,"report-no":"LIGO-P2000388","categories":"astro-ph.HE gr-qc hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We inspect the possibility that neutron star interiors are a mixture of\nordinary matter and mirror dark matter. This is a scenario that can be\nnaturally envisaged according to well studied accretion mechanisms, including\nthe Bondi-Hoyle one. We show that the inclusion of mirror dark matter in\nneutron star models lowers the maximum neutron star mass for a given equation\nof state, and that it decreases the tidal deformability of a given neutron\nstar. These general features imply that, given an equation of state, one can\nconstrain the maximum viable amount of mirror dark matter in neutron stars in\norder to consistently fulfill existing maximum mass and tidal deformability\nconstraints. Conversely, using tidal deformability measurements to rule out\nequations of state requires making assumptions on the amount of mirror dark\nmatter contained in neutron stars. Finally, the presence of mirror dark matter\nalso modifies the universal relation that links the tidal deformability of a\nneutron star to its compactness. Therefore, caution is mandatory when\nconsidering exotic models, such as the ones discussed in this paper.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:00:10 GMT"},{"version":"v2","created":"Tue, 3 Nov 2020 10:41:29 GMT"},{"version":"v3","created":"Thu, 5 Nov 2020 15:57:55 GMT"}],"update_date":"2020-11-06"}
{"id":"2010.12905","submitter":"Masahiro Kato","authors":"Masahiro Kato, Zhenghang Cui, Yoshihiro Fukuhara","title":"ATRO: Adversarial Training with a Rejection Option","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a classification framework with a rejection option to\nmitigate the performance deterioration caused by adversarial examples. While\nrecent machine learning algorithms achieve high prediction performance, they\nare empirically vulnerable to adversarial examples, which are slightly\nperturbed data samples that are wrongly classified. In real-world applications,\nadversarial attacks using such adversarial examples could cause serious\nproblems. To this end, various methods are proposed to obtain a classifier that\nis robust against adversarial examples. Adversarial training is one of them,\nwhich trains a classifier to minimize the worst-case loss under adversarial\nattacks. In this paper, in order to acquire a more reliable classifier against\nadversarial attacks, we propose the method of Adversarial Training with a\nRejection Option (ATRO). Applying the adversarial training objective to both a\nclassifier and a rejection function simultaneously, classifiers trained by ATRO\ncan choose to abstain from classification when it has insufficient confidence\nto classify a test data point. We examine the feasibility of the framework\nusing the surrogate maximum hinge loss and establish a generalization bound for\nlinear models. Furthermore, we empirically confirmed the effectiveness of ATRO\nusing various models and real-world datasets.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:05:03 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12906","submitter":"Ai-Jun Ma","authors":"Ai-Jun Ma, Wen-Fei Wang","title":"Contributions of the kaon pair from $\\rho(770)$ for the three-body\n  decays $B \\to D K\\bar{K}$","comments":"12 pages, 3 figures and 4 tables. Some modifications, matching the\n  published version","journal-ref":"Phys. Rev. D 103, 016002 (2021)","doi":"10.1103/PhysRevD.103.016002","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the contributions of the kaon pair originating from the resonance\n$\\rho(770)$ for the three-body decays $B \\to D K\\bar{K}$ by employing the\nperturbative QCD approach. According to the predictions in this work, the\ncontributions from the intermediate state $\\rho(770)^0 $ are relatively small\nfor the three-body decays such as $B^0 \\to \\bar{D}^0 K^+ K^-$, $B_s^0 \\to\n\\bar{D}^0 K^+ K^-$, and $B^+ \\to D_s^+ K^+K^-$, while about $20\\%$ of the total\nthree-body branching fraction for $B^+ \\to \\bar{D}^0 K^+ \\bar{K}^0$ could\npossibly come from the subprocess $\\rho(770)^+\\to K^+ \\bar{K}^0$. We also\nestimate the branching fractions for $\\rho(770)^\\pm$ decay into the kaon pair\nto be about $1\\%$, and that for the neutral $\\rho(770)$ decay into $K^+K^-$ or\n$K^0\\bar{K}^0$ to be about $0.5\\%$, which will be tested by future experiments.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:05:43 GMT"},{"version":"v2","created":"Tue, 5 Jan 2021 07:08:31 GMT"}],"update_date":"2021-01-06"}
{"id":"2010.12907","submitter":"Alberto Dom\\'inguez","authors":"Vaidehi S. Paliya, A. Dom\\'inguez, C. Cabello, N. Cardiel, J. Gallego,\n  B. Siana, M. Ajello, D. Hartmann, A. Gil de Paz, C. S. Stalin","title":"The First Gamma-ray Emitting BL Lacertae Object at the Cosmic Dawn","comments":"Accepted for publication in The Astrophysical Journal Letters","journal-ref":null,"doi":"10.3847/2041-8213/abbc06","report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the major challenges in studying the cosmic evolution of relativistic\njets is the identification of the high-redshift ($z>3$) BL Lacertae objects, a\nclass of jetted active galactic nuclei characterized by their quasi-featureless\noptical spectra. Here we report the identification of the first $\\gamma$-ray\nemitting BL Lac object, 4FGL~J1219.0+3653 (J1219), beyond $z=3$, i.e., within\nthe first two billion years of the age of the Universe. The optical and\nnear-infrared spectra of J1219 taken from 10.4 m Gran Telescopio Canarias\nexhibit no emission lines down to an equivalent width of $\\sim$3.5 A supporting\nits BL Lac nature. The detection of a strong Lyman-$\\alpha$ break at $\\sim$5570\nA, on the other hand, confirms that J2119 is indeed a high-redshift\n($z\\sim3.59$) quasar. Based on the prediction of a recent BL Lac evolution\nmodel, J1219 is one of the only two such objects expected to be present within\nthe comoving volume at $z=3.5$. Future identifications of more $z>3$\n$\\gamma$-ray emitting BL Lac sources, therefore, will be crucial to verify the\ntheories of their cosmic evolution.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:15:36 GMT"}],"update_date":"2020-11-11"}
{"id":"2010.12908","submitter":"Xiang Ling","authors":"Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma, Fangli\n  Xu, Alex X. Liu, Chunming Wu, Shouling Ji","title":"Deep Graph Matching and Searching for Semantic Code Retrieval","comments":"Accepted by ACM Transactions on Knowledge Discovery from Data (ACM\n  TKDD)","journal-ref":"ACM Trans. Knowl. Discov. Data 15, 5 (2021), 1-21","doi":"10.1145/3447571","report-no":null,"categories":"cs.AI cs.IR cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Code retrieval is to find the code snippet from a large corpus of source code\nrepositories that highly matches the query of natural language description.\nRecent work mainly uses natural language processing techniques to process both\nquery texts (i.e., human natural language) and code snippets (i.e., machine\nprogramming language), however neglecting the deep structured features of query\ntexts and source codes, both of which contain rich semantic information. In\nthis paper, we propose an end-to-end deep graph matching and searching (DGMS)\nmodel based on graph neural networks for the task of semantic code retrieval.\nTo this end, we first represent both natural language query texts and\nprogramming language code snippets with the unified graph-structured data, and\nthen use the proposed graph matching and searching model to retrieve the best\nmatching code snippet. In particular, DGMS not only captures more structural\ninformation for individual query texts or code snippets but also learns the\nfine-grained similarity between them by cross-attention based semantic matching\noperations. We evaluate the proposed DGMS model on two public code retrieval\ndatasets with two representative programming languages (i.e., Java and Python).\nExperiment results demonstrate that DGMS significantly outperforms\nstate-of-the-art baseline models by a large margin on both datasets. Moreover,\nour extensive ablation studies systematically investigate and illustrate the\nimpact of each part of DGMS.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:16:50 GMT"},{"version":"v2","created":"Fri, 22 Jan 2021 16:38:09 GMT"}],"update_date":"2021-06-23"}
{"id":"2010.12909","submitter":"Depen Morwani","authors":"Depen Morwani, Harish G. Ramaswamy","title":"Inductive Bias of Gradient Descent for Weight Normalized Smooth\n  Homogeneous Neural Nets","comments":"Accepted to ALT 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyze the inductive bias of gradient descent for weight normalized\nsmooth homogeneous neural nets, when trained on exponential or cross-entropy\nloss. We analyse both standard weight normalization (SWN) and exponential\nweight normalization (EWN), and show that the gradient flow path with EWN is\nequivalent to gradient flow on standard networks with an adaptive learning\nrate. We extend these results to gradient descent, and establish asymptotic\nrelations between weights and gradients for both SWN and EWN. We also show that\nEWN causes weights to be updated in a way that prefers asymptotic relative\nsparsity. For EWN, we provide a finite-time convergence rate of the loss with\ngradient flow and a tight asymptotic convergence rate with gradient descent. We\ndemonstrate our results for SWN and EWN on synthetic data sets. Experimental\nresults on simple datasets support our claim on sparse EWN solutions, even with\nSGD. This demonstrates its potential applications in learning neural networks\namenable to pruning.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:34:56 GMT"},{"version":"v2","created":"Thu, 26 Nov 2020 05:30:53 GMT"},{"version":"v3","created":"Tue, 31 Jan 2023 22:24:25 GMT"}],"update_date":"2023-02-02"}
{"id":"2010.12910","submitter":"Alexander B. Balakin","authors":"Alexander B. Balakin and Amir F. Shakirzyanov","title":"Is the axionic dark matter an equilibrium system?","comments":"Based on the talk presented on the 17th Russian Conference on\n  Gravitation, Cosmology and Astrophysics (RUSGRAV-17)","journal-ref":"Universe 2020, 6(11), 192","doi":"10.3390/universe6110192","report-no":null,"categories":"gr-qc astro-ph.CO hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider an axionic dark matter model with a modified periodic potential\nfor the pseudoscalar field in the framework of the axionic extension of the\nEinstein-aether theory. The modified potential is assumed to be equipped by the\nguiding function, which depends on the expansion scalar constructed as the\ntrace of the covariant derivative of the aether velocity four-vector. The\nequilibrium state of the axion field is defined as the state, for which the\nmodified potential itself and its first derivative with respect to the\npseudoscalar field are equal to zero. We apply the developed formalism to the\nhomogeneous isotropic cosmological model, and find the basic function, which\ndescribes the equilibrium state of the axionic dark matter in the expanding\nUniverse.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:43:44 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12911","submitter":"John C. Raymond","authors":"John C. Raymond, Jonathan D. Slavin, William P. Blair, Igor V.\n  Chilingarian, Blakesley Burkhart and Ravi Sankrit","title":"Turbulence and Particle Acceleration in Radiative Shock Waves in the\n  Cygnus Loop II: Development of Postshock Turbulence","comments":"40 pages, 22 Figures. Accepted for publication in ApJ","journal-ref":null,"doi":"10.3847/1538-4357/abb821","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Radiative shock waves in the Cygnus Loop and other supernova remnants show\ndifferent morphologies in [O III] and H{\\alpha} emission. We use HST spectra\nand narrowband images to study the development of turbulence in the cooling\nregion behind a shock on the west limb of the Cygnus Loop. We refine our\nearlier estimates of shock parameters that were based upon ground-based\nspectra, including ram pressure, vorticity and magnetic field strength. We\napply several techniques, including Fourier power spectra and the Rolling Hough\nTransform, to quantify the shape of the rippled shock front as viewed in\ndifferent emission lines. We assess the relative importance of thermal\ninstabilities, the thin shell instability, upstream density variations, and\nupstream magnetic field variations in producing the observed structure.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:01:59 GMT"},{"version":"v2","created":"Tue, 27 Oct 2020 13:11:38 GMT"}],"update_date":"2020-11-04"}
{"id":"2010.12912","submitter":"Camilo Thorne","authors":"Camilo Thorne and Saber Akhondi","title":"Word Embeddings for Chemical Patent Natural Language Processing","comments":"Extended version of an extended abstract presented (and reviewed) at\n  the Latinx Workshop at ICML 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We evaluate chemical patent word embeddings against known biomedical\nembeddings and show that they outperform the latter extrinsically and\nintrinsically. We also show that using contextualized embeddings can induce\npredictive models of reasonable performance for this domain over a relatively\nsmall gold standard.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:03:20 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12913","submitter":"Shafin Rahman","authors":"Shafin Rahman, Sejuti Rahman, Omar Shahid, Md. Tahmeed Abdullah,\n  Jubair Ahmed Sourov","title":"Classifying Eye-Tracking Data Using Saliency Maps","comments":"Accepted in: International Conference on Pattern Recognition (ICPR)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A plethora of research in the literature shows how human eye fixation pattern\nvaries depending on different factors, including genetics, age, social\nfunctioning, cognitive functioning, and so on. Analysis of these variations in\nvisual attention has already elicited two potential research avenues: 1)\ndetermining the physiological or psychological state of the subject and 2)\npredicting the tasks associated with the act of viewing from the recorded\neye-fixation data. To this end, this paper proposes a visual saliency based\nnovel feature extraction method for automatic and quantitative classification\nof eye-tracking data, which is applicable to both of the research directions.\nInstead of directly extracting features from the fixation data, this method\nemploys several well-known computational models of visual attention to predict\neye fixation locations as saliency maps. Comparing the saliency amplitudes,\nsimilarity and dissimilarity of saliency maps with the corresponding eye\nfixations maps gives an extra dimension of information which is effectively\nutilized to generate discriminative features to classify the eye-tracking data.\nExtensive experimentation using Saliency4ASD, Age Prediction, and Visual\nPerceptual Task dataset show that our saliency-based feature can achieve\nsuperior performance, outperforming the previous state-of-the-art methods by a\nconsiderable margin. Moreover, unlike the existing application-specific\nsolutions, our method demonstrates performance improvement across three\ndistinct problems from the real-life domain: Autism Spectrum Disorder\nscreening, toddler age prediction, and human visual perceptual task\nclassification, providing a general paradigm that utilizes the\nextra-information inherent in saliency maps for a more accurate classification.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:18:07 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12914","submitter":"Xiyao Wang","authors":"Xiyao Wang, Junge Zhang, Wenzhen Huang, Qiyue Yin","title":"Planning with Exploration: Addressing Dynamics Bottleneck in Model-based\n  Reinforcement Learning","comments":"15 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Model-based reinforcement learning (MBRL) is believed to have higher sample\nefficiency compared with model-free reinforcement learning (MFRL). However,\nMBRL is plagued by dynamics bottleneck dilemma. Dynamics bottleneck dilemma is\nthe phenomenon that the performance of the algorithm falls into the local\noptimum instead of increasing when the interaction step with the environment\nincreases, which means more data can not bring better performance. In this\npaper, we find that the trajectory reward estimation error is the main reason\nthat causes dynamics bottleneck dilemma through theoretical analysis. We give\nan upper bound of the trajectory reward estimation error and point out that\nincreasing the agent's exploration ability is the key to reduce trajectory\nreward estimation error, thereby alleviating dynamics bottleneck dilemma.\nMotivated by this, a model-based control method combined with exploration named\nMOdel-based Progressive Entropy-based Exploration (MOPE2) is proposed. We\nconduct experiments on several complex continuous control benchmark tasks. The\nresults verify that MOPE2 can effectively alleviate dynamics bottleneck dilemma\nand have higher sample efficiency than previous MBRL and MFRL algorithms.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:29:02 GMT"},{"version":"v2","created":"Tue, 24 Nov 2020 01:18:54 GMT"},{"version":"v3","created":"Thu, 24 Jun 2021 16:06:52 GMT"}],"update_date":"2021-06-25"}
{"id":"2010.12915","submitter":"Saif Khan Mohammed Dr.","authors":"Alok Kumar Sinha, Saif Khan Mohammed, P. Raviteja, Yi Hong and\n  Emanuele Viterbo","title":"OTFS Based Random Access Preamble Transmission For High Mobility\n  Scenarios","comments":"Accepted in IEEE Transactions on Vehicular Technology. Copyright 2020\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses (see IEEE Publication Services and Products\n  Board Operations Manual)","journal-ref":"IEEE Transactions on Vehicular Technology, vol. 69, no. 12,\n  December 2020","doi":"10.1109/TVT.2020.3034130","report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of uplink timing synchronization for Orthogonal Time\nFrequency Space (OTFS) modulation based systems where information is embedded\nin the delay-Doppler (DD) domain. For this, we propose a novel Random Access\n(RA) preamble waveform based on OTFS modulation. We also propose a method to\nestimate the round-trip propagation delay between a user terminal (UT) and the\nbase station (BS) based on the received RA preambles in the DD domain. This\nestimate (known as the timing advance estimate) is fed back to the respective\nUTs so that they can advance their uplink timing in order that the signal from\nall UTs in a cell is received at the BS in a time-synchronized manner. Through\nanalysis and simulations we study the impact of OTFS modulation parameters of\nthe RA preamble on the probability of timing error, which gives valuable\ninsights on how to choose these parameters. Exhaustive numerical simulations of\nhigh mobility scenarios suggests that the timing error probability (TEP)\nperformance of the proposed OTFS based RA is much more robust to channel\ninduced multi-path Doppler shift when compared to the RA method in Fourth\nGeneration (4G) systems.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:29:26 GMT"}],"update_date":"2021-04-08"}
{"id":"2010.12916","submitter":"Katelyn Gao","authors":"Katelyn Gao and Ozan Sener","title":"Modeling and Optimization Trade-off in Meta-learning","comments":"To appear at NeurIPS 2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  By searching for shared inductive biases across tasks, meta-learning promises\nto accelerate learning on novel tasks, but with the cost of solving a complex\nbilevel optimization problem. We introduce and rigorously define the trade-off\nbetween accurate modeling and optimization ease in meta-learning. At one end,\nclassic meta-learning algorithms account for the structure of meta-learning but\nsolve a complex optimization problem, while at the other end domain randomized\nsearch (otherwise known as joint training) ignores the structure of\nmeta-learning and solves a single level optimization problem. Taking MAML as\nthe representative meta-learning algorithm, we theoretically characterize the\ntrade-off for general non-convex risk functions as well as linear regression,\nfor which we are able to provide explicit bounds on the errors associated with\nmodeling and optimization. We also empirically study this trade-off for\nmeta-reinforcement learning benchmarks.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:32:08 GMT"},{"version":"v2","created":"Tue, 13 Apr 2021 20:03:56 GMT"}],"update_date":"2021-04-15"}
{"id":"2010.12917","submitter":"Zan-Xia Jin","authors":"Zan-Xia Jin, Heran Wu, Chun Yang, Fang Zhou, Jingyan Qin, Lei Xiao and\n  Xu-Cheng Yin","title":"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question\n  Answering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Text-based visual question answering (VQA) requires to read and understand\ntext in an image to correctly answer a given question. However, most current\nmethods simply add optical character recognition (OCR) tokens extracted from\nthe image into the VQA model without considering contextual information of OCR\ntokens and mining the relationships between OCR tokens and scene objects. In\nthis paper, we propose a novel text-centered method called RUArt (Reading,\nUnderstanding and Answering the Related Text) for text-based VQA. Taking an\nimage and a question as input, RUArt first reads the image and obtains text and\nscene objects. Then, it understands the question, OCRed text and objects in the\ncontext of the scene, and further mines the relationships among them. Finally,\nit answers the related text for the given question through text semantic\nmatching and reasoning. We evaluate our RUArt on two text-based VQA benchmarks\n(ST-VQA and TextVQA) and conduct extensive ablation studies for exploring the\nreasons behind RUArt's effectiveness. Experimental results demonstrate that our\nmethod can effectively explore the contextual information of the text and mine\nthe stable relationships between the text and objects.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:37:09 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12918","submitter":"Yash Pote","authors":"Kuldeep S. Meel, Yash Pote, Sourav Chakraborty","title":"On Testing of Samplers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a set of items $\\mathcal{F}$ and a weight function $\\mathtt{wt}:\n\\mathcal{F} \\mapsto (0,1)$, the problem of sampling seeks to sample an item\nproportional to its weight. Sampling is a fundamental problem in machine\nlearning. The daunting computational complexity of sampling with formal\nguarantees leads designers to propose heuristics-based techniques for which no\nrigorous theoretical analysis exists to quantify the quality of generated\ndistributions.\n  This poses a challenge in designing a testing methodology to test whether a\nsampler under test generates samples according to a given distribution. Only\nrecently, Chakraborty and Meel (2019) designed the first scalable verifier,\ncalled Barbarik1, for samplers in the special case when the weight function\n$\\mathtt{wt}$ is constant, that is, when the sampler is supposed to sample\nuniformly from $\\mathcal{F}$ . The techniques in Barbarik1, however, fail to\nhandle general weight functions.\n  The primary contribution of this paper is an affirmative answer to the above\nchallenge: motivated by Barbarik1 but using different techniques and analysis,\nwe design Barbarik2 an algorithm to test whether the distribution generated by\na sampler is $\\varepsilon$-close or $\\eta$-far from any target distribution. In\ncontrast to black-box sampling techniques that require a number of samples\nproportional to $|\\mathcal{F}|$ , Barbarik2 requires only\n$\\tilde{O}(tilt(\\mathtt{wt},\\varphi)^2/\\eta(\\eta - 6\\varepsilon)^3)$ samples,\nwhere the $tilt$ is the maximum ratio of weights of two satisfying assignments.\nBarbarik2 can handle any arbitrary weight function. We present a prototype\nimplementation of Barbarik2 and use it to test three state-of-the-art samplers.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:42:34 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12919","submitter":"Reid Pryzant","authors":"Reid Pryzant, Dallas Card, Dan Jurafsky, Victor Veitch, Dhanya Sridhar","title":"Causal Effects of Linguistic Properties","comments":"To appear at NAACL 2021 (Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of using observational data to estimate the causal\neffects of linguistic properties. For example, does writing a complaint\npolitely lead to a faster response time? How much will a positive product\nreview increase sales? This paper addresses two technical challenges related to\nthe problem before developing a practical method. First, we formalize the\ncausal quantity of interest as the effect of a writer's intent, and establish\nthe assumptions necessary to identify this from observational data. Second, in\npractice, we only have access to noisy proxies for the linguistic properties of\ninterest -- e.g., predictions from classifiers and lexicons. We propose an\nestimator for this setting and prove that its bias is bounded when we perform\nan adjustment for the text. Based on these results, we introduce TextCause, an\nalgorithm for estimating causal effects of linguistic properties. The method\nleverages (1) distant supervision to improve the quality of noisy proxies, and\n(2) a pre-trained language model (BERT) to adjust for the text. We show that\nthe proposed method outperforms related approaches when estimating the effect\nof Amazon review sentiment on semi-simulated sales figures. Finally, we present\nan applied case study investigating the effects of complaint politeness on\nbureaucratic response times.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:43:37 GMT"},{"version":"v2","created":"Thu, 8 Apr 2021 14:30:35 GMT"},{"version":"v3","created":"Fri, 9 Apr 2021 17:01:13 GMT"},{"version":"v4","created":"Thu, 20 May 2021 20:10:34 GMT"},{"version":"v5","created":"Mon, 14 Jun 2021 14:10:05 GMT"}],"update_date":"2021-06-15"}
{"id":"2010.12920","submitter":"Yichen Fu","authors":"Yichen Fu, Xin Zhang, Hong Qin","title":"An Explicitly Solvable Energy-Conserving Algorithm for Pitch-Angle\n  Scattering in Magnetized Plasmas","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We develop an Explicitly Solvable Energy-Conserving (ESEC) algorithm for the\nStochastic Differential Equation (SDE) describing the pitch-angle scattering\nprocess in magnetized plasmas. The Cayley transform is used to calculate both\nthe deterministic gyromotion and stochastic scattering, affording the algorithm\nto be explicitly solvable and exactly energy conserving. An unusual property of\nthe SDE for pitch-angle scattering is that its coefficients diverge at the zero\nvelocity and do not satisfy the global Lipschitz condition. Consequently, when\nstandard numerical methods, such as the Euler-Maruyama (EM), are applied,\nnumerical convergence is difficult to establish. For the proposed ESEC\nalgorithm, its energy-preserving property enables us to overcome this obstacle.\nWe rigorously prove that the ESEC algorithm is order 1/2 strongly convergent.\nThis result is confirmed by detailed numerical studies. For the case of\npitch-angle scattering in a magnetized plasma with a constant magnetic field,\nthe numerical solution is benchmarked against the analytical solution, and\nexcellent agreements are found.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:48:46 GMT"},{"version":"v2","created":"Mon, 11 Oct 2021 19:05:02 GMT"}],"update_date":"2021-10-13"}
{"id":"2010.12921","submitter":"Quanming Yao","authors":"Wei He and Quanming Yao and Chao Li and Naoto Yokoya and Qibin Zhao\n  and Hongyan Zhang and Liangpei Zhang","title":"Non-local Meets Global: An Iterative Paradigm for Hyperspectral Image\n  Restoration","comments":"Accepted to TPAMI","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-local low-rank tensor approximation has been developed as a\nstate-of-the-art method for hyperspectral image (HSI) restoration, which\nincludes the tasks of denoising, compressed HSI reconstruction and inpainting.\nUnfortunately, while its restoration performance benefits from more spectral\nbands, its runtime also substantially increases. In this paper, we claim that\nthe HSI lies in a global spectral low-rank subspace, and the spectral subspaces\nof each full band patch group should lie in this global low-rank subspace. This\nmotivates us to propose a unified paradigm combining the spatial and spectral\nproperties for HSI restoration. The proposed paradigm enjoys performance\nsuperiority from the non-local spatial denoising and light computation\ncomplexity from the low-rank orthogonal basis exploration. An efficient\nalternating minimization algorithm with rank adaptation is developed. It is\ndone by first solving a fidelity term-related problem for the update of a\nlatent input image, and then learning a low-dimensional orthogonal basis and\nthe related reduced image from the latent input image. Subsequently, non-local\nlow-rank denoising is developed to refine the reduced image and orthogonal\nbasis iteratively. Finally, the experiments on HSI denoising, compressed\nreconstruction, and inpainting tasks, with both simulated and real datasets,\ndemonstrate its superiority with respect to state-of-the-art HSI restoration\nmethods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:53:56 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.12922","submitter":"Maria Katsova","authors":"Maria Katsova","title":"The Evolution of the Solar-Stellar Activity","comments":"12 pages, 2 figures, 1 table. Accepted for publication to Journal of\n  Atmospheric and Solar-Terrestrial Physics","journal-ref":null,"doi":"10.1016/j.jastp.2020.105456","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a brief review of observational results contributing to modern\nideas on the evolution of stellar activity. Basic laws, derived for both\nrotation-age and activity-rotation relationships, allow us to trace how the\nactivity of low-mass stars changes with age during their stay on the main\nsequence. We focus on the evaluation of the activity properties of stars that\ncould be analogs of the young Sun. Our study includes joint consideration of\ndifferent tracers of activity, rotation and magnetic fields of Sun-like stars\nof various ages. We identify rotation periods, when the saturated regime of\nactivity changes to the unsaturated mode, when the solar-type activity is\nformed: for G- and K-type stars, they are 1.1 and 3.3 days, respectively. This\ncorresponds to an age interval of about 0.2-0.6 Gyr, when regular sunspot cycle\nbegan to be established on the early Sun. We discuss properties of the coronal\nand chromospheric activity in young Suns. Our evaluation of the EUV-fluxes in\nthe spectral range of 1350-1750 A shows that the far-UV radiation of the early\nSun was a factor of 7 times more intense than that of the present-day Sun, and\ntwice higher when the regular sunspot cycle was established. For the young Sun,\nwe can estimate the possible mass loss rate associated with quasi-steady\noutflow as $10^{-12} M_\\odot$/yr. The results of observations of the largest\nflares on solar-type stars are also discussed, leading to conclusion that the\nmost powerful phenomena occur on the fast-rotating stars in the saturated\nactivity regime. Our estimate of the stellar magnetic fields makes it possible\nto evaluate the maximal possible flare energy. This could help us better\nunderstand the origin of extreme events on the Sun in the past.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:58:29 GMT"}],"update_date":"2020-11-04"}
{"id":"2010.13321","submitter":"Ting Liu","authors":"Ting Liu, Jennifer J. Sun, Long Zhao, Jiaping Zhao, Liangzhe Yuan,\n  Yuxiao Wang, Liang-Chieh Chen, Florian Schroff, Hartwig Adam","title":"View-Invariant, Occlusion-Robust Probabilistic Embedding for Human Pose","comments":"Accepted to International Journal of Computer Vision (IJCV). Code is\n  available at\n  https://github.com/google-research/google-research/tree/master/poem. Video\n  synchronization results are available at\n  https://drive.google.com/corp/drive/folders/1nhPuEcX4Lhe6iK3nv84cvSCov2eJ52Xy.\n  arXiv admin note: text overlap with arXiv:1912.01001","journal-ref":null,"doi":"10.1007/s11263-021-01529-w","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recognition of human poses and actions is crucial for autonomous systems to\ninteract smoothly with people. However, cameras generally capture human poses\nin 2D as images and videos, which can have significant appearance variations\nacross viewpoints that make the recognition tasks challenging. To address this,\nwe explore recognizing similarity in 3D human body poses from 2D information,\nwhich has not been well-studied in existing works. Here, we propose an approach\nto learning a compact view-invariant embedding space from 2D body joint\nkeypoints, without explicitly predicting 3D poses. Input ambiguities of 2D\nposes from projection and occlusion are difficult to represent through a\ndeterministic mapping, and therefore we adopt a probabilistic formulation for\nour embedding space. Experimental results show that our embedding model\nachieves higher accuracy when retrieving similar poses across different camera\nviews, in comparison with 3D pose estimation models. We also show that by\ntraining a simple temporal embedding model, we achieve superior performance on\npose sequence retrieval and largely reduce the embedding dimension from\nstacking frame-based embeddings for efficient large-scale retrieval.\nFurthermore, in order to enable our embeddings to work with partially visible\ninput, we further investigate different keypoint occlusion augmentation\nstrategies during training. We demonstrate that these occlusion augmentations\nsignificantly improve retrieval performance on partial 2D input poses. Results\non action recognition and video alignment demonstrate that using our embeddings\nwithout any additional training achieves competitive performance relative to\nother models specifically trained for each task.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:58:35 GMT"},{"version":"v2","created":"Fri, 10 Sep 2021 09:34:06 GMT"},{"version":"v3","created":"Thu, 18 Nov 2021 10:03:27 GMT"}],"update_date":"2021-11-19"}
{"id":"2010.13326","submitter":"Samson Abramsky","authors":"Samson Abramsky","title":"Classical logic, classical probability, and quantum mechanics","comments":"15 pages. arXiv admin note: text overlap with arXiv:1705.07918","journal-ref":"The Work and Influence of Itamar Pitowsky, ed. Meir Hemmo and Orly\n  Shenker, Springer Nature, pages 1--17, 2020","doi":null,"report-no":null,"categories":"quant-ph cs.LO math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give an overview and conceptual discussion of some of our results on\ncontextuality and non-locality. We focus in particular on connections with the\nwork of Itamar Pitowsky on correlation polytopes, Bell inequalities, and\nBoole's \"conditions of possible experience\".\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:20:42 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.13327","submitter":"Mohammed Berkani","authors":"Mohammed Berkani","title":"Index of continuous semi-Fredholm families, regularities and\n  semiregularities","comments":"This paper is a continuation of our papers: arxiv:1912.07267v1 and\n  arxiv:2010.07040v1. The aim of these series of papers is to define an index\n  for continuous Fredholm or semi-Fredholm families. Several applications are\n  given through these papers, in particular a new generalization of Weyl\n  theorem is obtained in the paper arxiv:1912.07267v1 for normal families\n  acting on a Hilbert space. arXiv admin note: text overlap with\n  arXiv:2010.07040","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we define and index for continuous families of semi-Fredholm\nbounded liner operators. Moreover, we study various regularities and\nsemiregularities of continuous families of bounded linear operators.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:03:06 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.13328","submitter":"Samson Abramsky","authors":"Samson Abramsky","title":"Whither Semantics?","comments":"Appeared in special issue of TCS in honour of Maurice Nivat. arXiv\n  admin note: text overlap with arXiv:1806.09031, arXiv:2010.06496","journal-ref":"Theoretical Computer Science, vol. 807, pages 3--14, 2020","doi":null,"report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss how mathematical semantics has evolved, and suggest some new\ndirections for future work. As an example, we discuss some recent work on\nencapsulating model comparison games as comonads, in the context of finite\nmodel theory.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:13:36 GMT"}],"update_date":"2020-10-27"}
{"id":"2010.13551","submitter":"Graham Pulford","authors":"Graham W. Pulford","title":"From the Expectation Maximisation Algorithm to Autoencoded Variational\n  Bayes","comments":"27 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although the expectation maximisation (EM) algorithm was introduced in 1970,\nit remains somewhat inaccessible to machine learning practitioners due to its\nobscure notation, terse proofs and lack of concrete links to modern machine\nlearning techniques like autoencoded variational Bayes. This has resulted in\ngaps in the AI literature concerning the meaning of such concepts like \"latent\nvariables\" and \"variational lower bound,\" which are frequently used but often\nnot clearly explained. The roots of these ideas lie in the EM algorithm. We\nfirst give a tutorial presentation of the EM algorithm for estimating the\nparameters of a $K$-component mixture density. The Gaussian mixture case is\npresented in detail using $K$-ary scalar hidden (or latent) variables rather\nthan the more traditional binary valued $K$-dimenional vectors. This\npresentation is motivated by mixture modelling from the target tracking\nliterature. In a similar style to Bishop's 2009 book, we present variational\nBayesian inference as a generalised EM algorithm stemming from the variational\n(or evidential) lower bound, as well as the technique of mean field\napproximation (or product density transform). We continue the evolution from EM\nto variational autoencoders, developed by Kingma & Welling in 2014. In so\ndoing, we establish clear links between the EM algorithm and its variational\ncounterparts, hence clarifying the meaning of \"latent variables.\" We provide a\ndetailed coverage of the \"reparametrisation trick\" and focus on how the AEVB\ndiffers from conventional variational Bayesian inference. Throughout the\ntutorial, consistent notational conventions are used. This unifies the\nnarrative and clarifies the concepts. Some numerical examples are given to\nfurther illustrate the algorithms.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:23:26 GMT"},{"version":"v2","created":"Tue, 4 May 2021 07:33:28 GMT"}],"update_date":"2021-05-05"}
{"id":"2010.13552","submitter":"\\\"Ozlem Salehi","authors":"\\\"Ozlem Salehi, Zeki Seskir, \\.Ilknur Tepe","title":"A Computer Science-Oriented Approach to Introduce Quantum Computing to a\n  New Audience","comments":"Accepted to IEEE Transactions on Education","journal-ref":null,"doi":"10.1109/TE.2021.3078552","report-no":null,"categories":"physics.ed-ph cs.CY cs.ET quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Contribution: In this study, an alternative educational approach for\nintroducing quantum computing to a wider audience is highlighted. The proposed\nmethodology considers quantum computing as a generalized probability theory\nrather than a field emanating from physics and utilizes quantum programming as\nan educational tool to reinforce the learning process.\n  Background: Quantum computing is a topic mainly rooted in physics, and it has\nbeen gaining rapid popularity in recent years. A need for extending the\neducational reach to groups outside of physics has also been becoming a\nnecessity.\n  Intended outcomes: This study aims to inform academics and organizations\ninterested in introducing quantum computing to a diverse group of participants\non an educational approach. It is intended that the proposed methodology would\nfacilitate people from diverse backgrounds to enter the field\n  Application design: The introductory quantum physics content is bypassed and\nthe quantum computing concepts are introduced through linear algebra instead.\nQuantum programming tasks are prepared in line with the content. Pre/post-test\ndesign method and Likert scale satisfaction surveys are utilized to measure\nknowledge acquisition and to evaluate the perception of the learning process by\nthe participants.\n  Findings: Conducted pre/post-test design survey shows that there is a\nstatistically significant increase in the basic knowledge levels of the\nparticipants on quantum computing concepts. Furthermore, no significant\ndifference in the gain scores is observed between the participants from\ndifferent STEM-related educational backgrounds. The majority of the\nparticipants were satisfied and provided positive feedback.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:15:34 GMT"},{"version":"v2","created":"Tue, 27 Oct 2020 19:38:45 GMT"},{"version":"v3","created":"Mon, 7 Dec 2020 18:05:38 GMT"},{"version":"v4","created":"Tue, 11 May 2021 20:29:35 GMT"}],"update_date":"2021-05-31"}
{"id":"2010.13628","submitter":"Rajendra Gupta","authors":"Rajendra P. Gupta","title":"Varying physical constants and the lithium problem","comments":"8 pages, 2 figures, thoroughly revised as published with typos\n  corrected. Critical comments welcomed","journal-ref":"Astroparticle Physics (2021) 129, 102578","doi":"10.1016/j.astropartphys.2021.102578","report-no":null,"categories":"gr-qc astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have used the recently published varying physical constants (VPC) approach\nto resolve the primordial lithium abundance problem. The value of the ratio of\n$7Li$ to hydrogen $7Li/H=1.400(\\pm 0.023){\\times}10^{-10}$ we have calculated\nusing this approach is about four times lower than that estimated using the\nstandard lambda cold dark matter (${\\Lambda}$CDM) cosmological model, and is\nconsistent with the most agreed observational value of $1.6(\\pm\n0.3){\\times}10^{-10}$. In the VPC approach Einstein equations are modified to\ninclude the variation of the speed of light $c$, gravitational constant $G$ and\ncosmological constant ${\\Lambda}$ using the Einstein-Hilbert action.\nApplication of this approach to cosmology naturally leads to the variation of\nthe Plank constant $\\hbar$ and the Boltzmann constant $k_B$ as well. They\napproach fixed values at the scale factor $a\\ll 1$: $c=c_0/e$, $G=G_0/e^3$,\n$\\hbar=\\hbar_0/e$ and $k_B=k_{B0}/e^{5/4}$, where $e$ is the Euler's number\n(=2.7183). Since the VPC cosmology reduces to the same form as the\n${\\Lambda}$CDM cosmology at very small scale factors, we could use an existing\nBig-Bang nucleosynthesis (BBN) code AlterBBN with the above changes to\ncalculate the light element abundances under the VPC cosmology. Among other\nabundances we have calculated at baryon to photon ratio\n${\\eta}=6.1{\\times}10^{-10}$ are: $4He/H =0.2478 (\\pm 0.041)$, $D/H =2.453(\\pm\n0.041){\\times}10^{-5}$ and $3 He/H=2.940(\\pm 0.049){\\times}10^{-5}$.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:13:47 GMT"},{"version":"v2","created":"Tue, 5 Jan 2021 16:53:35 GMT"},{"version":"v3","created":"Thu, 24 Mar 2022 01:15:39 GMT"}],"update_date":"2022-03-25"}
{"id":"2010.13777","submitter":"Artur Czerwinski","authors":"Artur Czerwinski","title":"Quantum state tomography with informationally complete POVMs generated\n  in the time domain","comments":null,"journal-ref":"Quantum Inf. Process. 20, 105 (2021)","doi":"10.1007/s11128-021-03045-9","report-no":null,"categories":"quant-ph math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The article establishes a framework for dynamic generation of informationally\ncomplete POVMs in quantum state tomography. Assuming that the evolution of a\nquantum system is given by a dynamical map in the Kraus representation, one can\nswitch to the Heisenberg picture and define the measurements in the time\ndomain. Consequently, starting with an incomplete set of positive operators,\none can obtain sufficient information for quantum state reconstruction by\nmultiple measurements. The framework has been demonstrated on qubits and\nqutrits. For some types of dynamical maps, it suffices to initially have one\nmeasurement operator. The results demonstrate that quantum state tomography is\nfeasible even with limited measurement potential.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:17:37 GMT"},{"version":"v2","created":"Fri, 12 Mar 2021 09:00:55 GMT"}],"update_date":"2021-03-15"}
{"id":"2010.13778","submitter":"David Steuerman","authors":"Clarice D. Aiello, D. D. Awschalom, Hannes Bernien, Tina\n  Brower-Thomas, Kenneth R. Brown, Todd A. Brun, Justin R. Caram, Eric\n  Chitambar, Rosa Di Felice, Michael F. J. Fox, Stephan Haas, Alexander W.\n  Holleitner, Eric R. Hudson, Jeffrey H. Hunt, Robert Joynt, Scott Koziol, H.\n  J. Lewandowski, Douglas T. McClure, Jens Palsberg, Gina Passante, Kristen L.\n  Pudenz, Christopher J.K. Richardson, Jessica L. Rosenberg, R. S. Ross, Mark\n  Saffman, M. Singh, David W. Steuerman, Chad Stark, Jos Thijssen, A. Nick\n  Vamivakas, James D. Whitfield, Benjamin M. Zwickl","title":"Achieving a quantum smart workforce","comments":"18 pages, 2 figures, 1 table","journal-ref":"Quantum Sci. Technol. 6 030501 (2021)","doi":"10.1088/2058-9565/abfa64","report-no":null,"categories":"physics.ed-ph cs.ET cs.GL quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Interest in building dedicated Quantum Information Science and Engineering\n(QISE) education programs has greatly expanded in recent years. These programs\nare inherently convergent, complex, often resource intensive and likely require\ncollaboration with a broad variety of stakeholders. In order to address this\ncombination of challenges, we have captured ideas from many members in the\ncommunity. This manuscript not only addresses policy makers and funding\nagencies (both public and private and from the regional to the international\nlevel) but also contains needs identified by industry leaders and discusses the\ndifficulties inherent in creating an inclusive QISE curriculum. We report on\nthe status of eighteen post-secondary education programs in QISE and provide\nguidance for building new programs. Lastly, we encourage the development of a\ncomprehensive strategic plan for quantum education and workforce development as\na means to make the most of the ongoing substantial investments being made in\nQISE.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:24:57 GMT"}],"update_date":"2021-06-25"}
{"id":"2010.13779","submitter":"Kexin Yang","authors":"Kexin Yang, Xiaofei Zhou, Iulian Radu","title":"XR-Ed Framework: Designing Instruction-driven andLearner-centered\n  Extended Reality Systems for Education","comments":"In Submission","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, the HCI community has seen an increased interest in applying\nVirtual Reality (VR), AugmentedReality (AR) and Mixed Reality (MR) into\neducational settings. Despite many literature reviews, there stilllacks a clear\nframework that reveals the different design dimensions in educational Extended\nReality (XR)systems. Addressing this gap, we synthesize a broad range of\neducational XR to propose the XR-Ed framework,which reveals design space in six\ndimensions (Physical Accessibility, Scenario, Social Interactivity,\nAgency,Virtuality Degree, Assessment). Within each dimension, we contextualize\nthe framework using existing designcases. Based on the XR-Ed Design framework,\nwe incorporated instructional design approaches to proposeXR-Ins, an\ninstruction-oriented, step-by-step guideline in educational XR instruction\ndesign. Jointly, they aimto support practitioners by revealing implicit design\nchoices, offering design inspirations as well as guide themto design\ninstructional activities for XR technologies in a more instruction-oriented and\nlearner-centered way.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:18:05 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.13900","submitter":"Tirtharaj Dash","authors":"Tirtharaj Dash, Ashwin Srinivasan, Lovekesh Vig","title":"Incorporating Symbolic Domain Knowledge into Graph Neural Networks","comments":"Accepted in Machine Learning Journal (MLJ)","journal-ref":"Mach Learn 110, 1609-1636 (2021)","doi":"10.1007/s10994-021-05966-z","report-no":null,"categories":"cs.LG cs.AI cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Our interest is in scientific problems with the following characteristics:\n(1) Data are naturally represented as graphs; (2) The amount of data available\nis typically small; and (3) There is significant domain-knowledge, usually\nexpressed in some symbolic form. These kinds of problems have been addressed\neffectively in the past by Inductive Logic Programming (ILP), by virtue of 2\nimportant characteristics: (a) The use of a representation language that easily\ncaptures the relation encoded in graph-structured data, and (b) The inclusion\nof prior information encoded as domain-specific relations, that can alleviate\nproblems of data scarcity, and construct new relations. Recent advances have\nseen the emergence of deep neural networks specifically developed for\ngraph-structured data (Graph-based Neural Networks, or GNNs). While GNNs have\nbeen shown to be able to handle graph-structured data, less has been done to\ninvestigate the inclusion of domain-knowledge. Here we investigate this aspect\nof GNNs empirically by employing an operation we term \"vertex-enrichment\" and\ndenote the corresponding GNNs as \"VEGNNs\". Using over 70 real-world datasets\nand substantial amounts of symbolic domain-knowledge, we examine the result of\nvertex-enrichment across 5 different variants of GNNs. Our results provide\nsupport for the following: (a) Inclusion of domain-knowledge by\nvertex-enrichment can significantly improve the performance of a GNN. That is,\nthe performance VEGNNs is significantly better than GNNs across all GNN\nvariants; (b) The inclusion of domain-specific relations constructed using ILP\nimproves the performance of VEGNNs, across all GNN variants. Taken together,\nthe results provide evidence that it is possible to incorporate symbolic domain\nknowledge into a GNN, and that ILP can play an important role in providing\nhigh-level relationships that are not easily discovered by a GNN.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:22:21 GMT"},{"version":"v2","created":"Fri, 19 Feb 2021 15:55:52 GMT"}],"update_date":"2021-08-17"}
{"id":"2010.14055","submitter":"Georgios Laskaris","authors":"G.Laskaris, W.Ji, X.Yan, J.Zhou, W.R.Zimmerman, M.W.Ahmed, T.Averett,\n  A.Deltuva, A.C.Fonseca, H.Gao, J.Golak, A.Kafkarkou, H.J.Karwowski,\n  B.Lalremruata, J.Manfredi, J.M.Mueller, P.U.Sauer, R.Skibi\\'nski, A.P.Smith,\n  M.B.Tsang, H.R.Weller, H.Wita{\\l}a, Y.K.Wu and Z.W.Zhao","title":"First Measurement of the Asymmetry and the Gerasimov-Drell-Hearn\n  Integrand from $\\vec{{^3}He}(\\vec{\\gamma},p)d$ reaction at the Incident\n  Photon Energy of 29 MeV","comments":"5 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1304.5442","journal-ref":"Phys. Rev. C 103, 034311 (2021)","doi":"10.1103/PhysRevC.103.034311","report-no":null,"categories":"nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The first measurement of the $\\vec{^3He}(\\vec{\\gamma},p)d$ process was\nperformed at the High Intensity $\\gamma$-ray Source (HI$\\gamma$S) facility at\nTriangle Universities Nuclear Laboratory (TUNL) using a circularly polarized,\nmonoenergetic $\\gamma$-ray beam and a longitudinally polarized $^3$He target.\nThe spin-dependent asymmetry and the contribution from the two-body\nphotodisintegration to the $^3$He Gerasimov-Drell-Hearn integrand are extracted\nand compared with state-of-the-art three-nucleon system calculations at the\nincident photon energy of 29.0 MeV. The data are in general agreement with the\nvarious theoretical predictions based on the Siegert theorem or on explicit\ninclusion of meson-exchange currents.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:34:21 GMT"}],"update_date":"2021-03-17"}
{"id":"2010.14056","submitter":"Sean Plummer","authors":"Sean Plummer, Shuang Zhou, Anirban Bhattacharya, David Dunson, Debdeep\n  Pati","title":"Statistical Guarantees for Transformation Based Models with Applications\n  to Implicit Variational Inference","comments":"First two authors contributed equally to this work. arXiv admin note:\n  text overlap with arXiv:1701.07572","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST cs.LG stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transformation-based methods have been an attractive approach in\nnon-parametric inference for problems such as unconditional and conditional\ndensity estimation due to their unique hierarchical structure that models the\ndata as flexible transformation of a set of common latent variables. More\nrecently, transformation-based models have been used in variational inference\n(VI) to construct flexible implicit families of variational distributions.\nHowever, their use in both non-parametric inference and variational inference\nlacks theoretical justification. We provide theoretical justification for the\nuse of non-linear latent variable models (NL-LVMs) in non-parametric inference\nby showing that the support of the transformation induced prior in the space of\ndensities is sufficiently large in the $L_1$ sense. We also show that, when a\nGaussian process (GP) prior is placed on the transformation function, the\nposterior concentrates at the optimal rate up to a logarithmic factor. Adopting\nthe flexibility demonstrated in the non-parametric setting, we use the NL-LVM\nto construct an implicit family of variational distributions, deemed GP-IVI. We\ndelineate sufficient conditions under which GP-IVI achieves optimal risk bounds\nand approximates the true posterior in the sense of the Kullback-Leibler\ndivergence. To the best of our knowledge, this is the first work on providing\ntheoretical guarantees for implicit variational inference.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:06:29 GMT"},{"version":"v2","created":"Wed, 4 Nov 2020 20:02:43 GMT"}],"update_date":"2020-11-06"}
{"id":"2010.14057","submitter":"Debasish Chakroborti","authors":"Debasish Chakroborti","title":"An Intermediate Data-driven Methodology for Scientific Workflow\n  Management System to Support Reusability","comments":"Preprint. arXiv admin note: text overlap with arXiv:2010.04880","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this thesis first we propose an intermediate data management scheme for a\nSWfMS. In our second attempt, we explored the possibilities and introduced an\nautomatic recommendation technique for a SWfMS from real-world workflow data\n(i.e Galaxy [1] workflows) where our investigations show that the proposed\ntechnique can facilitate 51% of workflow building in a SWfMS by reusing\nintermediate data of previous workflows and can reduce 74% execution time of\nworkflow buildings in a SWfMS. Later we propose an adaptive version of our\ntechnique by considering the states of tools in a SWfMS, which shows around 40%\nreusability for workflows. Consequently, in our fourth study, We have done\nseveral experiments for analyzing the performance and exploring the\neffectiveness of the technique in a SWfMS for various environments. The\ntechnique is introduced to emphasize on storing cost reduction, increase data\nreusability, and faster workflow execution, to the best of our knowledge, which\nis the first of its kind. Detail architecture and evaluation of the technique\nare presented in this thesis. We believe our findings and developed system will\ncontribute significantly to the research domain of SWfMSs.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:27:25 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.14058","submitter":"Ryan Rossi","authors":"Ryan A. Rossi, Nesreen K. Ahmed, Aldo Carranza, David Arbour, Anup\n  Rao, Sungchul Kim, Eunyee Koh","title":"Heterogeneous Graphlets","comments":"arXiv admin note: substantial text overlap with arXiv:1901.10026","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.DS cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we introduce a generalization of graphlets to heterogeneous\nnetworks called typed graphlets. Informally, typed graphlets are small typed\ninduced subgraphs. Typed graphlets generalize graphlets to rich heterogeneous\nnetworks as they explicitly capture the higher-order typed connectivity\npatterns in such networks. To address this problem, we describe a general\nframework for counting the occurrences of such typed graphlets. The proposed\nalgorithms leverage a number of combinatorial relationships for different typed\ngraphlets. For each edge, we count a few typed graphlets, and with these counts\nalong with the combinatorial relationships, we obtain the exact counts of the\nother typed graphlets in o(1) constant time. Notably, the worst-case time\ncomplexity of the proposed approach matches the time complexity of the best\nknown untyped algorithm. In addition, the approach lends itself to an efficient\nlock-free and asynchronous parallel implementation. While there are no existing\nmethods for typed graphlets, there has been some work that focused on computing\na different and much simpler notion called colored graphlet. The experiments\nconfirm that our proposed approach is orders of magnitude faster and more\nspace-efficient than methods for computing the simpler notion of colored\ngraphlet. Unlike these methods that take hours on small networks, the proposed\napproach takes only seconds on large networks with millions of edges. Notably,\nsince typed graphlet is more general than colored graphlet (and untyped\ngraphlets), the counts of various typed graphlets can be combined to obtain the\ncounts of the much simpler notion of colored graphlets. The proposed methods\ngive rise to new opportunities and applications for typed graphlets.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 22:22:55 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.14059","submitter":"Mu-Tao Wang","authors":"Mu-Tao Wang","title":"Limits of quasi-local angular momentum on an isolated gravitating system","comments":"Conference on Differential Geometry, Calabi-Yau Theory, and General\n  Relativity in celebration of the 70th Birthday of Shing-Tung Yau. arXiv admin\n  note: text overlap with arXiv:2003.07732","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc math-ph math.AP math.DG math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  I shall discuss the Chen-Wang-Yau quasilocal angular momentum, which is\ndefined based on the theory of optimal isometric embedding and quasilocal mass\nof Wang-Yau, and the limits of which at spatial and null infinity of an\nisolated gravitating system. This is based on joint work with Po-Ning Chen,\nJordan Keller, Ye-Kai Wang, and Shing-Tung Yau.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:39:08 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.14061","submitter":"Yan Zeng","authors":"Yan Zeng and Jian-Yun Nie","title":"Jointly Optimizing State Operation Prediction and Value Generation for\n  Dialogue State Tracking","comments":"8 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We investigate the problem of multi-domain Dialogue State Tracking (DST) with\nopen vocabulary. Existing approaches exploit BERT encoder and copy-based RNN\ndecoder, where the encoder predicts the state operation, and the decoder\ngenerates new slot values. However, in such a stacked encoder-decoder\nstructure, the operation prediction objective only affects the BERT encoder and\nthe value generation objective mainly affects the RNN decoder. In this paper,\nwe propose a purely Transformer-based framework, where a single BERT works as\nboth the encoder and the decoder. In so doing, the operation prediction\nobjective and the value generation objective can jointly optimize this BERT for\nDST. At the decoding step, we re-use the hidden states of the encoder in the\nself-attention mechanism of the corresponding decoder layers to construct a\nflat encoder-decoder architecture for effective parameter updating.\nExperimental results show that our approach substantially outperforms the\nexisting state-of-the-art framework, and it also achieves very competitive\nperformance to the best ontology-based approaches.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:54:52 GMT"},{"version":"v2","created":"Thu, 8 Apr 2021 02:04:05 GMT"}],"update_date":"2021-04-09"}
{"id":"2010.14062","submitter":"Pablo Ducru","authors":"Pablo Ducru and Vladimir Sobes and Gerald Hale and Mark Paris and\n  Benoit Forget","title":"Scattering matrix pole expansions for complex wavenumbers in $R$-matrix\n  theory","comments":"Under review in Phys. Rev. C. 23 pages, 1 figure, 1 table. arXiv\n  admin note: substantial text overlap with arXiv:1903.02661","journal-ref":"Phys. Rev. C 103, 064609 (2021)","doi":"10.1103/PhysRevC.103.064609","report-no":null,"categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this follow-up article to [Shadow poles in the alternative parametrization\nof R-matrix theory, Ducru (2020)], we establish new results on scattering\nmatrix pole expansions for complex wavenumbers in R-matrix theory. In the past,\ntwo branches of theoretical formalisms emerged to describe the scattering\nmatrix in nuclear physics: R-matrix theory, and pole expansions. The two have\nbeen quite isolated from one another. Recently, our study of Brune's\nalternative parametrization of R-matrix theory has shown the need to extend the\nscattering matrix (and the underlying R-matrix operators) to complex\nwavenumbers. Two competing ways of doing so have emerged from a historical\nambiguity in the definitions of the shift $\\boldsymbol{S}$ and penetration\n$\\boldsymbol{P}$ functions: the legacy Lane \\& Thomas \"force closure\" approach,\nversus analytic continuation (which is the standard in mathematical physics).\nThe R-matrix community has not yet come to a consensus as to which to adopt for\nevaluations in standard nuclear data libraries, such as ENDF.\n  In this article, we argue in favor of analytic continuation of R-matrix\noperators. We bridge R-matrix theory with the Humblet-Rosenfeld pole\nexpansions, and unveil new properties of the Siegert-Humblet radioactive poles\nand widths, including their invariance properties to changes in channel radii\n$a_c$. We then show that analytic continuation of R-matrix operators preserves\nimportant physical and mathematical properties of the scattering matrix --\ncancelling spurious poles and guaranteeing generalized unitarity -- while still\nbeing able to close channels below thresholds.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 05:13:01 GMT"}],"update_date":"2021-06-23"}
{"id":"2010.14063","submitter":"Khalide Jbilou","authors":"A. El Ichi, K. Jbilou and R. Sadaka","title":"On some tensor tubal-Krylov subspace methods via the T-product","comments":"arXiv admin note: text overlap with arXiv:2006.07133","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the present paper, we introduce new tensor Krylov subspace methods for\nsolving linear tensor equations. The proposed methods use the well known\nT-product for tensors and tensor subspaces related to tube fibers. We introduce\nsome new tensor products and the related algebraic properties. These new\nproducts will enable us to develop third-order the tensor tubal GMRES and the\ntensor tubal Golub Kahan methods. We give some properties related to these\nmethods and proopse some numerical experiments.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:04:05 GMT"},{"version":"v2","created":"Sat, 27 Feb 2021 12:11:28 GMT"}],"update_date":"2021-03-02"}
{"id":"2010.14227","submitter":"Quanming Yao","authors":"Yongqi Zhang and Quanming Yao and Lei Chen","title":"Efficient, Simple and Automated Negative Sampling for Knowledge Graph\n  Embedding","comments":"VLDB Journal accepted. arXiv admin note: text overlap with\n  arXiv:1812.06410","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.DB","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Negative sampling, which samples negative triplets from non-observed ones in\nknowledge graph (KG), is an essential step in KG embedding. Recently,\ngenerative adversarial network (GAN), has been introduced in negative sampling.\nBy sampling negative triplets with large gradients, these methods avoid the\nproblem of vanishing gradient and thus obtain better performance. However, they\nmake the original model more complex and harder to train. In this paper,\nmotivated by the observation that negative triplets with large gradients are\nimportant but rare, we propose to directly keep track of them with the cache.\nIn this way, our method acts as a \"distilled\" version of previous GAN-based\nmethods, which does not waste training time on additional parameters to fit the\nfull distribution of negative triplets. However, how to sample from and update\nthe cache are two critical questions. We propose to solve these issues by\nautomated machine learning techniques. The automated version also covers\nGAN-based methods as special cases. Theoretical explanation of NSCaching is\nalso provided, justifying the superior over fixed sampling scheme. Besides, we\nfurther extend NSCaching with skip-gram model for graph embedding. Finally,\nextensive experiments show that our method can gain significant improvements on\nvarious KG embedding models and the skip-gram model, and outperforms the\nstate-of-the-art negative sampling methods.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:16:35 GMT"},{"version":"v2","created":"Wed, 14 Jul 2021 01:52:43 GMT"}],"update_date":"2021-07-15"}
{"id":"2010.14229","submitter":"Arindam Mishra","authors":"Suman Saha, Arindam Mishra, Syamal K. Dana, Chittaranjan Hens,\n  Nandadulal Bairagi","title":"Infection spreading and recovery in a square lattice","comments":"Accepted in Physical Review E","journal-ref":null,"doi":"10.1103/PhysRevE.102.052307","report-no":null,"categories":"q-bio.PE nlin.CD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate spreading and recovery of disease in a square lattice, and in\nparticular, emphasize the role of the initial distribution of infected patches\nin the network, on the progression of an endemic and initiation of a recovery\nprocess, if any, due to migration of both the susceptible and infected hosts.\nThe disease starts in the lattice with three possible initial distribution\npatterns of infected and infection-free sites, infected core patches (ICP),\ninfected peripheral patches (IPP) and randomly distributed infected patches\n(RDIP). Our results show that infection spreads monotonically in the lattice\nwith increasing migration without showing any sign of recovery in the ICP case.\nIn the IPP case, it follows a similar monotonic progression with increasing\nmigration, however, a self-organized healing process starts for higher\nmigration, leading the lattice to full recovery at a critical rate of\nmigration. Encouragingly, for the initial RDIP arrangement, chances of recovery\nare much higher with a lower rate of critical migration. An eigenvalue based\nsemi-analytical study is made to determine the critical migration rate for\nrealizing a stable infection-free lattice. The initial fraction of infected\npatches and the force of infection play significant roles in the self-organized\nrecovery. They follow an exponential law, for the RDIP case, that governs the\nrecovery process. For the frustrating case of ICP arrangement, we propose a\nrandom rewiring of links in the lattice allowing long-distance migratory paths\nthat effectively initiate a recovery process. Global prevalence of infection\nthereby declines and progressively improves with the rewiring probability that\nfollows a power law with the critical migration and leads to the birth of\nemergent infection-free networks.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:17:37 GMT"}],"update_date":"2020-12-02"}
{"id":"2010.14230","submitter":"Yuhao Zhou","authors":"Henry Zhou, Alexei Baevski and Michael Auli","title":"A Comparison of Discrete Latent Variable Models for Speech\n  Representation Learning","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.LG cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural latent variable models enable the discovery of interesting structure\nin speech audio data. This paper presents a comparison of two different\napproaches which are broadly based on predicting future time-steps or\nauto-encoding the input signal. Our study compares the representations learned\nby vq-vae and vq-wav2vec in terms of sub-word unit discovery and phoneme\nrecognition performance. Results show that future time-step prediction with\nvq-wav2vec achieves better performance. The best system achieves an error rate\nof 13.22 on the ZeroSpeech 2019 ABX phoneme discrimination challenge\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 01:22:14 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.14233","submitter":"Ethan Chi","authors":"Ethan A. Chi, Julian Salazar, and Katrin Kirchhoff","title":"Align-Refine: Non-Autoregressive Speech Recognition via Iterative\n  Realignment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.LG cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-autoregressive models greatly improve decoding speed over typical\nsequence-to-sequence models, but suffer from degraded performance. Infilling\nand iterative refinement models make up some of this gap by editing the outputs\nof a non-autoregressive model, but are constrained in the edits that they can\nmake. We propose iterative realignment, where refinements occur over latent\nalignments rather than output sequence space. We demonstrate this in speech\nrecognition with Align-Refine, an end-to-end Transformer-based model which\nrefines connectionist temporal classification (CTC) alignments to allow\nlength-changing insertions and deletions. Align-Refine outperforms Imputer and\nMask-CTC, matching an autoregressive baseline on WSJ at 1/14th the real-time\nfactor and attaining a LibriSpeech test-other WER of 9.0% without an LM. Our\nmodel is strong even in one iteration with a shallower decoder.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 09:35:37 GMT"}],"update_date":"2020-10-28"}
{"id":"2010.14359","submitter":"Siva Rajesh Kasa","authors":"Siva Rajesh Kasa and Vaibhav Rajan","title":"Improved Inference of Gaussian Mixture Copula Model for Clustering and\n  Reproducibility Analysis using Automatic Differentiation","comments":null,"journal-ref":null,"doi":"10.1016/j.ecosta.2021.08.010","report-no":null,"categories":"stat.ME stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Copulas provide a modular parameterization of multivariate distributions that\ndecouples the modeling of marginals from the dependencies between them.\nGaussian Mixture Copula Model (GMCM) is a highly flexible copula that can model\nmany kinds of multi-modal dependencies, as well as asymmetric and tail\ndependencies. They have been effectively used in clustering non-Gaussian data\nand in Reproducibility Analysis, a meta-analysis method designed to verify the\nreliability and consistency of multiple high-throughput experiments. Parameter\nestimation for GMCM is challenging due to its intractable likelihood. The best\nprevious methods have maximized a proxy-likelihood through a Pseudo Expectation\nMaximization (PEM) algorithm. They have no guarantees of convergence or\nconvergence to the correct parameters. In this paper, we use Automatic\nDifferentiation (AD) tools to develop a method, called AD-GMCM, that can\nmaximize the exact GMCM likelihood. In our simulation studies and experiments\nwith real data, AD-GMCM finds more accurate parameter estimates than PEM and\nyields better performance in clustering and Reproducibility Analysis. We\ndiscuss the advantages of an AD-based approach, to address problems related to\nmonotonic increase of likelihood and parameter identifiability in GMCM. We also\nanalyze, for GMCM, two well-known cases of degeneracy of maximum likelihood in\nGMM that can lead to spurious clustering solutions. Our analysis shows that,\nunlike GMM, GMCM is not affected in one of the cases.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:37:33 GMT"}],"update_date":"2021-09-29"}
{"id":"2010.14439","submitter":"Bill Yuchen Lin","authors":"Bill Yuchen Lin, Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Xiang\n  Ren, William W. Cohen","title":"Differentiable Open-Ended Commonsense Reasoning","comments":"Accepted to NAACL 2021. Project website: https://open-csr.github.io","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:07:00 GMT"},{"version":"v2","created":"Sun, 6 Jun 2021 20:20:27 GMT"}],"update_date":"2021-06-08"}
{"id":"2010.14620","submitter":"Louis Chen","authors":"Louis Chen, Divya Padmanabhan, Chee Chin Lim, Karthik Natarajan","title":"Correlation Robust Influence Maximization","comments":null,"journal-ref":"34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada","doi":null,"report-no":null,"categories":"cs.SI cs.AI cs.DS cs.LG math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a distributionally robust model for the influence maximization\nproblem. Unlike the classic independent cascade model\n\\citep{kempe2003maximizing}, this model's diffusion process is adversarially\nadapted to the choice of seed set. Hence, instead of optimizing under the\nassumption that all influence relationships in the network are independent, we\nseek a seed set whose expected influence under the worst correlation, i.e. the\n\"worst-case, expected influence\", is maximized. We show that this worst-case\ninfluence can be efficiently computed, and though the optimization is NP-hard,\na ($1 - 1/e$) approximation guarantee holds. We also analyze the structure to\nthe adversary's choice of diffusion process, and contrast with established\nmodels. Beyond the key computational advantages, we also highlight the extent\nto which the independence assumption may cost optimality, and provide insights\nfrom numerical experiments comparing the adversarial and independent cascade\nmodel.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 04:43:56 GMT"},{"version":"v2","created":"Tue, 22 Feb 2022 05:51:28 GMT"}],"update_date":"2022-02-23"}
{"id":"2010.14622","submitter":"Runbing Zheng","authors":"Runbing Zheng, Vince Lyzinski, Carey E. Priebe and Minh Tang","title":"Vertex nomination between graphs via spectral embedding and quadratic\n  programming","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a network and a subset of interesting vertices whose identities are\nonly partially known, the vertex nomination problem seeks to rank the remaining\nvertices in such a way that the interesting vertices are ranked at the top of\nthe list. An important variant of this problem is vertex nomination in the\nmulti-graphs setting. Given two graphs $G_1, G_2$ with common vertices and a\nvertex of interest $x \\in G_1$, we wish to rank the vertices of $G_2$ such that\nthe vertices most similar to $x$ are ranked at the top of the list. The current\npaper addresses this problem and proposes a method that first applies adjacency\nspectral graph embedding to embed the graphs into a common Euclidean space, and\nthen solves a penalized linear assignment problem to obtain the nomination\nlists. Since the spectral embedding of the graphs are only unique up to\northogonal transformations, we present two approaches to eliminate this\npotential non-identifiability. One approach is based on orthogonal Procrustes\nand is applicable when there are enough vertices with known correspondence\nbetween the two graphs. Another approach uses adaptive point set registration\nand is applicable when there are few or no vertices with known correspondence.\nWe show that our nomination scheme leads to accurate nomination under a\ngenerative model for pairs of random graphs that are approximately low-rank and\npossibly with pairwise edge correlations. We illustrate our algorithm's\nperformance through simulation studies on synthetic data as well as analysis of\na high-school friendship network and analysis of transition rates between web\npages on the Bing search engine.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:50:29 GMT"},{"version":"v2","created":"Tue, 2 Feb 2021 17:50:13 GMT"},{"version":"v3","created":"Tue, 26 Oct 2021 05:58:21 GMT"},{"version":"v4","created":"Sun, 27 Mar 2022 18:47:13 GMT"}],"update_date":"2022-03-29"}
{"id":"2010.14623","submitter":"Zbigniew Palmowski","authors":"Zbigniew Palmowski and Daria Puchalska","title":"Modeling social media contagion using Hawkes processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The contagion dynamics can emerge in social networks when repeated activation\nis allowed. An interesting example of this phenomenon is retweet cascades where\nusers allow to re-share content posted by other people with public accounts. To\nmodel this type of behaviour we use a Hawkes self-exciting process. To do it\nproperly though one needs to calibrate model under consideration. The main goal\nof this paper is to construct moments method of estimation of this model. The\nkey step is based on identifying of a generator of a Hawkes process. We perform\nnumerical analysis on real data as well.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 11:40:21 GMT"},{"version":"v2","created":"Mon, 2 Nov 2020 11:54:52 GMT"}],"update_date":"2020-11-03"}
{"id":"2010.14624","submitter":"Gourab K Patro","authors":"Gourab K Patro, Abhijnan Chakraborty, Niloy Ganguly, Krishna P.\n  Gummadi","title":"On Fair Virtual Conference Scheduling: Achieving Equitable Participant\n  and Speaker Satisfaction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.AI cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The (COVID-19) pandemic-induced restrictions on travel and social gatherings\nhave prompted most conference organizers to move their events online. However,\nin contrast to physical conferences, virtual conferences face a challenge in\nefficiently scheduling talks, accounting for the availability of participants\nfrom different time-zones as well as their interests in attending different\ntalks. In such settings, a natural objective for the conference organizers\nwould be to maximize some global welfare measure, such as the total expected\naudience participation across all talks. However, we show that optimizing for\nglobal welfare could result in a schedule that is unfair to the stakeholders,\ni.e., the individual utilities for participants and speakers can be highly\nunequal. To address the fairness concerns, we formally define fairness notions\nfor participants and speakers, and subsequently derive suitable fairness\nobjectives for them. We show that the welfare and fairness objectives can be in\nconflict with each other, and there is a need to maintain a balance between\nthese objective while caring for them simultaneously. Thus, we propose a joint\noptimization framework that allows conference organizers to design talk\nschedules that balance (i.e., allow trade-offs) between global welfare,\nparticipant fairness and the speaker fairness objectives. We show that the\noptimization problem can be solved using integer linear programming, and\nempirically evaluate the necessity and benefits of such joint optimization\napproach in virtual conference scheduling.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:05:12 GMT"}],"update_date":"2020-10-29"}
{"id":"2010.14991","submitter":"John Russo","authors":"Daniel M. Zuckerman, John D. Russo","title":"A gentle introduction to the non-equilibrium physics of trajectories:\n  Theory, algorithms, and biomolecular applications","comments":null,"journal-ref":null,"doi":"10.1119/10.0005603","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite the importance of non-equilibrium statistical mechanics in modern\nphysics and related fields, the topic is often omitted from undergraduate and\ncore-graduate curricula. Key aspects of non-equilibrium physics, however, can\nbe understood with a minimum of formalism based on a rigorous trajectory\npicture. The fundamental object is the ensemble of trajectories, a set of\nindependent time-evolving systems that easily can be visualized or simulated\n(for protein folding, e.g.), and which can be analyzed rigorously in analogy to\nan ensemble of static system configurations. The trajectory picture provides a\nstraightforward basis for understanding first-passage times, \"mechanisms\" in\ncomplex systems, and fundamental constraints the apparent reversibility of\ncomplex processes. Trajectories make concrete the physics underlying the\ndiffusion and Fokker-Planck partial differential equations. Last but not least,\ntrajectory ensembles underpin some of the most important algorithms which have\nprovided significant advances in biomolecular studies of protein conformational\nand binding processes.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:19:30 GMT"},{"version":"v2","created":"Wed, 16 Jun 2021 21:33:08 GMT"},{"version":"v3","created":"Tue, 20 Jul 2021 17:32:04 GMT"}],"update_date":"2021-11-03"}
{"id":"2010.15245","submitter":"Wenhan Dai","authors":"Wenhan Dai (1), Zhi Zeng (1), Daowei Dou (1), Hao Ma (1), Jianping\n  Chen (1 and 2), Junli Li (1), Hui Zhang (1) ((1) Department of Engineering\n  Physics, Tsinghua University, Beijing, China, (2) College of Nuclear Science\n  and Technology, Beijing Normal University, Beijing, China)","title":"A marine radioisotope gamma-ray spectrum analysis method based on Monte\n  Carlo simulation and MLP neural network","comments":"13 pages, 11 figures","journal-ref":"Journal of Instrumentation. 16(06):P06030 (13pp) (2021)","doi":"10.1088/1748-0221/16/06/P06030","report-no":null,"categories":"physics.ins-det cs.LG physics.data-an","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The monitoring of Cs-137 in seawater using scintillation detector relies on\nthe spectrum analysis method to extract the Cs-137 concentration. And when in\npoor statistic situation, the calculation result of the traditional net peak\narea (NPA) method has a large uncertainty. We present a machine learning based\nmethod to better analyze the gamma-ray spectrum with low Cs-137 concentration.\nWe apply multilayer perceptron (MLP) to analyze the 662 keV full energy peak of\nCs-137 in the seawater spectrum. And the MLP can be trained with a few measured\nbackground spectrums by combining the simulated Cs-137 signal with measured\nbackground spectrums. Thus, it can save the time of preparing and measuring the\nstandard samples for generating the training dataset. To validate the MLP-based\nmethod, we use Geant4 and background gamma-ray spectrums measured by a seaborne\nmonitoring device to generate an independent test dataset to test the result by\nour method and the traditional NPA method. We find that the MLP-based method\nachieves a root mean squared error of 0.159, 2.3 times lower than that of the\ntraditional net peak area method, indicating the MLP-based method improves the\nprecision of Cs-137 concentration calculation\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:40:48 GMT"},{"version":"v2","created":"Thu, 19 Aug 2021 12:06:53 GMT"}],"update_date":"2021-08-20"}
{"id":"2010.15586","submitter":"Xianchao Wu","authors":"Xianchao Wu","title":"Event-Driven Learning of Systematic Behaviours in Stock Markets","comments":"11 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.ST cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is reported that financial news, especially financial events expressed in\nnews, provide information to investors' long/short decisions and influence the\nmovements of stock markets. Motivated by this, we leverage financial event\nstreams to train a classification neural network that detects latent\nevent-stock linkages and stock markets' systematic behaviours in the U.S. stock\nmarket. Our proposed pipeline includes (1) a combined event extraction method\nthat utilizes Open Information Extraction and neural co-reference resolution,\n(2) a BERT/ALBERT enhanced representation of events, and (3) an extended\nhierarchical attention network that includes attentions on event, news and\ntemporal levels. Our pipeline achieves significantly better accuracies and\nhigher simulated annualized returns than state-of-the-art models when being\napplied to predicting Standard\\&Poor 500, Dow Jones, Nasdaq indices and 10\nindividual stocks.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 16:14:25 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.15590","submitter":"Fabrice Muhlenbach","authors":"Fabrice Muhlenbach","title":"Enjeux \\'ethiques de l'IA en sant\\'e : une humanisation du parcours de\n  soin par l'intelligence artificielle ?","comments":"Preprint of a paper to appear in \"Soins Cadres\" journal, in French","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Considering the use of artificial intelligence for greater personalization of\npatient care and better management of human and material resources may seem\nlike an opportunity not to be missed. In order to offer a better humanization\nof the care pathway, artificial intelligence is a tool that decision-makers in\nthe hospital sector must appropriate by taking care of the new ethical issues\nand conflicts of values that this technology generates.\n  Envisager le recours \\`a l'intelligence artificielle pour une plus grande\npersonnalisation de la prise en charge du patient et une meilleure gestion des\nressources humaines et mat\\'erielles peut sembler une opportunit\\'e \\`a ne pas\nmanquer. Afin de proposer une meilleure humanisation du parcours de soin,\nl'intelligence artificielle est un outil que les d\\'ecideurs du milieu\nhospitalier doivent s'approprier en veillant aux nouveaux enjeux \\'ethiques et\nconflits de valeurs que cette technologie engendre.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 20:34:19 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.15591","submitter":"Baosong Wu","authors":"Baosong Wu","title":"Zero-dead Time NMR in Low Field: Single-Sideband Technique Revisited","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently the rapid-scan technique is reviving in NMR or EPR, because of its\nbenefits of zero-dead time and low RF power. While signal baseline is still a\nbig problem in such experiments, time-share method has been used to indirectly\navoid it. However, it is obviously not a truly zero-dead time method. Other\ndata-processing methods were also adopted to deal with raw data. Here we try to\nuse single-sideband technique at 11.4MHz to mitigate this obstacle. The\nprospect is that single sideband technique can be used in rapid-scan experiment\nfor low/high field imaging.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:37:18 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.15592","submitter":"Hung  Viet Chu Mr","authors":"Hung Viet Chu","title":"Difference in the Number of Summands in the Zeckendorf Partitions of\n  Consecutive Integers","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Zeckendorf proved that every positive integer has a unique partition as a sum\nof non-consecutive Fibonacci numbers. We study the difference between the\nnumber of summands in the partition of two consecutive integers. In particular,\nlet $L(n)$ be the number of summands in the partition of $n$. We characterize\nall positive integers such that $L(n) > L(n+1)$, $L(n) < L(n+1)$, and $L(n) =\nL(n+1)$. Furthermore, we call $n+1$ a peak of $L$ if $L(n) < L(n+1) > L(n+2)$\nand a divot of $L$ if $L(n) > L(n+1) < L(n+2)$. We characterize all such peaks\nand divots of $L$.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 03:51:59 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.15594","submitter":"Muhammad Yousefnezhad","authors":"Muhammad Yousefnezhad, Alessandro Selvitella, Daoqiang Zhang, Andrew\n  J. Greenshaw, Russell Greiner","title":"Shared Space Transfer Learning for analyzing multi-site fMRI data","comments":"34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada. The Supplementary Material:\n  https://www.yousefnezhad.com/publications/NeurIPS2020_Paper4157_SuppMat.zip","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI eess.IV math.FA q-bio.NC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-voxel pattern analysis (MVPA) learns predictive models from task-based\nfunctional magnetic resonance imaging (fMRI) data, for distinguishing when\nsubjects are performing different cognitive tasks -- e.g., watching movies or\nmaking decisions. MVPA works best with a well-designed feature set and an\nadequate sample size. However, most fMRI datasets are noisy, high-dimensional,\nexpensive to collect, and with small sample sizes. Further, training a robust,\ngeneralized predictive model that can analyze homogeneous cognitive tasks\nprovided by multi-site fMRI datasets has additional challenges. This paper\nproposes the Shared Space Transfer Learning (SSTL) as a novel transfer learning\n(TL) approach that can functionally align homogeneous multi-site fMRI datasets,\nand so improve the prediction performance in every site. SSTL first extracts a\nset of common features for all subjects in each site. It then uses TL to map\nthese site-specific features to a site-independent shared space in order to\nimprove the performance of the MVPA. SSTL uses a scalable optimization\nprocedure that works effectively for high-dimensional fMRI datasets. The\noptimization procedure extracts the common features for each site by using a\nsingle-iteration algorithm and maps these site-specific common features to the\nsite-independent shared space. We evaluate the effectiveness of the proposed\nmethod for transferring between various cognitive tasks. Our comprehensive\nexperiments validate that SSTL achieves superior performance to other\nstate-of-the-art analysis techniques.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 08:50:26 GMT"}],"update_date":"2020-10-30"}
{"id":"2010.15696","submitter":"Mathis Wiedeking","authors":"M. Wiedeking, M. Guttormsen, A.C. Larsen, F. Zeiser, A. G\\\"orgen, S.\n  N. Liddick, D. M\\\"ucher, S. Siem, and A. Spyrou","title":"Independent Normalization for $\\gamma$-ray Strength Functions: The Shape\n  Method","comments":"13 pages, 8 figures","journal-ref":"Phys. Rev. C 104, 014311 (2021)","doi":"10.1103/PhysRevC.104.014311","report-no":null,"categories":"physics.data-an nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Shape method, a novel approach to obtain the functional form of the\n$\\gamma$-ray strength function ($\\gamma$SF) in the absence of neutron resonance\nspacing data, is introduced. When used in connection with the Oslo method the\nslope of the Nuclear Level Density (NLD) is obtained simultaneously. The\nfoundation of the Shape method lies in the primary $\\gamma$-ray transitions\nwhich preserve information on the functional form of the $\\gamma$SF. The Shape\nmethod has been applied to $^{56}$Fe, $^{92}$Zr, $^{164}$Dy, and $^{240}$Pu,\nwhich are representative cases for the variety of situations encountered in\ntypical NLD and $\\gamma$SF studies. The comparisons of results from the Shape\nmethod to those from the Oslo method demonstrate that the functional form of\nthe $\\gamma$SF is retained regardless of nuclear structure details or $J^\\pi$\nvalues of the states fed by the primary transitions.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 15:01:31 GMT"}],"update_date":"2021-07-21"}
{"id":"2010.16243","submitter":"Dimiter Dobrev","authors":"Dimiter Dobrev","title":"Language for Description of Worlds","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We will reduce the task of creating AI to the task of finding an appropriate\nlanguage for description of the world. This will not be a programing language\nbecause programing languages describe only computable functions, while our\nlanguage will describe a somewhat broader class of functions. Another\nspecificity of this language will be that the description will consist of\nseparate modules. This will enable us look for the description of the world\nautomatically such that we discover it module after module. Our approach to the\ncreation of this new language will be to start with a particular world and\nwrite the description of that particular world. The point is that the language\nwhich can describe this particular world will be appropriate for describing any\nworld.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 14:13:51 GMT"},{"version":"v2","created":"Mon, 25 Jan 2021 08:38:37 GMT"},{"version":"v3","created":"Thu, 24 Jun 2021 13:01:20 GMT"},{"version":"v4","created":"Fri, 8 Jul 2022 20:55:01 GMT"}],"update_date":"2022-07-12"}
{"id":"2011.02288","submitter":"Sarah Cannon","authors":"Sarah Cannon, Ari Goldbloom-Helzner, Varun Gupta, JN Matthews, Bhushan\n  Suwal","title":"Voting Rights, Markov Chains, and Optimization by Short Bursts","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Finding outlying elements in probability distributions can be a hard problem.\nTaking a real example from Voting Rights Act enforcement, we consider the\nproblem of maximizing the number of simultaneous majority-minority districts in\na political districting plan. An unbiased random walk on districting plans is\nunlikely to find plans that approach this maximum. A common search approach is\nto use a biased random walk: preferentially select districting plans with more\nmajority-minority districts. Here, we present a third option, called short\nbursts, in which an unbiased random walk is performed for a small number of\nsteps (called the burst length), then re-started from the most extreme plan\nthat was encountered in the last burst. We give empirical evidence that\nshort-burst runs outperform biased random walks for the problem of maximizing\nthe number of majority-minority districts, and that there are many values of\nburst length for which we see this improvement. Abstracting from our use case,\nwe also consider short bursts where the underlying state space is a line with\nvarious probability distributions, and then explore some features of more\ncomplicated state spaces and how these impact the effectiveness of short\nbursts.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 17:41:30 GMT"},{"version":"v2","created":"Wed, 22 Jun 2022 17:44:46 GMT"}],"update_date":"2022-06-23"}
{"id":"2011.03526","submitter":"Camilo Rocha","authors":"Camila Riccio, Jorge Finke, Camilo Rocha","title":"Identifying Stress Responsive Genes using Overlapping Communities in\n  Co-expression Networks","comments":null,"journal-ref":null,"doi":"10.1186/s12859-021-04462-4","report-no":null,"categories":"q-bio.MN cs.LG cs.SI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper proposes a workflow to identify genes that respond to specific\ntreatments in plants. The workflow takes as input the RNA sequencing read\ncounts and phenotypical data of different genotypes, measured under control and\ntreatment conditions. It outputs a reduced group of genes marked as relevant\nfor treatment response. Technically, the proposed approach is both a\ngeneralization and an extension of WGCNA. It aims to identify specific modules\nof overlapping communities underlying the co-expression network of genes.\nModule detection is achieved by using Hierarchical Link Clustering. The\noverlapping nature of the systems' regulatory domains that generate\nco-expression can be identified by such modules. LASSO regression is employed\nto analyze phenotypic responses of modules to treatment.\n  Results. The workflow is applied to rice (Oryza sativa), a major food source\nknown to be highly sensitive to salt stress. The workflow identifies 19 rice\ngenes that seem relevant in the response to salt stress. They are distributed\nacross 6 modules: 3 modules, each grouping together 3 genes, are associated to\nshoot K content; 2 modules of 3 genes are associated to shoot biomass; and 1\nmodule of 4 genes is associated to root biomass. These genes represent target\ngenes for the improvement of salinity tolerance in rice.\n  Conclusion. A more effective framework to reduce the search-space for target\ngenes that respond to a specific treatment is introduced. It facilitates\nexperimental validation by restraining efforts to a smaller subset of genes of\nhigh potential relevance.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:14:59 GMT"},{"version":"v2","created":"Sat, 9 Apr 2022 17:22:53 GMT"}],"update_date":"2022-04-12"}
{"id":"2011.04512","submitter":"Dongyub Lee","authors":"Dongyub Lee, Byeongil Ko, Myeong Cheol Shin, Taesun Whang, Daniel Lee,\n  Eun Hwa Kim, EungGyun Kim, and Jaechoon Jo","title":"Auxiliary Sequence Labeling Tasks for Disfluency Detection","comments":"Submitted to INTERSPEECH 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Detecting disfluencies in spontaneous speech is an important preprocessing\nstep in natural language processing and speech recognition applications.\nExisting works for disfluency detection have focused on designing a single\nobjective only for disfluency detection, while auxiliary objectives utilizing\nlinguistic information of a word such as named entity or part-of-speech\ninformation can be effective. In this paper, we focus on detecting disfluencies\non spoken transcripts and propose a method utilizing named entity recognition\n(NER) and part-of-speech (POS) as auxiliary sequence labeling (SL) tasks for\ndisfluency detection. First, we investigate cases that utilizing linguistic\ninformation of a word can prevent mispredicting important words and can be\nhelpful for the correct detection of disfluencies. Second, we show that\ntraining a disfluency detection model with auxiliary SL tasks can improve its\nF-score in disfluency detection. Then, we analyze which auxiliary SL tasks are\ninfluential depending on baseline models. Experimental results on the widely\nused English Switchboard dataset show that our method outperforms the previous\nstate-of-the-art in disfluency detection.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:51:17 GMT"},{"version":"v2","created":"Mon, 5 Apr 2021 13:09:23 GMT"}],"update_date":"2021-04-06"}
{"id":"2011.04514","submitter":"Philipp del Hougne","authors":"Philipp del Hougne, K. Brahima Yeo, Philippe Besnier, Matthieu Davy","title":"Coherent wave control in complex media with arbitrary wavefronts","comments":"13 pages including 4 figures + 7 pages Supplemental Material","journal-ref":"Phys. Rev. Lett. 126, 193903 (2021)","doi":"10.1103/PhysRevLett.126.193903","report-no":null,"categories":"physics.app-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Wavefront shaping (WFS) has emerged as powerful tool to control the\npropagation of diverse wave phenomena (light, sound, microwaves, ...) in\ndisordered matter for applications including imaging, communication, energy\ntransfer, micromanipulation, and scattering anomalies. Nonetheless, in practice\nthe necessary coherent control of multiple input channels remains a vexing\nproblem. Here, we overcome this difficulty by doping the disordered medium with\nprogrammable meta-atoms in order to adapt it to an imposed arbitrary incoming\nwavefront. Besides lifting the need for carefully shaped incident wavefronts,\nour approach also unlocks new opportunities such as sequentially achieving\ndifferent functionalities with the same arbitrary wavefront. We demonstrate our\nconcept experimentally for electromagnetic waves using programmable\nmetasurfaces in a chaotic cavity, with applications to focusing with the\ngeneralized Wigner-Smith operator as well as coherent perfect absorption. We\nexpect our fundamentally new perspective on coherent wave control to facilitate\nthe transition of intricate WFS protocols into real applications for various\nwave phenomena.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 19:48:25 GMT"},{"version":"v2","created":"Thu, 18 Feb 2021 21:28:23 GMT"}],"update_date":"2021-05-14"}
{"id":"2011.05268","submitter":"Hanlin Zhang","authors":"Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun,\n  Chenyan Xiong, Jian Tang","title":"Towards Interpretable Natural Language Understanding with Explanations\n  as Latent Variables","comments":"NeurIPS 2020. The first three authors contribute equally","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently generating natural language explanations has shown very promising\nresults in not only offering interpretable explanations but also providing\nadditional information and supervision for prediction. However, existing\napproaches usually require a large set of human annotated explanations for\ntraining while collecting a large set of explanations is not only time\nconsuming but also expensive. In this paper, we develop a general framework for\ninterpretable natural language understanding that requires only a small set of\nhuman annotated explanations for training. Our framework treats natural\nlanguage explanations as latent variables that model the underlying reasoning\nprocess of a neural model. We develop a variational EM framework for\noptimization where an explanation generation module and an\nexplanation-augmented prediction module are alternatively optimized and\nmutually enhance each other. Moreover, we further propose an explanation-based\nself-training method under this framework for semi-supervised learning. It\nalternates between assigning pseudo-labels to unlabeled data and generating new\nexplanations to iteratively improve each other. Experiments on two natural\nlanguage understanding tasks demonstrate that our framework can not only make\neffective predictions in both supervised and semi-supervised settings, but also\ngenerate good natural language explanation.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 02:05:56 GMT"},{"version":"v2","created":"Tue, 29 Jun 2021 12:24:08 GMT"},{"version":"v3","created":"Thu, 26 May 2022 22:12:42 GMT"}],"update_date":"2022-05-30"}
{"id":"2011.07956","submitter":"Dong-Ho Lee","authors":"Wangchunshu Zhou, Dong-Ho Lee, Ravi Kiran Selvam, Seyeon Lee, Bill\n  Yuchen Lin, Xiang Ren","title":"Pre-training Text-to-Text Transformers for Concept-centric Common Sense","comments":"15 pages, 4 figures. Code and Data: https://github.com/INK-USC/CALM/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained language models (PTLM) have achieved impressive results in a\nrange of natural language understanding (NLU) and generation (NLG) tasks.\nHowever, current pre-training objectives such as masked token prediction (for\nBERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not\nexplicitly model the relational commonsense knowledge about everyday concepts,\nwhich is crucial to many downstream tasks that need common sense to understand\nor generate. To augment PTLMs with concept-centric commonsense knowledge, in\nthis paper, we propose both generative and contrastive objectives for learning\ncommon sense from the text, and use them as intermediate self-supervised\nlearning tasks for incrementally pre-training PTLMs (before task-specific\nfine-tuning on downstream datasets). Furthermore, we develop a joint\npre-training framework to unify generative and contrastive objectives so that\nthey can mutually reinforce each other. Extensive experimental results show\nthat our method, concept-aware language model (CALM), can pack more commonsense\nknowledge into the parameters of a pre-trained text-to-text transformer without\nrelying on external knowledge graphs, yielding better performance on both NLU\nand NLG tasks. We show that while only incrementally pre-trained on a\nrelatively small corpus for a few steps, CALM outperforms baseline methods by a\nconsistent margin and even comparable with some larger PTLMs, which suggests\nthat CALM can serve as a general, plug-and-play method for improving the\ncommonsense reasoning ability of a PTLM.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 07:00:37 GMT"},{"version":"v2","created":"Wed, 25 Nov 2020 04:53:38 GMT"}],"update_date":"2020-11-26"}
{"id":"2011.08065","submitter":"Debesh Jha","authors":"Debesh Jha, Sharib Ali, Krister Emanuelsen, Steven A. Hicks,\n  VajiraThambawita, Enrique Garcia-Ceja, Michael A. Riegler, Thomas de Lange,\n  Peter T. Schmidt, H{\\aa}vard D. Johansen, Dag Johansen, and P{\\aa}l Halvorsen","title":"Kvasir-Instrument: Diagnostic and therapeutic tool segmentation dataset\n  in gastrointestinal endoscopy","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph cs.CV cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Gastrointestinal (GI) pathologies are periodically screened, biopsied, and\nresected using surgical tools. Usually the procedures and the treated or\nresected areas are not specifically tracked or analysed during or after\ncolonoscopies. Information regarding disease borders, development and amount\nand size of the resected area get lost. This can lead to poor follow-up and\nbothersome reassessment difficulties post-treatment. To improve the current\nstandard and also to foster more research on the topic we have released the\n``Kvasir-Instrument'' dataset which consists of $590$ annotated frames\ncontaining GI procedure tools such as snares, balloons and biopsy forceps, etc.\nBeside of the images, the dataset includes ground truth masks and bounding\nboxes and has been verified by two expert GI endoscopists. Additionally, we\nprovide a baseline for the segmentation of the GI tools to promote research and\nalgorithm development. We obtained a dice coefficient score of 0.9158 and a\nJaccard index of 0.8578 using a classical U-Net architecture. A similar dice\ncoefficient score was observed for DoubleUNet. The qualitative results showed\nthat the model did not work for the images with specularity and the frames with\nmultiple instruments, while the best result for both methods was observed on\nall other types of images. Both, qualitative and quantitative results show that\nthe model performs reasonably good, but there is a large potential for further\nimprovements. Benchmarking using the dataset provides an opportunity for\nresearchers to contribute to the field of automatic endoscopic diagnostic and\ntherapeutic tool segmentation for GI endoscopy.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 18:14:36 GMT"}],"update_date":"2020-11-17"}
{"id":"2011.08067","submitter":"Bishal Santra","authors":"Bishal Santra, Potnuru Anusha, Pawan Goyal","title":"Hierarchical Transformer for Task Oriented Dialog Systems","comments":"v3: Latest camera ready version; 10 pages; Codes:\n  https://github.com/bsantraigi/HIER ,\n  https://github.com/bsantraigi/hier-transformer-pytorch v2: To appear in NAACL\n  2021 (Long Paper) v1: preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generative models for dialog systems have gained much interest because of the\nrecent success of RNN and Transformer based models in tasks like question\nanswering and summarization. Although the task of dialog response generation is\ngenerally seen as a sequence-to-sequence (Seq2Seq) problem, researchers in the\npast have found it challenging to train dialog systems using the standard\nSeq2Seq models. Therefore, to help the model learn meaningful utterance and\nconversation level features, Sordoni et al. (2015b); Serban et al. (2016)\nproposed Hierarchical RNN architecture, which was later adopted by several\nother RNN based dialog systems. With the transformer-based models dominating\nthe seq2seq problems lately, the natural question to ask is the applicability\nof the notion of hierarchy in transformer based dialog systems. In this paper,\nwe propose a generalized framework for Hierarchical Transformer Encoders and\nshow how a standard transformer can be morphed into any hierarchical encoder,\nincluding HRED and HIBERT like models, by using specially designed attention\nmasks and positional encodings. We demonstrate that Hierarchical Encoding helps\nachieve better natural language understanding of the contexts in\ntransformer-based models for task-oriented dialog systems through a wide range\nof experiments.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:08:52 GMT"},{"version":"v2","created":"Sun, 14 Mar 2021 15:38:26 GMT"},{"version":"v3","created":"Sun, 9 May 2021 10:25:13 GMT"}],"update_date":"2021-05-11"}
{"id":"2011.08129","submitter":"Mou-Cheng Xu","authors":"Mou-Cheng Xu","title":"Tissue characterization based on the analysis on i3DUS data for\n  diagnosis support in neurosurgery","comments":"MRes thesis","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.AI cs.CV cs.LG cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Brain shift makes the pre-operative MRI navigation highly inaccurate hence\nthe intraoperative modalities are adopted in surgical theatre. Due to the\nexcellent economic and portability merits, the Ultrasound imaging is used at\nour collaborating hospital, Charing Cross Hospital, Imperial College London,\nUK. However, it is found that intraoperative diagnosis on Ultrasound images is\nnot straightforward and consistent, even for very experienced clinical experts.\nHence, there is a demand to design a Computer-aided-diagnosis system to provide\na robust second opinion to help the surgeons. The proposed CAD system based on\n\"Mixed-Attention Res-U-net with asymmetric loss function\" achieves the\nstate-of-the-art results comparing to the ground truth by classification at\npixel-level directly, it also outperforms all the current main stream\npixel-level classification methods (e.g. U-net, FCN) in all the evaluation\nmetrices.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 10:44:49 GMT"}],"update_date":"2020-11-17"}
{"id":"2011.09868","submitter":"Aldo Figallo Orellano","authors":"Aldo Figallo-Orellano and Juan Sebastian Slagter","title":"An algebraic study of the first order version of some implicational\n  fragments of the three-valued Lukasiewicz logic","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  MV-algebras are an algebraic semantics for Lukasiewicz logic and MV-algebras\ngenerated by a finite chain are Heyting algebras where the Godel implication\ncan be written in terms of De Morgan and Moisil's modal operators. In our work,\na fragment of trivalent Lukasiewicz logic is studied. The propositional and\nfirst-order logic is presented. The maximal consistent theories are studied as\nMonteiro's maximal deductive systems of the Lindenbaum-Tarski algebra, in both\ncases. Consequently, the adequacy theorem with respect to the suitable\nalgebraic structures is proven.\n","versions":[{"version":"v1","created":"Fri, 23 Oct 2020 21:37:47 GMT"}],"update_date":"2020-11-20"}
{"id":"2012.08299","submitter":"Zuhair Al-Johar Dr.","authors":"Zuhair Al-Johar","title":"Invariance under permutations as a semantic motivation for\n  Stratification","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This article examines the notion of invariance under different kinds of\npermutations in a milieu of a theory of classes and sets, as a semantic\nmotivation for Quine's new foundations \"NF\". The approach largely depends on\ninterpreting a finite axiomatization of NF beginning from the least\nrestrictions on permutations and then gradually upgrading those restrictions as\nto enable interpreting NF. Comparisons with earlier works are drawn.\n","versions":[{"version":"v1","created":"Sat, 24 Oct 2020 12:40:16 GMT"}],"update_date":"2020-12-16"}
